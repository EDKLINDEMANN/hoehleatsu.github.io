<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Theory meets practice...</title>
    <description>A blog about statistics in theory and practice. Not always serious, not always flawless, but definitely a statistically flavoured bean.
</description>
    <link>http://staff.math.su.se/hoehle/blog/</link>
    <atom:link href="http://staff.math.su.se/hoehle/blog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sat, 11 Feb 2017 11:33:24 +0100</pubDate>
    <lastBuildDate>Sat, 11 Feb 2017 11:33:24 +0100</lastBuildDate>
    <generator>Jekyll v3.1.6</generator>
    
      <item>
        <title>Happy pbirthday class of 2016</title>
        <description>&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Continuing the analys of firstnames given to newborns in Berlin 2016, we solve the following problem: what is the probability, that in a school class of size &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; of these 2016 born kids there will at least two kids having the same first name. This problem is an instance of the birthday problem with unequal probabilities. R code is provided for solving the problem exactly for moderate &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; and approximatively for larger &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt;. For the case that all probabilities are equal, our results are compared to the output of R&#39;s lovely &lt;code&gt;pbirthday&lt;/code&gt; function.&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2017-02-08-bday/WORDMAPCLOUD-1.png&quot; /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br&gt; &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width:0&quot; src=&quot;https://i.creativecommons.org/l/by-sa/4.0/88x31.png&quot;/&gt;&lt;/a&gt; This work is licensed under a &lt;a rel=&quot;license&quot;
href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt;. The markdown+Rknitr source code of this blog is available under a &lt;a href=&quot;https://www.gnu.org/licenses/gpl-3.0.html&quot;&gt;GNU General Public License (GPL v3)&lt;/a&gt; license from &lt;a href=&quot;https://github.com/hoehleatsu/hoehleatsu.github.io&quot;&gt;&lt;img src=&quot;/hoehle/blog/images/GitHub-Mark-32px.png&quot; alt=&quot;github&quot; /&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In the post &lt;a href=&quot;http://staff.math.su.se/hoehle/blog/2017/02/06/onomastics.html&quot;&gt;Naming Uncertainty by the Bootstrap&lt;/a&gt; we performed a descriptive analysis of the names given to newborns in Berlin 2016. For instance, it was shown that Marie and Alexander were the top-1 names among girls and boys, respectively. In a comment &lt;a href=&quot;http://www.masalmon.eu/&quot;&gt;Maëlle&lt;/a&gt; asked what&#39;s the resulting probability that there will be kids with the same name in a school class. We implement equations by &lt;span class=&quot;citation&quot; data-cites=&quot;klotz1979&quot;&gt;Klotz (1979)&lt;/span&gt; and &lt;span class=&quot;citation&quot; data-cites=&quot;mase1992&quot;&gt;Mase (1992)&lt;/span&gt; in R in order to answer this important question.&lt;/p&gt;
&lt;h2 id=&quot;the-birthday-problem&quot;&gt;The Birthday Problem&lt;/h2&gt;
&lt;p&gt;The above posed question is a variation of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Birthday_problem&quot;&gt;&lt;strong&gt;birthday problem&lt;/strong&gt;&lt;/a&gt;, which every statistician has solved at least once in an introductory probability class: &lt;em&gt;in a class of &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; randomly chosen persons, what is the probability that some pair of them will have the same birthday&lt;/em&gt;? Assuming that there are &lt;span class=&quot;math inline&quot;&gt;\(N=365\)&lt;/span&gt; possible birthdays and all days are equally probable the answer can be calculated as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
P(\text{at least two people in the class have the same birthday}) =
1-\frac{(N)_{n}}{N^n},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&quot;math inline&quot;&gt;\((x)_n = x! / (x-n)!\)&lt;/span&gt;. Say we are interested in &lt;span class=&quot;math inline&quot;&gt;\(n=26\)&lt;/span&gt;, which is the &lt;a href=&quot;https://www.berlin.de/imperia/md/content/sen-bildung/rechtsvorschriften/grundschulverordnung.pdf&quot;&gt;maximal allowed class size&lt;/a&gt; in Berlin&#39;s elementary schools (§4, Sect. 8). We can perform the necessary calculations either directly or by R&#39;s &lt;code&gt;pbirthday&lt;/code&gt;function.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;n &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;26&lt;/span&gt; ; N &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;365&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;manual=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt; -&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;exp&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;lfactorial&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;365&lt;/span&gt;)-&lt;span class=&quot;kw&quot;&gt;lfactorial&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;365-26&lt;/span&gt;) -&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;26&lt;/span&gt;*&lt;span class=&quot;kw&quot;&gt;log&lt;/span&gt;(N)),
  &lt;span class=&quot;dt&quot;&gt;pbirthday=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;pbirthday&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;26&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;classes=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;365&lt;/span&gt;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##    manual pbirthday 
## 0.5982408 0.5982408&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finding the &lt;code&gt;pbirthday&lt;/code&gt; function as part of base R was a bit surprising, but just underlines that R really has its roots in statistics!&lt;/p&gt;
&lt;h3 id=&quot;birthday-problem-with-unequal-probabilities&quot;&gt;Birthday Problem with Unequal Probabilities&lt;/h3&gt;
&lt;p&gt;In our problem &lt;span class=&quot;math inline&quot;&gt;\(N\)&lt;/span&gt; corresponds to all possble names of newborns in 2016. For the analysis we only group by firstname and thus do not distinguish between instances of the same name applying to both girls and boys.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;newborn &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;distrNames %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;group_by&lt;/span&gt;(firstname) %&amp;gt;%
&lt;span class=&quot;st&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;summarise&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;count=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;sum&lt;/span&gt;(count)) %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;ungroup&lt;/span&gt;() %&amp;gt;%
&lt;span class=&quot;st&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;mutate&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;p=&lt;/span&gt;count/&lt;span class=&quot;kw&quot;&gt;sum&lt;/span&gt;(count)) %&amp;gt;%
&lt;span class=&quot;st&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;arrange&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;desc&lt;/span&gt;(count))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 13,245 × 3
##   firstname count           p
##       &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt;       &amp;lt;dbl&amp;gt;
## 1     Marie   695 0.009996404
## 2    Sophie   649 0.009334772
## 3 Charlotte   495 0.007119741
## 4 Alexander   468 0.006731392
## # ... with 1.324e+04 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In total there are &lt;span class=&quot;math inline&quot;&gt;\(N=13245\)&lt;/span&gt; possible names. From the &lt;span class=&quot;math inline&quot;&gt;\(p\)&lt;/span&gt; column it also becomes obvious that not all names are equally likely. Had they been, the quick solution to Maëlle&#39;s question would have been:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;pbirthday&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;26&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;classes=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;nrow&lt;/span&gt;(newborn))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.02425434&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Less than &lt;code&gt;sprintf(&amp;quot;%0.f%%&amp;quot;,pbirthday(n=26, classes=nrow(newborn)))&lt;/code&gt;! However, we expect this probability to be much higher, if we start to take unequal occurrence probabilities into account.&lt;/p&gt;
&lt;p&gt;It&#39;s easy to see that the probability of no collision, i.e. no kids having the same name, can be calculated as: &lt;span class=&quot;math display&quot;&gt;\[
P(NC_n) = n!
\underset{1\leq i_1 &amp;lt; i_2 &amp;lt; \cdots &amp;lt;i_n \leq r}{\sum \sum \cdots \sum}
p_{i_1} p_{i_2} \cdots p_{i_n}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;However, this is a formiddable number of terms to sum. In the case of &lt;span class=&quot;math inline&quot;&gt;\(N=13245\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(n=26\)&lt;/span&gt; the number is:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;Rmpfr::&lt;span class=&quot;kw&quot;&gt;chooseMpfr&lt;/span&gt;(N,n)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## 1 &amp;#39;mpfr&amp;#39; number of precision  294   bits 
## [1] 360635627424461042343649241991659010127226742008898829465568350273963478046740130&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(that&#39;s an 80 digit number!), which is not &lt;em&gt;ever&lt;/em&gt; going to happen. Instead &lt;span class=&quot;citation&quot; data-cites=&quot;klotz1979&quot;&gt;Klotz (1979)&lt;/span&gt;, based on generating functions, showed that the above corresponds to&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
P(NC_n) = n!
\underset{\underset{\sum_{j=1}^n j \cdot t_j = r}{0\leq t_1,t_2,\ldots,&amp;lt;t_n \leq n}}{\sum \sum \cdots \sum}
(-1)^{n + \sum_j t_j}
\left(
\prod_{j=1}^n \frac{ (P_j/j)^{t_j}}{t_j!}
\right),
\]&lt;/span&gt; where &lt;span class=&quot;math inline&quot;&gt;\(P_j = \sum_{i=1}^N p_i^j\)&lt;/span&gt;. The vector &lt;span class=&quot;math inline&quot;&gt;\(\mathbf{t}=(t_1,\ldots,t_n)\)&lt;/span&gt; counts the number of singletons (&lt;span class=&quot;math inline&quot;&gt;\(t_1\)&lt;/span&gt;), doubletons (&lt;span class=&quot;math inline&quot;&gt;\(t_2\)&lt;/span&gt;), &lt;span class=&quot;math inline&quot;&gt;\(\ldots\)&lt;/span&gt;, up to the number of names occurring &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; times. We now &lt;em&gt;just&lt;/em&gt; have to sum over all &lt;span class=&quot;math inline&quot;&gt;\(\mathbf{t}\)&lt;/span&gt; such that &lt;span class=&quot;math inline&quot;&gt;\(\sum_{j=1}^n j \cdot t_j = n\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Error: &amp;lt;text&amp;gt;:105:1: unexpected symbol
## 104: pbirthday_up(n=n, prob=rep(1/N, 365)
## 105: pbirthday
##      ^&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;approximation-by-mase-1992&quot;&gt;Approximation by Mase (1992)&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;## Error in pbirthday_up_approx(n = r): object &amp;#39;r&amp;#39; not found&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Error in pbirthday(n = r, classes = N): object &amp;#39;r&amp;#39; not found&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Error in eval(expr, envir, enclos): object &amp;#39;r&amp;#39; not found&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&quot;refs&quot; class=&quot;references&quot;&gt;
&lt;div id=&quot;ref-klotz1979&quot;&gt;
&lt;p&gt;Klotz, J. 1979. “The Birthday Problem with Unequal Probabilities.” 591. Department of Statistics, University of Wisconsin, Madison.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-mase1992&quot;&gt;
&lt;p&gt;Mase, S. 1992. “Approximations to the Birthday Problem with Unequal Occurrence Probabilities and Their Application to the Surname Problem in Japan.” &lt;em&gt;Ann. Inst. Stat. Math.&lt;/em&gt; 44 (3): 479–99.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
        <pubDate>Wed, 08 Feb 2017 00:00:00 +0100</pubDate>
        <link>http://staff.math.su.se/hoehle/blog/2017/02/08/bday.html</link>
        <guid isPermaLink="true">http://staff.math.su.se/hoehle/blog/2017/02/08/bday.html</guid>
        
        <category>rstats</category>
        
        <category>stats</category>
        
        <category>data journalism</category>
        
        <category>onomastics</category>
        
        
      </item>
    
      <item>
        <title>Naming Uncertainty by the Bootstrap</title>
        <description>&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Data on the names of all newborn babies in Berlin 2016 are used to illustrate how a scientific treatment of chance could enhance rank statements in, e.g., &lt;strong&gt;onomastics&lt;/strong&gt; investigations. For this purpose, we first identify different stages of the naming-your-baby process, which are influenced by chance. Second, we compute confidence intervals for the ranks based on a bootstrap procedure reflecting the above chance elements. This leads to an alternative league table based on what we will call &lt;strong&gt;uncertainty corrected ranks&lt;/strong&gt;. From an R perspective we use the problem as a practice session for wrangling data &lt;code&gt;dplyr&lt;/code&gt;-style (code available by clicking on the github logo in the license below).&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2017-02-06-onomastics/WORDMAPCLOUD-1.png&quot; /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br&gt; &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width:0&quot; src=&quot;https://i.creativecommons.org/l/by-sa/4.0/88x31.png&quot;/&gt;&lt;/a&gt; This work is licensed under a &lt;a rel=&quot;license&quot;
href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt;. The markdown+Rknitr source code of this blog is available under a &lt;a href=&quot;https://www.gnu.org/licenses/gpl-3.0.html&quot;&gt;GNU General Public License (GPL v3)&lt;/a&gt; license from &lt;a href=&quot;https://github.com/hoehleatsu/hoehleatsu.github.io&quot;&gt;&lt;img src=&quot;/hoehle/blog/images/GitHub-Mark-32px.png&quot; alt=&quot;github&quot; /&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;What&#39;s the most popular first name given to newborn boys and girls? This question seems to fascinate at different levels of temporal and spatial aggregation, because the choice of names and its dynamics reflects cultural and social behavior. The branch of science related to the study of names is entitled &lt;a href=&quot;https://en.wikipedia.org/wiki/Onomastics&quot;&gt;&lt;strong&gt;onomastics&lt;/strong&gt;&lt;/a&gt;. Mathematical modelling is used in onomastics to study name dynamics by evolutionary models and models for contagious phenomena &lt;span class=&quot;citation&quot; data-cites=&quot;kahn_bentley2003&quot;&gt;(Hahn and Bentley 2003, &lt;span class=&quot;citation&quot; data-cites=&quot;kessler_etal2012&quot;&gt;Kessler et al. (2012)&lt;/span&gt;)&lt;/span&gt;. But even the task of &lt;a href=&quot;(http://waitbutwhy.com/2013/12/how-to-name-baby.html)&quot;&gt;naming your baby&lt;/a&gt; has almost onomastics optimizing flavour requiring data science skills. However, once the Official Social Security Administration has released the numbers for all names of newborns in a given year, finding the most popular baby name appears a simple counting and ranking job: for example the &lt;a href=&quot;http://www.babynamewizard.com/the-top-1000-baby-names-of-2015-united-states-of-america&quot;&gt;most popular US baby names in 2015 were Emma (girls) and Noah (boys)&lt;/a&gt;.&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2017-02-06-onomastics/Hello-My-Name-Is.png&quot; /&gt; &lt;br&gt; &lt;!-- Modified based on the following source: https://openclipart.org/image/300px/svg_to_png/250091/ --&gt;
&lt;/center&gt;
&lt;p&gt;
&lt;p&gt;
&lt;p&gt;&lt;strong&gt;Statistics&lt;/strong&gt; is the scientific study of chance. One fundamental concept is the inference of a &lt;strong&gt;population&lt;/strong&gt; quantity from observing the quantity in a &lt;strong&gt;sample&lt;/strong&gt; (=subset) of this population. To make this specific for the baby names: In Germany there is no official first name statistics, as a consequence, the site &lt;a href=&quot;http://www.beliebte-vornamen.de&quot;&gt;www.beliebte-vornamen.de&lt;/a&gt; uses information from a sample of 196,158 kids (corresponding to 26% of all newborns in Germany 2016) originating from a selection of registrar&#39;s offices and birth clinics to determine the most popular first name in Germany 2016. However, the aspect of uncertainty in the resulting ranking, due to only measuring a sample of the population, is ignored when reporting the &lt;a href=&quot;http://www.beliebte-vornamen.de/jahrgang/j2016&quot;&gt;2016 league table&lt;/a&gt;. The aspect of uncertainty can, however, also be more subtle. As an example, the city of Berlin recently released the official &lt;a href=&quot;https://daten.berlin.de/datensaetze/liste-der-h%C3%A4ufigen-vornamen-2014&quot;&gt;2016 first name statistic&lt;/a&gt; of &lt;strong&gt;all newborns&lt;/strong&gt; in the city. The data are available at &lt;a href=&quot;https://en.wikipedia.org/wiki/Boroughs_and_neighborhoods_of_Berlin&quot;&gt;district level&lt;/a&gt;, which is helpful, because there are notable socio-economic and cultural differences between the districts. One could argue that since the data cover the &lt;strong&gt;entire population of interest&lt;/strong&gt; (i.e. newborns in Berlin 2016) the use of &lt;strong&gt;inferential statistics&lt;/strong&gt; is superfluous. But is it that simple?&lt;/p&gt;
&lt;p&gt;In what follows we use the Berlin newborn names to illustrate how a scientific treatment of &lt;strong&gt;chance&lt;/strong&gt; could enhance rank statements in general and in name rank tables in particular.&lt;/p&gt;
&lt;h2 id=&quot;descriptive-data-analysis&quot;&gt;Descriptive Data Analysis&lt;/h2&gt;
&lt;p&gt;Altogether, the &lt;code&gt;distrNames&lt;/code&gt; variable contains the information about the frequency of 13245 unique first names. Below is shown the first 10 lines of the data.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2017-02-06-onomastics/unnamed-chunk-5-1.png&quot; style=&quot;display: block; margin: auto;&quot; /&gt;&lt;/p&gt;
&lt;p&gt;By summing the &lt;code&gt;count&lt;/code&gt; column it becomes clear that in total, 69525 names were registered in Berlin 2016 (35620 boys and 33905) girls. The proportion of boy names is 51.2%. One caveat with the Berlin name statistic is that, if a child is given several first names, each name is counted once in the statistic. Hence, the above total sum is actually higher than the number of kids born 2016 (38,030 in 2015, official 2016 number not available yet). Despite of the potential problems with multiple names per kids, the empirical boy fraction in the data is close to reported ratios of the number of born boys vs. girls of 1.05 &lt;span class=&quot;citation&quot; data-cites=&quot;jacobsen1999&quot;&gt;(Jacobsen, Møller, and Mouritsen 1999)&lt;/span&gt;, which means that the expected fraction of boys among the newborns should be approximately 51.2%.&lt;/p&gt;
&lt;p&gt;Strangely enough, 15 babies seem to have an empty first name (but the sex is known). We decided to keep these &lt;code&gt;NA&lt;/code&gt; names in the analysis, because at the time of writing it was unclear, if this is a data recording problem (e.g. a delay of the December 2016 kids) or actually allowed. An email inquiry with the data providing agency about the origin of these &lt;code&gt;NA&lt;/code&gt;&#39;s currently remains unanswered (since 7 days).&lt;/p&gt;
&lt;p&gt;We can now look at the top-5-names in Berlin for each gender:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Aggregate data over district and sort according to rank within gender
newborn &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;distrNames %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;group_by&lt;/span&gt;(firstname, sex) %&amp;gt;%
&lt;span class=&quot;st&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;summarise&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;count=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;sum&lt;/span&gt;(count)) %&amp;gt;%
&lt;span class=&quot;st&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;arrange&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;desc&lt;/span&gt;(count)) %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;group_by&lt;/span&gt;(sex) %&amp;gt;%
&lt;span class=&quot;st&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;mutate&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;rank=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;rank&lt;/span&gt;(-count,&lt;span class=&quot;dt&quot;&gt;ties=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;min&amp;quot;&lt;/span&gt;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## Source: local data frame [10 x 4]
## Groups: sex [2]
## 
##     firstname    sex count  rank
##         &amp;lt;chr&amp;gt; &amp;lt;fctr&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;
## 1       Marie      f   695     1
## 2      Sophie      f   649     2
## 3   Charlotte      f   495     3
## 4       Maria      f   403     4
## 5      Emilia      f   382     5
## 6   Alexander      m   467     1
## 7        Paul      m   383     2
## 8       Elias      m   371     3
## 9  Maximilian      m   344     4
## 10       Emil      m   295     5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The top-1 names per gender and district from &lt;code&gt;distrNames&lt;/code&gt; can easily be computed in similar fashion using &lt;code&gt;group_by&lt;/code&gt; and &lt;code&gt;summarise&lt;/code&gt; operations. To spice up the visualization we use a custom made &lt;strong&gt;wordmapcloud&lt;/strong&gt;, which overlays the top-1 names over an alpha-channeled wordcloud of the district&#39;s name with font size proportional to frequency. In the resulting plot we see little geographical variation in the top-1 names over the districts - particularly for girls.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2017-02-06-onomastics/WORDMAPCLOUD-1.png&quot; style=&quot;display: block; margin: auto;&quot; /&gt;&lt;/p&gt;
&lt;p&gt;The &lt;a href=&quot;https://en.wikipedia.org/wiki/Gini_coefficient&quot;&gt;Gini index&lt;/a&gt; for the name frequency is calculated using the &lt;code&gt;ineq&lt;/code&gt; package and is 0.728 and 0.743 for girls and boys, respectively. This means that the occurrence of names in boys is dominated by fewer names for boys than for girls. Furthermore, both gender&#39;s name distribution tend to be dominated by few names. This feature can also be visualized by a Lorenz curve - here shown separately for each sex:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2017-02-06-onomastics/LORENZCURVE-1.png&quot; style=&quot;display: block; margin: auto;&quot; /&gt;&lt;/p&gt;
&lt;p&gt;From the curve one can for example deduce that the frequency of the top-50 girl names (top 0.7% out of the 6957 girl names), cover 29.0% of all 33905 girl namings.&lt;/p&gt;
&lt;h2 id=&quot;analysing-stochasticity-in-the-name-selection&quot;&gt;Analysing Stochasticity in the Name Selection&lt;/h2&gt;
&lt;p&gt;At which places is stochasticity a useful concept for abstracting unobservable factors influencing the name selection? We shall focus on 5 stages:&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;the number of babies born in Berlin in 2016&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the gender of a given born baby; as mentioned above the odds for the kid being a boy is roughly 1.05:1.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the number of names given to a baby of a specific sex&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the selection of the name(s) given that the gender of the baby is known&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;reporting problems leading to the wrong name(s) being recorded&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We will ignore uncertainty from stages 1, 3 and 5 and, hence, only focus on uncertainty arising from stages 2 and 4. One may ask in stage 4, if the naming is not deterministic, once the parents know the sex of their baby? In this post we take the position that &lt;em&gt;even&lt;/em&gt; given sex the naming is the outcome of a stochastic process. The selection probabilities are likely to vary from couple to couple based on complex interactions between, e.g., social status, existing names in the family as well as past exposure and associations with names. Since data are never going to be available on these individual factors, we will, as a proxy, assume that the drawing probabilities are district specific. As a result, the selected name can be considered as one realization of the multinomial distribution with the underlying true popularity of all possible names in the district acting as selection probabilities.&lt;/p&gt;
&lt;h3 id=&quot;uncertainty-assessment-using-the-bootstrap&quot;&gt;Uncertainty Assessment using the Bootstrap&lt;/h3&gt;
&lt;p&gt;When combining the above stages 3 and 4, the name selection process can be mimicked by a &lt;strong&gt;simple bootstrap&lt;/strong&gt; procedure &lt;strong&gt;stratified by district&lt;/strong&gt; &lt;span class=&quot;citation&quot; data-cites=&quot;davison_hinkley1997&quot;&gt;(Davison and Hinkley 1997)&lt;/span&gt;. In spirit, this approach corresponds to the bootstrap approach to ranks used in Sect. 5.3 of &lt;span class=&quot;citation&quot; data-cites=&quot;goldstein_spiegelhalter1996&quot;&gt;Goldstein and Spiegelhalter (1996)&lt;/span&gt;. We operationalise this in R using the &lt;code&gt;boot&lt;/code&gt; package, the work-horse will be the function &lt;code&gt;name_ranks&lt;/code&gt; shown below.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;######################################################################
## Compute rank of name within female and male population,
## respectively for a draw of all kids (one kid per row) with
## replacement.
##
## Parameters:
##  x - the full data, one row per kid
##  idx - vector of length nrow(x) containing a possible permutation
##        (with replacement)
##  returns - which column to return, &amp;quot;rank&amp;quot; or &amp;quot;count&amp;quot; (for use in boot).
##            If returns==&amp;quot;dplyr::everything()&amp;quot;, then entire frame is returned (useful for
##            use with broom)
##
## Returns:
##  vector or data.frame with stratified ranks (arranged by (firstname, sex))
######################################################################

name_ranks &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(x,  &lt;span class=&quot;dt&quot;&gt;idx=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;seq_len&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;nrow&lt;/span&gt;(x)), &lt;span class=&quot;dt&quot;&gt;returns=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;rank&amp;quot;&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;count&amp;quot;&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;dplyr::everything()&amp;quot;&lt;/span&gt;)) {
  ##Make resampled data and append all_strata to ensure each firstname-sex combination occurs
  x_boot &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;x %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;slice&lt;/span&gt;(idx) %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;bind_rows&lt;/span&gt;(all_strata)

  ##Summarise the number of occurrences for each firstname-sex strata and compute the ranks.
  aggrx_wranks &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;x_boot %&amp;gt;%&lt;span class=&quot;st&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;group_by&lt;/span&gt;(firstname,sex) %&amp;gt;%
&lt;span class=&quot;st&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;summarise&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;count =&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;sum&lt;/span&gt;(count)) %&amp;gt;%
&lt;span class=&quot;st&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;group_by&lt;/span&gt;(sex) %&amp;gt;%
&lt;span class=&quot;st&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;mutate&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;rank=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;rank&lt;/span&gt;(-count, &lt;span class=&quot;dt&quot;&gt;ties.method=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;min&amp;quot;&lt;/span&gt;)) %&amp;gt;%
&lt;span class=&quot;st&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;arrange&lt;/span&gt;(firstname, sex) &lt;span class=&quot;co&quot;&gt;#important to ensure order.&lt;/span&gt;

  ##Select relevant columns
  res &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;aggrx_wranks %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;ungroup&lt;/span&gt;() %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;select_&lt;/span&gt;(returns)

  ##Return as vector (needed for boot pkg) or data.frame (needed from broom)
  if (returns[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;] %in%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;rank&amp;quot;&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;count&amp;quot;&lt;/span&gt;)) &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt;(res %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;.[[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;]]) else &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt;(res)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In the above, &lt;code&gt;all_strata&lt;/code&gt; is a &lt;code&gt;data.frame&lt;/code&gt; containing all possible strata of gender and firstname. This is done in order to ensure that we later get a zero count for names, even if they do not appear in the bootstrap re-sample.&lt;/p&gt;
&lt;p&gt;We then convert the aggregated data to long format where each kid is represented by one row. This is the most didactic way to explain what is going on in the bootstrap, but an aggregated multinomial approach would probably be faster in terms of execution time.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;kids &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;distrNames %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;slice&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;rep&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;seq_len&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;nrow&lt;/span&gt;(distrNames)), &lt;span class=&quot;dt&quot;&gt;times=&lt;/span&gt;distrNames %$%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;count)) %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;mutate&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;count=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Ready to perform the bootstrap stratified within districts? Yes, its conveniently done using the &lt;code&gt;boot&lt;/code&gt; package (which is easily paralleled too).&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;set.seed&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;123&lt;/span&gt;) ##fix seed for reproducibility
b &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;boot::&lt;span class=&quot;kw&quot;&gt;boot&lt;/span&gt;(kids, &lt;span class=&quot;dt&quot;&gt;statistic=&lt;/span&gt;name_ranks, &lt;span class=&quot;dt&quot;&gt;R=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;999&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;strata=&lt;/span&gt;kids$district, &lt;span class=&quot;dt&quot;&gt;parallel=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;multicore&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;ncpus=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We use the percentile method on the 999 + 1 bootstrap rank-vectors as a method for computing a 90% confidence interval for the rank of each name for boys and girls, respectively.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update 2017-02-07&lt;/strong&gt;: &lt;a href=&quot;http://www.masalmon.eu/&quot;&gt;Maëlle&lt;/a&gt; made me &lt;a href=&quot;https://twitter.com/ma_salmon/status/828505021666967552&quot;&gt;aware&lt;/a&gt; of some newer ways to perform the bootstrap, e.g., using the &lt;code&gt;broom&lt;/code&gt; package. It&#39;s especially useful for the parametric bootstrap, but by joining with the previously calculated observed ranks, the code for making a simple bootstrap stratified bootstrap actually looks quite nice (although not parallized and hence slower):&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;require&lt;/span&gt;(broom)
b_broom &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;kids %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;group_by&lt;/span&gt;(district) %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;bootstrap&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;m=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;999&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;by_group=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;) %&amp;gt;%
&lt;span class=&quot;st&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;do&lt;/span&gt;({ &lt;span class=&quot;kw&quot;&gt;name_ranks&lt;/span&gt;(.,&lt;span class=&quot;dt&quot;&gt;returns=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;dplyr::everything()&amp;quot;&lt;/span&gt;) }) %&amp;gt;%
&lt;span class=&quot;st&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;group_by&lt;/span&gt;(sex,firstname) %&amp;gt;%
&lt;span class=&quot;st&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;summarise&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;rankci.5.&amp;quot;&lt;/span&gt;=&lt;span class=&quot;kw&quot;&gt;quantile&lt;/span&gt;(rank, &lt;span class=&quot;fl&quot;&gt;0.05&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;type=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;),&lt;span class=&quot;st&quot;&gt;&amp;quot;rankci.95.&amp;quot;&lt;/span&gt;=&lt;span class=&quot;kw&quot;&gt;quantile&lt;/span&gt;(rank, &lt;span class=&quot;fl&quot;&gt;0.95&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;type=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;))

newborn_ranks &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;newborn %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;inner_join&lt;/span&gt;(b_broom,&lt;span class=&quot;dt&quot;&gt;by=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;firstname&amp;quot;&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;sex&amp;quot;&lt;/span&gt;)) %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;arrange&lt;/span&gt;(rank,sex)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## Source: local data frame [10 x 6]
## Groups: sex [2]
## 
##     firstname    sex count  rank rankci.5. rankci.95.
##         &amp;lt;chr&amp;gt; &amp;lt;fctr&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;     &amp;lt;int&amp;gt;      &amp;lt;int&amp;gt;
## 1       Marie      f   695     1         1          2
## 2   Alexander      m   467     1         1          1
## 3      Sophie      f   649     2         1          2
## 4        Paul      m   383     2         2          3
## 5   Charlotte      f   495     3         3          3
## 6       Elias      m   371     3         2          4
## 7       Maria      f   403     4         4          5
## 8  Maximilian      m   344     4         3          4
## 9      Emilia      f   382     5         4          5
## 10       Emil      m   295     5         5          9&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using the lower limit of the 90% CI to group the names, we define the concept of a &lt;strong&gt;uncertainty corrected&lt;/strong&gt; rank (ucrank). This is just the lowest rank which we, given the modelled stochasticity, cannot be ruled out (at the 5% lvl. of significance). Listing the top-5 of these corrected ranks leads to the following tables for girls and boys, respectively:&lt;/p&gt;
&lt;center&gt;
&lt;!-- html table generated in R 3.3.2 by xtable 1.8-2 package --&gt;
&lt;!-- Thu Feb  9 23:40:38 2017 --&gt;
&lt;table border=&quot;5,&quot; padding=&quot;10,&quot; style=&quot;width=100%&quot;&gt;
&lt;tr&gt;
&lt;th&gt;
ucrank (among girls)
&lt;/th&gt;
&lt;th&gt;
first names (girls)
&lt;/th&gt;
&lt;th&gt;
ucrank (among boys)
&lt;/th&gt;
&lt;th&gt;
first names (boys)
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;
1
&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;
Marie, Sophie
&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;
1
&lt;/td&gt;
&lt;td&gt;
Alexander
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;
3
&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;
Charlotte
&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;
2
&lt;/td&gt;
&lt;td&gt;
Paul, Elias
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;
4
&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;
Maria, Emilia
&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;
3
&lt;/td&gt;
&lt;td&gt;
Maximilian
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;
6
&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;
Anna, Emma, Mia, Sophia
&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;
5
&lt;/td&gt;
&lt;td&gt;
Emil, Noah, Anton, Felix
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;
8
&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;
Johanna, Luise
&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;
6
&lt;/td&gt;
&lt;td&gt;
Oskar
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/center&gt;
&lt;p&gt;
&lt;p&gt;Instead of using the uncertainty corrected ranks, we could instead have visualized the 90% rank confidence intervals instead (dots denote the observed ranks):&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2017-02-06-onomastics/RANKCIPLOT-1.png&quot; style=&quot;display: block; margin: auto;&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;discussion&quot;&gt;Discussion&lt;/h2&gt;
&lt;p&gt;In this post we have used the bootstrap method as a way to assess uncertainty in ranks. This approach is very general and can be extended to areas beyond onomastics. No matter the area of application the approach requires a careful identification of the elements of chance you want to take into account. In the particular application we decided to ignore specific uncertainty aspects (e.g. number of babies born) to not impose further hard-to-verify assumptions. However, as soon as there is uncertainty, ranks are known to be subject to large variation. Hence, a different reporting or visualization of the ranks than the point estimator from the sample is necessary. The use of &lt;em&gt;uncertainty corrected&lt;/em&gt; ranks is not revolutionary, but it underlines the importance of uncertainty in the construction of league tables. A more uncertainty enhancing presentation of ranks in, e.g., data journalism, is therefore needed.&lt;/p&gt;
&lt;center&gt;
&lt;embed src=&quot;https://openclipart.org/image/300px/svg_to_png/221003/Name-Numer-T-Shirt.png&amp;amp;disposition=attachment&quot; /&gt; &lt;/enter&gt;
&lt;p&gt;
&lt;/center&gt;
&lt;h2 id=&quot;references&quot; class=&quot;unnumbered&quot;&gt;References&lt;/h2&gt;
&lt;div id=&quot;refs&quot; class=&quot;references&quot;&gt;
&lt;div id=&quot;ref-davison_hinkley1997&quot;&gt;
&lt;p&gt;Davison, A. C., and D. V. Hinkley. 1997. &lt;em&gt;Bootstrap Methods and Their Applications&lt;/em&gt;. Cambridge University Press.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-goldstein_spiegelhalter1996&quot;&gt;
&lt;p&gt;Goldstein, Harvey, and David J. Spiegelhalter. 1996. “League Tables and Their Limitations: Statistical Issues in Comparisons of Institutional Performance.” &lt;em&gt;Journal of the Royal Statistical Society. Series A (Statistics in Society)&lt;/em&gt; 159 (3). [Wiley, Royal Statistical Society]: 385–443. &lt;a href=&quot;http://www.jstor.org/stable/2983325&quot; class=&quot;uri&quot;&gt;http://www.jstor.org/stable/2983325&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-kahn_bentley2003&quot;&gt;
&lt;p&gt;Hahn, Matthew W, and Alexander R Bentley. 2003. “Drift as a Mechanism for Cultural Change: An Example from Baby Names.” &lt;em&gt;Proceedings of the Royal Society B: Biological Sciences&lt;/em&gt; 270 (Suppl 1): S120–S123. doi:&lt;a href=&quot;https://doi.org/10.1098/rsbl.2003.0045&quot;&gt;10.1098/rsbl.2003.0045&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-jacobsen1999&quot;&gt;
&lt;p&gt;Jacobsen, R., H. Møller, and A. Mouritsen. 1999. “Natural Variation in the Human Sex Ratio.” &lt;em&gt;Human Reproduction&lt;/em&gt; 14 (12): 3120. doi:&lt;a href=&quot;https://doi.org/10.1093/humrep/14.12.3120&quot;&gt;10.1093/humrep/14.12.3120&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-kessler_etal2012&quot;&gt;
&lt;p&gt;Kessler, David A, Yosi E Maruvka, Jøergen Ouren, and Nadav M Shnerb. 2012. “You Name It –How Memory and Delay Govern First Name Dynamics.” Edited by Eshel Ben-Jacob. &lt;em&gt;PLoS ONE&lt;/em&gt; 7 (6). San Francisco, USA: Public Library of Science: e38790. doi:&lt;a href=&quot;https://doi.org/10.1371/journal.pone.0038790&quot;&gt;10.1371/journal.pone.0038790&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
        <pubDate>Mon, 06 Feb 2017 00:00:00 +0100</pubDate>
        <link>http://staff.math.su.se/hoehle/blog/2017/02/06/onomastics.html</link>
        <guid isPermaLink="true">http://staff.math.su.se/hoehle/blog/2017/02/06/onomastics.html</guid>
        
        <category>rstats</category>
        
        <category>stats</category>
        
        <category>ranks</category>
        
        <category>league table</category>
        
        <category>data journalism</category>
        
        <category>onomastics</category>
        
        
      </item>
    
      <item>
        <title>suRprise! - Classifying Kinder Eggs by Boosting</title>
        <description>&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Carrying the Danish tradition of Juleforsøg to the realm of statistics, we use R to classify the figure content of Kinder Eggs using boosted classification trees for the egg&#39;s weight and possible rattling noises.&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-12-23-surprise/pics/figures.jpg&quot; /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br&gt; &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width:0&quot; src=&quot;https://i.creativecommons.org/l/by-sa/4.0/88x31.png&quot;/&gt;&lt;/a&gt; This work is licensed under a &lt;a rel=&quot;license&quot;
href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt;. The markdown+Rknitr source code of this blog is available under a &lt;a href=&quot;https://www.gnu.org/licenses/gpl-3.0.html&quot;&gt;GNU General Public License (GPL v3)&lt;/a&gt; license from &lt;a href=&quot;https://github.com/hoehleatsu/hoehleatsu.github.io&quot;&gt;&lt;img src=&quot;/hoehle/blog/images/GitHub-Mark-32px.png&quot; alt=&quot;github&quot; /&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;A &lt;strong&gt;juleforsøg&lt;/strong&gt; is the kind of &lt;a href=&quot;https://www.youtube.com/watch?v=sinQ06YzbJI8&quot;&gt;exploding experiment&lt;/a&gt; happening in the last physics or chemistry class before the Christmas vacation. Not seldomly the teacher, with a look of secrecy, initializes the class by locking the door mumbling something like &amp;quot;the headmaster better not see this...&amp;quot;. With Christmas approaching fast, here is an attempt to create a statistical juleforsøg concluding the &lt;em&gt;Theory meets practice&lt;/em&gt; 2016 posting season:&lt;/p&gt;
&lt;p&gt;The advertisement campaign of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Kinder_Surprise&quot;&gt;Kinder Surprise Eggs&lt;/a&gt; aka. &lt;a href=&quot;https://en.wikipedia.org/wiki/Kinder_Joy&quot;&gt;Kinder Joy&lt;/a&gt; claims that the content of every 7th egg is a figure (see &lt;a href=&quot;https://blog.kalaydo.de/blog/wp-content/uploads/2016/05/Biene-Maja.jpg&quot;&gt;example&lt;/a&gt;) - otherwise they contain toys or puzzles, which positively can be described as junk. Figures, in particular completed series, on the other hand, can achieve high &lt;a href=&quot;https://translate.google.com/translate?sl=de&amp;amp;tl=en&amp;amp;js=y&amp;amp;prev=_t&amp;amp;hl=en&amp;amp;ie=UTF-8&amp;amp;u=https%3A%2F%2Fwww.kalaydo.de%2Fblog%2Fwertvolle-ue-ei-figuren%2F&amp;amp;edit-text=&amp;amp;act=url&quot;&gt;trading values&lt;/a&gt;. The clear goal is thus to optimize your egg hunting strategy in order to maximize figure content.&lt;/p&gt;
&lt;h2 id=&quot;the-problem&quot;&gt;The problem&lt;/h2&gt;
&lt;p&gt;Your budget is limited, so the question is which egg to select when standing in the supermarket?&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-12-23-surprise/pics/inshopwithprice.jpg&quot; /&gt;
&lt;/center&gt;
&lt;p&gt;
&lt;p&gt;Photo: Price in SEK per egg in a Swedish supermarket. The red ellipse shows the price per kg.&lt;/p&gt;
&lt;h3 id=&quot;various-egg-selection-strategies&quot;&gt;Various egg selection strategies&lt;/h3&gt;
&lt;p&gt;It goes without saying that brute force purchasing strategies would be insane. Hence, a number of egg selection strategies can be observed in real life:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The no clue egg enthusiast: Selects an egg at random. With a certain probability (determined by the producer and the cleverness of the previous supermarked visitors) the egg contains a figure&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The egg junkie: knows a good &lt;a href=&quot;https://www.radiologycafe.com/blog/easter-egg-xray&quot;&gt;radiologist&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The egg nerd: using &lt;a href=&quot;https://translate.google.com/translate?sl=de&amp;amp;tl=en&amp;amp;js=y&amp;amp;prev=_t&amp;amp;hl=en&amp;amp;ie=UTF-8&amp;amp;u=http%3A%2F%2Fwww.eierwiki.de%2Findex.php%3Ftitle%3DTipps_%2526_Tricks_beim_Eierkauf&amp;amp;edit-text=&amp;amp;act=url&quot;&gt;scale, rattling noises and the barcode&lt;/a&gt; he/she quickly determines whether there is a figure in the egg&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We shall in this post be interested in &lt;strong&gt;the statistician&#39;s egg selection approach&lt;/strong&gt;: Egg classification based on weight and rattling noise using &#39;top-notch&#39; machine learning algorithms - in our case based on boosted classification trees.&lt;/p&gt;
&lt;h2 id=&quot;data-collection&quot;&gt;Data Collection&lt;/h2&gt;
&lt;p&gt;We collected n=79 eggs of which 43.0% were figures - the data are available under a GPL v3.0 license from &lt;a href=&quot;https://github.com/hoehleatsu/hoehleatsu.github.io/blob/master/figure/source/2016-12-23-surprise/surprise.txt&quot;&gt;github&lt;/a&gt;. For each egg, we determined its &lt;strong&gt;weight&lt;/strong&gt; as well as the sound it produced when being shaken. If the sounds could be characterized as &lt;strong&gt;rattling&lt;/strong&gt; (aka. clattering) this was indicative of the content consisting of many parts and, hence, unlikely to be a figure.&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-12-23-surprise/pics/weightandrattle.jpg&quot; /&gt;
&lt;/center&gt;
&lt;p&gt;
&lt;p&gt;Altogether, the first couple of rows of the dataset look as follows.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;head&lt;/span&gt;(surprise, &lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;5&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##   weight rattles_like_figure figure rattles rattles_fac figure_fac
## 1     32                   1      0       0          no         no
## 2     34                   0      1       1         yes        yes
## 3     34                   1      1       0          no        yes
## 4     30                   1      0       0          no         no
## 5     34                   1      1       0          no        yes&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;descriptive-data-analysis&quot;&gt;Descriptive Data Analysis&lt;/h3&gt;
&lt;p&gt;The fraction of figures in the dataset was 34/79, which is way higher than the proclaimed 1/7; possibly, because professionals egg collectors were at work...&lt;/p&gt;
&lt;p&gt;Of the 79 analysed eggs, 54 were categorized as non-rattling. The probability of such a non-rattling egg really containing a figure was 51.9%. This proportion is not impressive, but could be due to the data collector&#39;s having a different understanding of exactly how the variable &lt;em&gt;rattling&lt;/em&gt; was to be interpreted: Does it &lt;em&gt;rattle&lt;/em&gt;, or does it &lt;em&gt;rattle like a figure&lt;/em&gt;? In hindsight, a clearer definition and communication of this variable would have prevented ambiguity in the collection.&lt;/p&gt;
&lt;p&gt;A descriptive plot of the weight distribution of eggs with and without figure content shows, that eggs with figures tend to be slightly heavier:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-12-23-surprise/WEIGHTPLOT-1.png&quot; style=&quot;display: block; margin: auto;&quot; /&gt; Note: The first approximately 50% of the eggs were weighted on a standard supermarket scales, which showed the resulting weight in even steps of 2g only.&lt;/p&gt;
&lt;p&gt;Below the proportion (in %) of eggs with figure content per observed weight:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##           weight
## figure_fac    26    28    29    30    31    32    33    34    35    36    40
##        no  100.0  50.0  66.7  53.3  71.4  72.7  75.0  25.0 100.0  33.3   0.0
##        yes   0.0  50.0  33.3  46.7  28.6  27.3  25.0  75.0   0.0  66.7 100.0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A simple selection rule based on weight would be to weigh eggs until you hit a 40g egg. A slightly less certain stopping rule would be to pick 34g eggs. However, modern statistics is more than counting and analysing proportions!&lt;/p&gt;
&lt;h2 id=&quot;machine-learning-the-egg-content&quot;&gt;Machine Learning the Egg Content&lt;/h2&gt;
&lt;p&gt;We use machine learning algorithms to solve the binary classification problem at hand. In particular, we use the &lt;code&gt;caret&lt;/code&gt; package &lt;span class=&quot;citation&quot; data-cites=&quot;caret&quot;&gt;(Kuhn 2016)&lt;/span&gt; and classify figure content using boosted classification trees as implemented in the &lt;a href=&quot;https://en.wikipedia.org/wiki/Xgboost&quot;&gt;&lt;code&gt;xgboost&lt;/code&gt;&lt;/a&gt; package &lt;span class=&quot;citation&quot; data-cites=&quot;xgboost&quot;&gt;(Chen et al. 2016)&lt;/span&gt;. Details on how to use the &lt;code&gt;caret&lt;/code&gt; package can, e.g., be found in the following &lt;a href=&quot;https://topepo.github.io/caret/index.html&quot;&gt;tutorial&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;library&lt;/span&gt;(caret)

##Grid with xgboost hyperparameters
xgb_hyperparam_grid =&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;expand.grid&lt;/span&gt;(
  &lt;span class=&quot;dt&quot;&gt;nrounds =&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;25&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;50&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;250&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;1000&lt;/span&gt;),
  &lt;span class=&quot;dt&quot;&gt;eta =&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;fl&quot;&gt;0.01&lt;/span&gt;, &lt;span class=&quot;fl&quot;&gt;0.001&lt;/span&gt;, &lt;span class=&quot;fl&quot;&gt;0.0001&lt;/span&gt;),
  &lt;span class=&quot;dt&quot;&gt;max_depth =&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;seq&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;16&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;by=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;),
  &lt;span class=&quot;dt&quot;&gt;subsample =&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;fl&quot;&gt;0.4&lt;/span&gt;,&lt;span class=&quot;fl&quot;&gt;0.5&lt;/span&gt;,&lt;span class=&quot;fl&quot;&gt;0.6&lt;/span&gt;),
  &lt;span class=&quot;dt&quot;&gt;gamma =&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;colsample_bytree =&lt;/span&gt; &lt;span class=&quot;fl&quot;&gt;0.8&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;min_child_weight =&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;
)
##caret training control object
control &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;trainControl&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;method=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;repeatedcv&amp;quot;&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;number=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;8&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;repeats=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;8&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;classProbs=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;,
                        &lt;span class=&quot;dt&quot;&gt;summaryFunction =&lt;/span&gt; twoClassSummary, &lt;span class=&quot;dt&quot;&gt;allowParallel=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;)
##train away and do it parallelized on 3 cores...
&lt;span class=&quot;kw&quot;&gt;library&lt;/span&gt;(doMC)
&lt;span class=&quot;kw&quot;&gt;registerDoMC&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;cores =&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;)
m_xgb &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;train&lt;/span&gt;( figure_fac ~&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;weight *&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;rattles_fac, &lt;span class=&quot;dt&quot;&gt;data=&lt;/span&gt;surprise, &lt;span class=&quot;dt&quot;&gt;method=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;xgbTree&amp;quot;&lt;/span&gt;,
               &lt;span class=&quot;dt&quot;&gt;trControl=&lt;/span&gt;control, &lt;span class=&quot;dt&quot;&gt;verbose=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;FALSE&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;metric=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;ROC&amp;quot;&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;tuneGrid=&lt;/span&gt;xgb_hyperparam_grid)
##look at the result
m_xgb&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## eXtreme Gradient Boosting  
##   
##  79 samples 
##   2 predictor 
##   2 classes: &amp;#39;no&amp;#39;, &amp;#39;yes&amp;#39;  
##   
##  No pre-processing 
##  Resampling: Cross-Validated (8 fold, repeated 8 times)  
##  Summary of sample sizes: 69, 70, 69, 69, 69, 68, ...  
##  Resampling results across tuning parameters: 
##   
##    eta    max_depth  subsample  nrounds  ROC        Sens       Spec      
##    1e-04   2         0.4          25     0.6661328  0.8661458  0.4328125 
##    1e-04   2         0.4          50     0.6657943  0.8661458  0.4359375 
##    1e-04   2         0.4         100     0.6760938  0.8661458  0.4398437 
##    ...  ...        ... 
##    1e-02  16         0.6         250     0.6769792  0.7901042  0.4210937 
##    1e-02  16         0.6        1000     0.6578516  0.7364583  0.4335938 
##   
##  Tuning parameter &amp;#39;gamma&amp;#39; was held constant at a value of 1 
##  Tuning 
##   parameter &amp;#39;colsample_bytree&amp;#39; was held constant at a value of 0.8 
##  Tuning 
##   parameter &amp;#39;min_child_weight&amp;#39; was held constant at a value of 1 
##  ROC was used to select the optimal model using  the largest value. 
##  The final values used for the model were nrounds = 250, max_depth = 6, eta = 0.01, 
##   gamma = 1, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 0.4.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The average AUC for the 64 resamples is 0.69. Average sensitivity and specificity are 84.0% and 42.1%, respectively. This shows that predicting figure content with the available data is better than simply picking an egg at random, but no figure-guaranteeing strategy appears possible on a per-egg basis.&lt;/p&gt;
&lt;h3 id=&quot;predicting-the-content-of-a-particular-egg&quot;&gt;Predicting the Content of a Particular Egg&lt;/h3&gt;
&lt;p&gt;Suppose the egg you look at weighs 36g and, when shaken, sounds like a lot of small parts being moved. In other words:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;predict&lt;/span&gt;(m_xgb, &lt;span class=&quot;dt&quot;&gt;newdata =&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;data.frame&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;weight=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;36&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;rattles_fac=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;yes&amp;quot;&lt;/span&gt;),&lt;span class=&quot;dt&quot;&gt;type=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;prob&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##          no       yes
## 1 0.4329863 0.5670137&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Despite the rattling noises, the classifier thinks that it&#39;s slightly more likely that the content is a figure. However, when we opened this particular egg:&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-12-23-surprise/pics/car.jpg&quot; /&gt;
&lt;/center&gt;
&lt;p&gt;
&lt;p&gt;...a car. Definitely not a figure! The proof of concept disappointment was, however, quickly counteracted by the surrounding chocolate...&lt;/p&gt;
&lt;p&gt;As a standard operating procedure for your optimized future supermarket hunt, below are shown the classifier&#39;s predicted probabilities for figure content as a function of egg weight and the &lt;code&gt;rattles_fac&lt;/code&gt; variable.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-12-23-surprise/CLASSIFIEROUTPUT-1.png&quot; style=&quot;display: block; margin: auto;&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;discussion&quot;&gt;Discussion&lt;/h2&gt;
&lt;p&gt;The present post only discusses the optimal selection on a per-egg basis. One could weight &amp;amp; shake several eggs and then select the one with the highest predicted probability for containing a figure. Future research is needed to solve this sequential decision making problem in an &lt;a href=&quot;http://staff.math.su.se/hoehle/blog/2016/06/12/optimalChoice.html&quot;&gt;optimal way&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&quot;outlook&quot;&gt;Outlook&lt;/h3&gt;
&lt;p&gt;We have retained a validation sample of 10 eggs and are willing to send an unconsumed 11th element of the sample to whoever obtains the best score on this validation sample. Anyone who knows how to upload this to &lt;a href=&quot;https://www.kaggle.com&quot;&gt;kaggle&lt;/a&gt;?&lt;/p&gt;
&lt;center&gt;
We wish all readers &lt;em&gt;God jul&lt;/em&gt; and a happy new year!
&lt;/center&gt;
&lt;p&gt;
&lt;h2 id=&quot;acknowledgments&quot;&gt;Acknowledgments&lt;/h2&gt;
&lt;p&gt;Thanks to former colleagues at the Department of Statistics, University of Munich, as well as numerous statistics students in Munich and Stockholm, for contributing to the data collection. In particular we thank Alexander Jerak for his idea of optimizing figure hunting in a data driven way more than 10 years ago.&lt;/p&gt;
&lt;h2 id=&quot;literature&quot; class=&quot;unnumbered&quot;&gt;Literature&lt;/h2&gt;
&lt;div id=&quot;refs&quot; class=&quot;references&quot;&gt;
&lt;div id=&quot;ref-xgboost&quot;&gt;
&lt;p&gt;Chen, Tianqi, Tong He, Michael Benesty, Vadim Khotilovich, and Yuan Tang. 2016. &lt;em&gt;Xgboost: Extreme Gradient Boosting&lt;/em&gt;. &lt;a href=&quot;https://CRAN.R-project.org/package=xgboost&quot; class=&quot;uri&quot;&gt;https://CRAN.R-project.org/package=xgboost&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-caret&quot;&gt;
&lt;p&gt;Kuhn, Max. 2016. &lt;em&gt;Caret: Classification and Regression Training&lt;/em&gt;. &lt;a href=&quot;https://CRAN.R-project.org/package=caret&quot; class=&quot;uri&quot;&gt;https://CRAN.R-project.org/package=caret&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
        <pubDate>Fri, 23 Dec 2016 00:00:00 +0100</pubDate>
        <link>http://staff.math.su.se/hoehle/blog/2016/12/23/surprise.html</link>
        <guid isPermaLink="true">http://staff.math.su.se/hoehle/blog/2016/12/23/surprise.html</guid>
        
        <category>rstats</category>
        
        <category>stats</category>
        
        <category>programming</category>
        
        <category>juleforsøg</category>
        
        <category>classification</category>
        
        
      </item>
    
      <item>
        <title>4x3 R-Hackathoning - The Finisher&#39;s Guide</title>
        <description>&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;We present experiences from organizing a small R hackathon aimed at advancing knowledge and documentation of the R package surveillance. The hackathon was piggybacked on the ESCAIDE2016 conference visited by current and potential package users in the area of infectious disease epidemiology. The output of the hackathon is available at &lt;a href=&quot;https://surveillancer.github.io/tutorials/&quot; class=&quot;uri&quot;&gt;https://surveillancer.github.io/tutorials/&lt;/a&gt;.&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-12-12-hackinthedark/ears-1.png&quot; /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br&gt; &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width:0&quot; src=&quot;https://i.creativecommons.org/l/by-sa/4.0/88x31.png&quot;/&gt;&lt;/a&gt; This work is licensed under a &lt;a rel=&quot;license&quot;
href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt;. The markdown+Rknitr source code of this blog is available under a &lt;a href=&quot;https://www.gnu.org/licenses/gpl-3.0.html&quot;&gt;GNU General Public License (GPL v3)&lt;/a&gt; license from &lt;a href=&quot;https://github.com/hoehleatsu/hoehleatsu.github.io&quot;&gt;&lt;img src=&quot;/hoehle/blog/images/GitHub-Mark-32px.png&quot; alt=&quot;github&quot; /&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;A &lt;strong&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Hackathon&quot;&gt;hackathon&lt;/a&gt;&lt;/strong&gt; is a extreme-programming sprint-like event where people involved in software development (and beyond) meet for a short period of time with the purpose of collaborative programming, typically in the context of &lt;strong&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Open-source_software&quot;&gt;open-source software&lt;/a&gt;&lt;/strong&gt;. The word hackathon is a merger of &lt;strong&gt;hack&lt;/strong&gt; and &lt;strong&gt;marathon&lt;/strong&gt;, where &lt;a href=&quot;http://www.dictionary.com/browse/hack&quot;&gt;&lt;em&gt;hacking&lt;/em&gt;&lt;/a&gt; is to be understood as the skillful modification of computer programs (and not the malicious circumvention of security measures). Lots of good guides have been written on &lt;a href=&quot;https://hackathon.guide/&quot;&gt;how to run a successful Hackathon&lt;/a&gt;. In the area of &lt;strong&gt;infectious disease epidemiology&lt;/strong&gt;, which has been the main area of motivation for our statistical developments and implementations, very successful events (&lt;a href=&quot;https://sites.google.com/site/hackoutwiki/home&quot;&gt;hackout&lt;/a&gt;, &lt;a href=&quot;https://sites.google.com/site/hackout2/&quot;&gt;hackout2&lt;/a&gt;, &lt;a href=&quot;http://hackout3.ropensci.org/&quot;&gt;hackout3&lt;/a&gt;) have previously been organized. At a much smaller scale we wanted to ignite the energy and enthusiasm such an event spawns.&lt;/p&gt;
&lt;p&gt;As a consequence, this blog post gathers our experiences from organising a small &lt;strong&gt;4x3 hackathon&lt;/strong&gt; (4 people, 3 days) for the surveillance R-package in connection with the &lt;a href=&quot;http://ecdc.europa.eu/en/escaide/Pages/ESCAIDE.aspx&quot;&gt;ESCAIDE2016&lt;/a&gt; conference in November 2016. Our hope is that these experiences might be useful for others - even if working in very different contexts.&lt;/p&gt;
&lt;h2 id=&quot;organizing-and-running-the-hackathon&quot;&gt;Organizing and Running the Hackathon&lt;/h2&gt;
&lt;p&gt;We report on a number of practical &amp;quot;?&amp;quot; and &amp;quot;!&amp;quot; below.&lt;/p&gt;
&lt;h3 id=&quot;why&quot;&gt;Why?&lt;/h3&gt;
&lt;p&gt;Over the last several years we worked on a package for the visualization, modelling and monitoring of surveillance time series. As most of us are busy with other tasks now, it felt like a good idea to all meet in person to work a little on the package and network with potential users in order to increase awareness of the package. The 10&#39;th European Scientific Conference on Applied Infectious Disease Epidemiology (&lt;a href=&quot;http://ecdc.europa.eu/en/escaide/Pages/ESCAIDE.aspx&quot;&gt;ESCAIDE2016&lt;/a&gt;) organized by the &lt;a href=&quot;http://ecdc.europa.eu&quot;&gt;European Centre for Disease Prevention and Control&lt;/a&gt; (ECDC) in Stockholm, Sweden, 28-30 Nov 2016, with its about 600 participants, felt like the right place to be.&lt;/p&gt;
&lt;h3 id=&quot;a-cool-name&quot;&gt;A Cool Name?&lt;/h3&gt;
&lt;p&gt;Stockholm is placed on the 59th parallel north, hence, during end of November daylight is limited to approximately &lt;a href=&quot;http://www.timeanddate.com/sun/sweden/stockholm&quot;&gt;6:30 hours&lt;/a&gt;. In other words: Perfect hacking conditions. In order to honour this, &lt;strong&gt;Hack in the Dark&lt;/strong&gt; became our internal handle for the hackathon.&lt;/p&gt;
&lt;h3 id=&quot;who&quot;&gt;Who?&lt;/h3&gt;
&lt;p&gt;Hackathons come in all sizes. We decided on a mini four person hackathon of experienced R users, who all knew the package well: two former Ph.D. students who had used the package as the implementational repository for their methodological developments (one of them now being the package maintainer), a former power-user of the package and the package creator. Alternatively, we could have involved new persons in order to expand awareness of the package and increase diversity of the hackathonians, but we decided to go for the small team in order to maximize efficiency.&lt;/p&gt;
&lt;h3 id=&quot;venue&quot;&gt;Venue?&lt;/h3&gt;
&lt;p&gt;Piggybacking on an existing conference held in a large conference centre meant we did not have to worry about WLAN, food and seating. Especially when only being 4 persons.&lt;/p&gt;
&lt;h3 id=&quot;what-to-do&quot;&gt;What to do?&lt;/h3&gt;
&lt;p&gt;We started about 8 weeks before the hackathon to brainstorm using &lt;a href=&quot;https://slack.com/&quot;&gt;slack&lt;/a&gt; as a messaging system. We then created a priority matrix in &lt;a href=&quot;http://docs.google.com&quot;&gt;google docs&lt;/a&gt; allowing each of the participants to prioritize the ideas. This gave us an initial idea of what we wanted to do. Unfortunately, most of us then got pretty busy with other activities so we never managed to revisit the matrix until a couple of days before the start of the hackathon. Instead, we recapitulated matters in an &amp;quot;indian buffet process&amp;quot; meeting in Stockholm at the night before the hackathon:&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;Write i/o tutorials explaining how to get data into the package and then use package functions for cool visualizations of the data&lt;/li&gt;
&lt;li&gt;Use open European data for the tutorials - the theme of ESCAIDE2016 was after all: &lt;strong&gt;Data for action&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Make a &lt;a href=&quot;https://shiny.rstudio.com/&quot;&gt;shiny app&lt;/a&gt; to visualize the effect of various parameters choices for the surveillance algorithms implemented in the package. The best choice of configuration has been a recurrent user question throughout the years.&lt;/li&gt;
&lt;li&gt;Demo twitter surveillance by monitoring the conference hashtag &lt;code&gt;#ESCAIDE2016&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;source-code-management&quot;&gt;Source Code Management?&lt;/h3&gt;
&lt;p&gt;We chose to create an organization &lt;strong&gt;surveillancer&lt;/strong&gt; on &lt;a href=&quot;http://www.github.com&quot;&gt;github&lt;/a&gt;, which we then all joined with our individual github accounts. All new projects were then conducted by initiating new repositories. The &lt;code&gt;surveillance&lt;/code&gt; package itself is still developed on &lt;a href=&quot;http://www.r-forge.r-project.org&quot;&gt;R-Forge&lt;/a&gt; using &lt;code&gt;svn&lt;/code&gt;, but since we knew most of our work would be &lt;em&gt;using&lt;/em&gt; the surveillance package rather than &lt;em&gt;developing&lt;/em&gt; the package, we decided to keep the existing infrastructure for the package and instead develop the planned tutorials and visualizations in a new github project. This worked ok, but switching between &lt;code&gt;svn&lt;/code&gt; and &lt;code&gt;git&lt;/code&gt; for commits on different projects was not always helpful: &lt;code&gt;git commit -a&lt;/code&gt; is a useful friend if you don&#39;t know the &lt;a href=&quot;https://githowto.com/staging_changes&quot;&gt;git staging area&lt;/a&gt;...&lt;/p&gt;
&lt;h3 id=&quot;project-output-format&quot;&gt;Project Output Format?&lt;/h3&gt;
&lt;p&gt;We decided to create an R package and then use Hadley Wickham&#39;s new &lt;a href=&quot;https://hadley.github.io/pkgdown/&quot;&gt;pkgdown&lt;/a&gt; package to create a website containing all hackathon output. The above specified tutorials were then created as vignettes. An immediate advantage of this approach was that all hackathon output was bundled and that vignette code was directly available for the interested user.&lt;/p&gt;
&lt;h3 id=&quot;demo-demo-demo&quot;&gt;Demo, demo, demo!&lt;/h3&gt;
&lt;p&gt;Inspired by the extreme programming paradigm, and because we wanted to interact with the conference, we decided to demo at least once a day by posting hackathon output on twitter. Besides the outgoing publicity we also frequently demo&#39;ed internally in order to get input and suggestions. This worked pretty well - there is nothing as motivating and interactive as getting constructive input and suggestions from your table neighbour!&lt;/p&gt;
&lt;p&gt;Interaction with the other conference participants, on the other hand, was moderate. We showed parts and pieces to interested people, but in hindsight we should have aimed for a poster presentation or a related activity in order to generate more real-life awareness of the hackathon outside the virtual world of twitter.&lt;/p&gt;
&lt;h2 id=&quot;summing-up&quot;&gt;Summing Up&lt;/h2&gt;
&lt;p&gt;The three days of hackathon passed quickly, but we managed to get the four formulated outputs done.&lt;/p&gt;
&lt;p&gt;Intense software sprints are hard work, thus, it was natural that towards the end of the hackathon the concentration decreased slightly. However, phases of intense coding are perfectly supplemented by listening to scientific talks, talking to former colleagues visting the conference or sharing the passion of R with others working in the field. In particular it was nice to exchange ideas with &lt;a href=&quot;http://www.imperial.ac.uk/people/t.jombart&quot;&gt;Thibaut Jombart&lt;/a&gt;, whose &lt;a href=&quot;http://www.repidemicsconsortium.org/&quot;&gt;R Epidemics Consortium (RECON)&lt;/a&gt; project hopefully is able to bundle the R initiatives in infectious disease epidemiology a little. Besides the availability of software, the training aspect of new users (e.g. trainee epidemiologists) is also crucial. Finally, the &lt;strong&gt;aftermath&lt;/strong&gt; of the hackathon is as important as the pre-event planning: dedicated coordinators have to ensure that loose ends are wrapped up. Here, the participants&#39; enthusiasm declines quickly as other activities become higher priorities. Again, it&#39;s essential to have a clear goal of what needs to be done (e.g. a blog entry...).&lt;/p&gt;
&lt;p&gt;Altogether, code sessions such as a &lt;a href=&quot;http://staff.math.su.se/hoehle/blog/2016/08/04/outbreakEnd.html&quot;&gt;reproducibility session&lt;/a&gt; or a &lt;strong&gt;toolbox session&lt;/strong&gt; could be components for spicing up scientific conferences. For example the toolbox event could consist of a set of interested people, who on conference day 1 decide to implement a particular method useful in practice, and then demo it on the last day. Obviously, all these suggestions take time away from other conference content and certainly are more stressful than dozing of in the plenary sessions...&lt;/p&gt;
&lt;p&gt;No matter what, focus of a hackathon should also be on social aspects. It also proves wise not to ignore fresh air &amp;amp; sunlight completely. To our surprise, the 6:30 hours of daylight were at times actually quite sunny in Stockholm!&lt;/p&gt;
&lt;h3 id=&quot;visit-the-hack-in-the-dark-output&quot;&gt;Visit the Hack in the Dark Output&lt;/h3&gt;
&lt;p&gt;The output of the hackathon can be found here:&lt;/p&gt;
&lt;center&gt;
&lt;a href=&quot;https://surveillancer.github.io/tutorials/&quot; class=&quot;uri&quot;&gt;https://surveillancer.github.io/tutorials/&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;
&lt;p&gt;In order to run the accompanying code (available from github by clicking on the &amp;quot;fork me on github&amp;quot; icons), version 1.13.0 of the &lt;code&gt;surveillance&lt;/code&gt; package is needed (available from CRAN). As an appetizer to check out the hackathon &lt;a href=&quot;https://surveillancer.github.io/tutorials/&quot;&gt;site&lt;/a&gt; or the &lt;a href=&quot;https://github.com/surveillancer/tutorials&quot;&gt;code&lt;/a&gt;, here are two of our tweets demoing output during the event:&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;
First draft output of the &lt;a href=&quot;https://twitter.com/hashtag/ESCAIDE2016?src=hash&quot;&gt;#ESCAIDE2016&lt;/a&gt; surveillance &lt;a href=&quot;https://twitter.com/hashtag/rstats?src=hash&quot;&gt;#rstats&lt;/a&gt; hackathon: Visualizing &lt;a href=&quot;https://twitter.com/hashtag/opendata?src=hash&quot;&gt;#opendata&lt;/a&gt; by &lt;a href=&quot;https://twitter.com/ECDC_EU&quot;&gt;&lt;span class=&quot;citation&quot; data-cites=&quot;ECDC_EU&quot;&gt;(&lt;span class=&quot;citeproc-not-found&quot; data-reference-id=&quot;ECDC_EU&quot;&gt;&lt;strong&gt;???&lt;/strong&gt;&lt;/span&gt;)&lt;/span&gt;&lt;/a&gt; on Salmonella Agona. &lt;a href=&quot;https://twitter.com/hashtag/data4action?src=hash&quot;&gt;#data4action&lt;/a&gt; &lt;a href=&quot;https://t.co/8ApaDNF07L&quot;&gt;pic.twitter.com/8ApaDNF07L&lt;/a&gt;
&lt;/p&gt;
— Michael Höhle (@m_hoehle) &lt;a href=&quot;https://twitter.com/m_hoehle/status/803270577150631937&quot;&gt;November 28, 2016&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;
Interactive illustration of monitoring algorithms for infectious disease surveillance &lt;a href=&quot;https://twitter.com/hashtag/escaide2016?src=hash&quot;&gt;#escaide2016&lt;/a&gt; &lt;a href=&quot;https://twitter.com/hashtag/rstats?src=hash&quot;&gt;#rstats&lt;/a&gt; &lt;a href=&quot;https://t.co/qizcqqMbEJ&quot;&gt;https://t.co/qizcqqMbEJ&lt;/a&gt; &lt;a href=&quot;https://t.co/LyZujDLsF2&quot;&gt;pic.twitter.com/LyZujDLsF2&lt;/a&gt;
&lt;/p&gt;
— Dirk Schumacher (@dirk_sch) &lt;a href=&quot;https://twitter.com/dirk_sch/status/803573405660286976&quot;&gt;November 29, 2016&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;h3 id=&quot;the-future&quot;&gt;The Future&lt;/h3&gt;
&lt;p&gt;We wish you all the best for your own hackathon event. Put software on the scientific agenda!&lt;/p&gt;
&lt;h2 id=&quot;acknowledgments&quot;&gt;Acknowledgments&lt;/h2&gt;
&lt;p&gt;Thanks to &lt;a href=&quot;http://www.masalmon.eu/&quot;&gt;Maëlle Salmon&lt;/a&gt;, &lt;a href=&quot;https://www.dirk-schumacher.net/&quot;&gt;Dirk Schumacher&lt;/a&gt; and &lt;a href=&quot;http://www.imbe.med.uni-erlangen.de/cms/sebastian_meyer.html&quot;&gt;Sebastian Meyer&lt;/a&gt; for all their great work and the creative atmosphere during the hackathon! The event was implicitly supported by the Swedish Research Council as part of the project Statistical Modelling, Monitoring and Predictive Analytics against Infectious Disease Outbreaks (grant number 2015-05182_VR).&lt;/p&gt;
&lt;div id=&quot;refs&quot; class=&quot;references&quot;&gt;

&lt;/div&gt;
</description>
        <pubDate>Mon, 12 Dec 2016 00:00:00 +0100</pubDate>
        <link>http://staff.math.su.se/hoehle/blog/2016/12/12/hackinthedark.html</link>
        <guid isPermaLink="true">http://staff.math.su.se/hoehle/blog/2016/12/12/hackinthedark.html</guid>
        
        <category>rstats</category>
        
        <category>stats</category>
        
        <category>programming</category>
        
        
      </item>
    
      <item>
        <title>Better Confidence Intervals for Quantiles</title>
        <description>&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
\newcommand{\bm}[1]{\boldsymbol{\mathbf{#1}}}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\]&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;We discuss the computation of confidence intervals for the median or any other quantile in R. In particular we are interested in the interpolated order statistic approach suggested by &lt;span class=&quot;citation&quot; data-cites=&quot;hettmansperger_sheather1986&quot;&gt;Hettmansperger and Sheather (1986)&lt;/span&gt; and &lt;span class=&quot;citation&quot; data-cites=&quot;nyblom1992&quot;&gt;Nyblom (1992)&lt;/span&gt;. In order to make the methods available to a greater audience we provide an implementation of these methods in the R package &lt;code&gt;quantileCI&lt;/code&gt; and a small simulation study is conducted to show that these intervals indeed have a very good coverage. The study also shows that these intervals perform better than the currently available approaches in R. We therefore propose that these intervals should be used more in the future!&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-10-23-quantileCI/FIRSTPICTURE-1.png&quot; /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br&gt; &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width:0&quot; src=&quot;https://i.creativecommons.org/l/by-sa/4.0/88x31.png&quot;/&gt;&lt;/a&gt; This work is licensed under a &lt;a rel=&quot;license&quot;
href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt;. The markdown+Rknitr source code of this blog is available under a &lt;a href=&quot;https://www.gnu.org/licenses/gpl-3.0.html&quot;&gt;GNU General Public License (GPL v3)&lt;/a&gt; license from &lt;a href=&quot;https://github.com/hoehleatsu/hoehleatsu.github.io&quot;&gt;&lt;img src=&quot;/hoehle/blog/images/GitHub-Mark-32px.png&quot; alt=&quot;github&quot; /&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Statistics 101 teaches that for a distribution, possibly contaminated with outliers, a robust measure of the central tendency is the median. Not knowing this fact can make your analysis worthy to report in the &lt;a href=&quot;http://www.sueddeutsche.de/wirtschaft/heilbronn-dieser-mann-ist-so-reich-dass-statistiken-seines-wohnorts-wertlos-sind-1.2705044&quot;&gt;newspaper&lt;/a&gt; (&lt;a href=&quot;https://translate.google.com/translate?sl=de&amp;amp;tl=en&amp;amp;js=y&amp;amp;prev=_t&amp;amp;hl=en&amp;amp;ie=UTF-8&amp;amp;u=http%3A%2F%2Fwww.sueddeutsche.de%2Fwirtschaft%2Fheilbronn-dieser-mann-ist-so-reich-dass-statistiken-seines-wohnorts-wertlos-sind-1.2705044&amp;amp;edit-text=&quot;&gt;Google translate&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Higher quantiles of a distribution also have a long history as threshold for when to declare an observation an outlier. For example, growth curves for children illustrate how the quantiles of, e.g., &lt;a href=&quot;http://www.cdc.gov/growthcharts/data/set1clinical/cj41l024.pdf&quot;&gt;the BMI distribution develop by age&lt;/a&gt;. &lt;strong&gt;Obesity&lt;/strong&gt; is then for children defined as exceedance of the &lt;a href=&quot;http://www.who.int/growthref/bmifa_girls_z_5_19_labels.pdf?ua=1&quot;&gt;97.7% quantile&lt;/a&gt; of the distribution at a particular age. Quantile regression is a non-parametric method to compute such curves and the statistical community has been quite busy lately investigating new ways to compute such quantile regressions models.&lt;/p&gt;
&lt;p&gt;The focus of this blog post is nevertheless the simplest setting: Given an iid. sample &lt;span class=&quot;math inline&quot;&gt;\(\bm{x}\)&lt;/span&gt; of size &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; from a univariate and absolutely continuous distribution &lt;span class=&quot;math inline&quot;&gt;\(F\)&lt;/span&gt;, how does one compute an estimate for the &lt;span class=&quot;math inline&quot;&gt;\(p\)&lt;/span&gt;-Quantile of &lt;span class=&quot;math inline&quot;&gt;\(F\)&lt;/span&gt; together with a corresponding two-sided &lt;span class=&quot;math inline&quot;&gt;\((1-\alpha)\cdot 100\%\)&lt;/span&gt; confidence interval for it?&lt;/p&gt;
&lt;h3 id=&quot;the-point-estimate&quot;&gt;The Point Estimate&lt;/h3&gt;
&lt;p&gt;Computing the quantile in a sample with statistical software is discussed in the excellent survey of &lt;span class=&quot;citation&quot; data-cites=&quot;hyndman_fan1996&quot;&gt;Hyndman and Fan (1996)&lt;/span&gt;. The simplest estimator is based on the &lt;a href=&quot;https://en.wikipedia.org/wiki/Order_statistic&quot;&gt;order statistic&lt;/a&gt; of the sample, i.e. &lt;span class=&quot;math inline&quot;&gt;\(x_{(1)} &amp;lt; x_{(2)} &amp;lt; \cdots &amp;lt; x_{(n)}\)&lt;/span&gt;. &lt;span class=&quot;math display&quot;&gt;\[
\hat{x}_p = \min_{k} \left\{\hat{F}(x_{(k)}) \geq p\right\} = x_{(\lceil n \cdot p\rceil)},
\]&lt;/span&gt; where &lt;span class=&quot;math inline&quot;&gt;\(\hat{F}\)&lt;/span&gt; is the &lt;a href=&quot;https://en.wikipedia.org/wiki/Empirical_distribution_function&quot;&gt;empirical cumulative distribution&lt;/a&gt; function of the sample. Since &lt;span class=&quot;math inline&quot;&gt;\(\hat{F}\)&lt;/span&gt; has jumps of size &lt;span class=&quot;math inline&quot;&gt;\(1/n\)&lt;/span&gt; the actual value of &lt;span class=&quot;math inline&quot;&gt;\(\hat{F}(\hat{x}_{p})\)&lt;/span&gt; can end up being somewhat larger than the desired &lt;span class=&quot;math inline&quot;&gt;\(p\)&lt;/span&gt;. Therefore, &lt;span class=&quot;citation&quot; data-cites=&quot;hyndman_fan1996&quot;&gt;Hyndman and Fan (1996)&lt;/span&gt; prefer estimators interpolating between the two values of the order statistic with &lt;span class=&quot;math inline&quot;&gt;\(\hat{F}\)&lt;/span&gt; just below and just above &lt;span class=&quot;math inline&quot;&gt;\(p\)&lt;/span&gt;. It is interesting that even &lt;a href=&quot;http://robjhyndman.com/hyndsight/sample-quantiles-20-years-later/&quot;&gt;20 years after&lt;/a&gt;, there still is no universally accepted way to do this in different statistical software and the &lt;code&gt;type&lt;/code&gt; argument of the &lt;code&gt;quantile&lt;/code&gt; function in R has been a close friend when comparing results with SPSS or Stata users. In what follows we will, however, stick with the simple &lt;span class=&quot;math inline&quot;&gt;\(x_{(\lceil n \cdot p\rceil)}\)&lt;/span&gt; estimator stated above.&lt;/p&gt;
&lt;p&gt;Below is illustrated how one would use R to compute the, say, the 80% quantile of a sample using the above estimator. We can compute this either manually or using the &lt;code&gt;quantile&lt;/code&gt; function with &lt;code&gt;type=1&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Make a tiny artificial dataset, say, the BMI z-score of 25 children
&lt;span class=&quot;kw&quot;&gt;sort&lt;/span&gt;(x &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;rnorm&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;25&lt;/span&gt;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##  [1] -1.44090165 -1.40318433 -1.21953433 -0.95029549 -0.90398754 -0.66095890 -0.47801787
##  [8] -0.43976149 -0.36174823 -0.34116984 -0.33047704 -0.31576897 -0.28904542 -0.03789851
## [15] -0.03764990 -0.03377687  0.22121130  0.30331291  0.43716773  0.47435054  0.60897987
## [22]  0.64611097  1.20086374  1.52483138  2.67862782&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Define the quantile we want to consider
p &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.8&lt;/span&gt;
##Since we know the true distribution we can easily find the true quantile
(x_p &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;qnorm&lt;/span&gt;(p))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8416212&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Compute the estimates using the quantile function and manually
&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;quantile=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;quantile&lt;/span&gt;(x, &lt;span class=&quot;dt&quot;&gt;type=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;prob=&lt;/span&gt;p), &lt;span class=&quot;dt&quot;&gt;manual=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;sort&lt;/span&gt;(x)[&lt;span class=&quot;kw&quot;&gt;ceiling&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;length&lt;/span&gt;(x)*p)])&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## quantile.80%       manual 
##    0.4743505    0.4743505&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;confidence-interval-for-the-quantile&quot;&gt;Confidence interval for the quantile&lt;/h3&gt;
&lt;p&gt;Besides the point estimate &lt;span class=&quot;math inline&quot;&gt;\(\hat{x}_p\)&lt;/span&gt; we also would like to report a two-sided &lt;span class=&quot;math inline&quot;&gt;\((1-\alpha)\cdot 100\%\)&lt;/span&gt; confidence interval &lt;span class=&quot;math inline&quot;&gt;\((x_p^{\text{l}}, x_p^{\text{u}})\)&lt;/span&gt; for the desired population quantile. The interval &lt;span class=&quot;math inline&quot;&gt;\((x_p^{\text{l}}, x_p^{\text{u}})\)&lt;/span&gt; should, hence, fulfill the following condition: &lt;span class=&quot;math display&quot;&gt;\[
P( (x_p^{\text{l}}, x_p^{\text{u}}) \ni x_p) = 1 - \alpha,
\]&lt;/span&gt; where we have used the &amp;quot;backwards&amp;quot; &lt;span class=&quot;math inline&quot;&gt;\(\in\)&lt;/span&gt; to stress the fact that it&#39;s the interval which is random. Restricting the limits of this confidence intervals to be &lt;strong&gt;one of the realisations from the order statistics&lt;/strong&gt; implies that we need to find indices &lt;span class=&quot;math inline&quot;&gt;\(d\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(e\)&lt;/span&gt; with &lt;span class=&quot;math inline&quot;&gt;\(d&amp;lt;e\)&lt;/span&gt; s.t. &lt;span class=&quot;math display&quot;&gt;\[
P( x_{(d)} \leq x_p \leq x_{(e)}) \geq 1 - \alpha.
\]&lt;/span&gt; Note that it may not be possible to achieve the desired coverage exactly in this case. For now we prefer the conservative choice of having to attain &lt;strong&gt;at least&lt;/strong&gt; the desired coverage. Note that for &lt;span class=&quot;math inline&quot;&gt;\(1\leq r \leq n\)&lt;/span&gt; we have &lt;span class=&quot;math display&quot;&gt;\[
\begin{align*}
P( x_{r} \leq x_p) &amp;amp;= P(\text{at least $r$ observations are smaller than or equal to $x_p$}) \\
      &amp;amp;= \sum_{k=r}^{n} P(\text{exactly $k$ observations are smaller than or equal to $x_p$}) \\
      &amp;amp;= \sum_{k=r}^{n} {n \choose k} P(X \leq x_p)^k (1-P(X \leq x_p))^{n-k} \\
      &amp;amp;= \sum_{k=r}^{n} {n \choose k} p^k (1-p)^{n-k} \\
      &amp;amp;= 1 - \sum_{k=0}^{r-1} {n \choose k} p^k (1-p)^{n-k}
\end{align*}
\]&lt;/span&gt; In principle, we could now try out all possible &lt;span class=&quot;math inline&quot;&gt;\((d,e)\)&lt;/span&gt; combinations and for each interval investigate, whether it has the desired &lt;span class=&quot;math inline&quot;&gt;\(\geq 1-\alpha/2\)&lt;/span&gt; property. If several combinations achieve this criterion we would, e.g., take the interval having minimal length. This is what the &lt;code&gt;MKmisc::quantileCI&lt;/code&gt; function does. However, the number of pairs to investigate is of order &lt;span class=&quot;math inline&quot;&gt;\(O(n^2)\)&lt;/span&gt;, which for large &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; quickly becomes lengthy to compute. Instead, we compute an &lt;strong&gt;equi-tailed confidence interval&lt;/strong&gt; by finding two one-sided &lt;span class=&quot;math inline&quot;&gt;\(1-\alpha/2\)&lt;/span&gt; intervals, i.e. we find &lt;span class=&quot;math inline&quot;&gt;\(d\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(e\)&lt;/span&gt; s.t. &lt;span class=&quot;math inline&quot;&gt;\(P(x_{(d)} \leq x_p) = 1-\alpha/2\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(P(x_p \geq x_{(e)}) = 1-\alpha/2\)&lt;/span&gt;. In other words,&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
\begin{align*}
d &amp;amp;= \argmax P(x_{(r)} \leq x_p) \geq 1 - \frac{\alpha}{2} \\
  &amp;amp;= \texttt{qbinom(alpha/2, size=n, prob=p)} \\
e &amp;amp;= \argmin P(x_p \geq x_{(r)}) \geq 1 - \frac{\alpha}{2} \\
  &amp;amp;= \texttt{qbinom(1-alpha/2, size=n, prob=p) + 1}
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Note that the problem can arise, that the above solutions are zero or &lt;span class=&quot;math inline&quot;&gt;\(n+1\)&lt;/span&gt;, respectively. In this case one has to decide how to proceed. For an illustration of the above in case of the median see the &lt;a href=&quot;http://freakonometrics.hypotheses.org/4199&quot;&gt;post&lt;/a&gt; by &lt;a href=&quot;https://twitter.com/freakonometrics&quot;&gt;@freakonometrics&lt;/a&gt;. Also note that the &lt;code&gt;qbinom&lt;/code&gt; function uses the &lt;a href=&quot;https://en.wikipedia.org/wiki/Cornish%E2%80%93Fisher_expansion&quot;&gt;Cornish-Fisher Expansion&lt;/a&gt; to come up with an initial guess for the quantile, which is then refined by a numerical search. In other words, the function is of order &lt;span class=&quot;math inline&quot;&gt;\(O(1)\)&lt;/span&gt; and will, hence, be fast even for large &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;When it comes to confidence intervals for quantiles the set of alternative implementations in R is extensive. &lt;a href=&quot;http://finzi.psych.upenn.edu/cgi-bin/namazu.cgi?query=confidence+interval+for+quantiles&amp;amp;max=100&amp;amp;result=normal&amp;amp;sort=score&amp;amp;idxname=functions&amp;amp;idxname=vignettes&amp;amp;idxname=views&quot;&gt;Searching for this on CRAN&lt;/a&gt;, we found the following functionality:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col style=&quot;width: 24%&quot; /&gt;
&lt;col style=&quot;width: 12%&quot; /&gt;
&lt;col style=&quot;width: 63%&quot; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&quot;header&quot;&gt;
&lt;th&gt;Package::Function&lt;/th&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;Version&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;&lt;a href=&quot;http://finzi.psych.upenn.edu/R/library/MKmisc/html/quantileCI.html&quot;&gt;&lt;code&gt;MKMisc::quantileCI&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;0.993&lt;/td&gt;
&lt;td&gt;Implements an exact but very slow &lt;span class=&quot;math inline&quot;&gt;\(O(n^2)\)&lt;/span&gt; search as well as an asymptotic method approximating the exact procedure. Due to the method being slow it is not investigated further, but looking at it an &lt;code&gt;Rcpp&lt;/code&gt; implementation of the nested loop might be able to speed up the performance substantially.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;&lt;a href=&quot;http://finzi.psych.upenn.edu/R/library/jmuOutlier/html/quantileCI.html&quot;&gt;&lt;code&gt;jmuOutlier::quantileCI&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;1.1&lt;/td&gt;
&lt;td&gt;Implements the exact method.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;&lt;a href=&quot;http://finzi.psych.upenn.edu/R/library/EnvStats/html/eqnpar.html&quot;&gt;&lt;code&gt;envStats::eqnpar&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;2.1.1&lt;/td&gt;
&lt;td&gt;implements both an exact and an asymptotic interval&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;&lt;a href=&quot;http://finzi.psych.upenn.edu/R/library/asht/html/quantileTest.html&quot;&gt;&lt;code&gt;asht::quantileTest&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;0.6&lt;/td&gt;
&lt;td&gt;also implements an exact method&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;&lt;a href=&quot;http://finzi.psych.upenn.edu/R/library/Qtools/html/confint.midquantile.html&quot;&gt;&lt;code&gt;Qtools::confint.midquantile&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;1.1&lt;/td&gt;
&lt;td&gt;operates on the mid-quantile (whatever that is). The method is not investigated further.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;
&lt;p&gt;There might even be more, but for now we are satisfied comparing just the above mentioned procedures:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;as.numeric&lt;/span&gt;(MKmisc::&lt;span class=&quot;kw&quot;&gt;quantileCI&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;x=&lt;/span&gt;x, &lt;span class=&quot;dt&quot;&gt;prob=&lt;/span&gt;p, &lt;span class=&quot;dt&quot;&gt;method=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;exact&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;conf.level=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.95&lt;/span&gt;)$CI)
&lt;span class=&quot;kw&quot;&gt;as.numeric&lt;/span&gt;(MKmisc::&lt;span class=&quot;kw&quot;&gt;quantileCI&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;x=&lt;/span&gt;x, &lt;span class=&quot;dt&quot;&gt;prob=&lt;/span&gt;p, &lt;span class=&quot;dt&quot;&gt;method=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;asymptotic&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;conf.level=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.95&lt;/span&gt;)$CI)
&lt;span class=&quot;kw&quot;&gt;as.numeric&lt;/span&gt;(jmuOutlier::&lt;span class=&quot;kw&quot;&gt;quantileCI&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;x=&lt;/span&gt;x, &lt;span class=&quot;dt&quot;&gt;probs=&lt;/span&gt;p, &lt;span class=&quot;dt&quot;&gt;conf.level=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.95&lt;/span&gt;)[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;lower&amp;quot;&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;upper&amp;quot;&lt;/span&gt;)])
&lt;span class=&quot;kw&quot;&gt;as.numeric&lt;/span&gt;(EnvStats::&lt;span class=&quot;kw&quot;&gt;eqnpar&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;x=&lt;/span&gt;x, &lt;span class=&quot;dt&quot;&gt;p=&lt;/span&gt;p, &lt;span class=&quot;dt&quot;&gt;ci=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;ci.method=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;exact&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;approx.conf.level=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.95&lt;/span&gt;)$interval$limits)
&lt;span class=&quot;kw&quot;&gt;as.numeric&lt;/span&gt;(EnvStats::&lt;span class=&quot;kw&quot;&gt;eqnpar&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;x=&lt;/span&gt;x, &lt;span class=&quot;dt&quot;&gt;p=&lt;/span&gt;p, &lt;span class=&quot;dt&quot;&gt;ci=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;ci.method=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;normal.approx&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;approx.conf.level=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.95&lt;/span&gt;)$interval$limits)
&lt;span class=&quot;kw&quot;&gt;as.numeric&lt;/span&gt;(asht::&lt;span class=&quot;kw&quot;&gt;quantileTest&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;x=&lt;/span&gt;x,&lt;span class=&quot;dt&quot;&gt;p=&lt;/span&gt;p,&lt;span class=&quot;dt&quot;&gt;conf.level=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.95&lt;/span&gt;)$conf.int)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## [1] -0.03377687  1.52483138
## [1] -0.03377687  1.52483138
## [1] -0.03377687  1.52483138
## [1] 0.2212113 2.6786278
## [1] -0.03377687  1.52483138
## [1] -0.03377687  2.67862782&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An impressive number of similar, but yet, different results! To add to the confusion here is our take at this as developed in the &lt;code&gt;quantileCI&lt;/code&gt; package available from github:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;devtools::&lt;span class=&quot;kw&quot;&gt;install_github&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;hoehleatsu/quantileCI&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The package provides three methods for computing confidence intervals for quantiles:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;quantileCI::&lt;span class=&quot;kw&quot;&gt;quantile_confint_nyblom&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;x=&lt;/span&gt;x, &lt;span class=&quot;dt&quot;&gt;p=&lt;/span&gt;p, &lt;span class=&quot;dt&quot;&gt;conf.level=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.95&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;interpolate=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;FALSE&lt;/span&gt;)
quantileCI::&lt;span class=&quot;kw&quot;&gt;quantile_confint_nyblom&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;x=&lt;/span&gt;x, &lt;span class=&quot;dt&quot;&gt;p=&lt;/span&gt;p, &lt;span class=&quot;dt&quot;&gt;conf.level=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.95&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;interpolate=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;)
quantileCI::&lt;span class=&quot;kw&quot;&gt;quantile_confint_boot&lt;/span&gt;(x, &lt;span class=&quot;dt&quot;&gt;p=&lt;/span&gt;p, &lt;span class=&quot;dt&quot;&gt;conf.level=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.95&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;R=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;999&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;type=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## [1] -0.03377687  2.67862782
## [1] 0.07894831 1.54608644
## [1] -0.0376499  1.2008637&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first procedure with &lt;code&gt;interpolate=FALSE&lt;/code&gt; implements the previously explained exact approach, which is also implemented in some of the other packages. However, when the &lt;code&gt;interpolate&lt;/code&gt; argument is set to &lt;code&gt;TRUE&lt;/code&gt; (the default), an additional interpolation step between the two neighbouring order statistics is performed as suggested in the work of &lt;span class=&quot;citation&quot; data-cites=&quot;nyblom1992&quot;&gt;Nyblom (1992)&lt;/span&gt;, which extends work for the median by &lt;span class=&quot;citation&quot; data-cites=&quot;hettmansperger_sheather1986&quot;&gt;Hettmansperger and Sheather (1986)&lt;/span&gt; to arbitrary quantiles. It generates intervals of the form:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
\left( (1-\lambda_1) x_{(d)} + \lambda_1 x_{(d+1)}, (1-\lambda_2) x_{(e-1)} + \lambda_1 x_{(e)} \right)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;with &lt;span class=&quot;math inline&quot;&gt;\(0 \leq \lambda_1, \lambda_2 \leq 1\)&lt;/span&gt; chosen appropriately to get as close to the desired coverage as possible without knowing the exact underlying distribution - see the paper for details.&lt;/p&gt;
&lt;p&gt;The last call in the above is to a basic bootstrap procedure, which resamples the data with replacement, computes the quantile using &lt;code&gt;type=1&lt;/code&gt; and then reports the 2.5% and 97.5% percentiles of this bootstrapped distribution. Such percentiles of the basic bootstrap are a popular way to get confidence intervals for the quantile, e.g., this is what we have used in &lt;span class=&quot;citation&quot; data-cites=&quot;hoehle_hoehle2009&quot;&gt;Höhle and Höhle (2009)&lt;/span&gt; for reporting the 95% quantile of the absolute difference in height at so called &lt;strong&gt;check points&lt;/strong&gt; in the assessment of accuracy for a digital elevation model (DEM) in photogrammetry. However, the coverage of the percentile bootstrap procedure is not without problems, because the convergence rate as a function of the number of replicates &lt;span class=&quot;math inline&quot;&gt;\(r\)&lt;/span&gt; is only of order &lt;span class=&quot;math inline&quot;&gt;\(O(r^{-\frac{1}{2}})\)&lt;/span&gt; for quantiles (&lt;span class=&quot;citation&quot; data-cites=&quot;falk_kaufmann1991&quot;&gt;Falk and Kaufmann (1991)&lt;/span&gt;). As a trade-off between accuracy and speed we use &lt;span class=&quot;math inline&quot;&gt;\(R=999\)&lt;/span&gt; throughout this post.&lt;/p&gt;
&lt;h2 id=&quot;simulation-study-to-determine-coverage&quot;&gt;Simulation Study to Determine Coverage&lt;/h2&gt;
&lt;p&gt;We write a function, which for a given sample &lt;code&gt;x&lt;/code&gt; computes two-sided confidence intervals for the p-Quantile using a selection of the above described procedures:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;quantile_confints&lt;/span&gt;(x, &lt;span class=&quot;dt&quot;&gt;p=&lt;/span&gt;p, &lt;span class=&quot;dt&quot;&gt;conf.level=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.95&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##   jmuOutlier_exact EnvStats_exact EnvStats_asymp asht_quantTest nyblom_exact
## 1      -0.03377687      0.2212113    -0.03377687    -0.03377687  -0.03377687
## 2       1.52483138      2.6786278     1.52483138     2.67862782   2.67862782
##   nyblom_interp        boot
## 1    0.07894831 -0.03377687
## 2    1.54608644  1.26565726&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In order to evaluate the various methods and implementations we conduct a Monte Carlo simulation study to assess each methods&#39; coverage. For this purpose we write a small wrapper function to conduct the simulation study using &lt;a href=&quot;http://gforge.se/2015/02/how-to-go-parallel-in-r-basics-tips/&quot;&gt;parallel computation&lt;/a&gt;. The function wraps the &lt;code&gt;quantileCI::qci_coverage_one_sim&lt;/code&gt; function, which lets the user define a simulation scenario (true underlying distribution, size of the sample, etc.), then applies all confidence interval methods gathered in the above &lt;code&gt;quantile_confints&lt;/code&gt; and finally assesses whether each confidence interval covers the true value or not.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;simulate.coverage_qci &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;n,&lt;span class=&quot;dt&quot;&gt;p=&lt;/span&gt;p,&lt;span class=&quot;dt&quot;&gt;conf.level=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.9&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;nSim=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;10e3&lt;/span&gt;, ...) {
  ##Windows users: change to below lapply function or use snow.
  ##lapplyFun &amp;lt;- function(x, mc.cores=NA, ...) pblapply(x, ...)
  lapplyFun &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;parallel::mclapply

  sims &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;dplyr::&lt;span class=&quot;kw&quot;&gt;bind_rows&lt;/span&gt;(
    &lt;span class=&quot;kw&quot;&gt;lapplyFun&lt;/span&gt;(1L:nSim, function(i) {
      quantileCI::&lt;span class=&quot;kw&quot;&gt;qci_coverage_one_sim&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;qci_fun=&lt;/span&gt;quantile_confints, &lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;n,&lt;span class=&quot;dt&quot;&gt;p=&lt;/span&gt;p,&lt;span class=&quot;dt&quot;&gt;conf.level=&lt;/span&gt;conf.level,...)
    }, &lt;span class=&quot;dt&quot;&gt;mc.cores =&lt;/span&gt; parallel::&lt;span class=&quot;kw&quot;&gt;detectCores&lt;/span&gt;() -&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)
  ) %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;summarise_each&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;funs&lt;/span&gt;(mean))
  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt;(sims)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id=&quot;simulation-1&quot;&gt;Simulation 1&lt;/h4&gt;
&lt;p&gt;We can now compare the coverage of the different implementation for the particular &lt;code&gt;n&lt;/code&gt;=25 and &lt;code&gt;p&lt;/code&gt;=0.8 setting:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;simulate.coverage_qci&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;25&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;p=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.8&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;conf.level=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.95&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##   jmuOutlier_exact EnvStats_exact EnvStats_asymp asht_quantTest nyblom_exact
## 1           0.9536         0.9473         0.9536         0.9786       0.9786
##   nyblom_interp   boot
## 1        0.9464 0.9154&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that the &lt;code&gt;nyblom_interp&lt;/code&gt; procedure is closer to the nominal coverage than it&#39;s exact cousin &lt;code&gt;nyblom_exact&lt;/code&gt; and the worst results are obtained by the bootstrap percentile method. We also note that the results of the &lt;code&gt;jmuOutlier_exact&lt;/code&gt; method appear to deviate from &lt;code&gt;asht_quantTest&lt;/code&gt; as well as &lt;code&gt;nyblom_exact&lt;/code&gt;, which is surprising, because they should implement the same approach.&lt;/p&gt;
&lt;h4 id=&quot;simulation-2&quot;&gt;Simulation 2&lt;/h4&gt;
&lt;p&gt;As a further test-case we consider the situation for the median in a smaller sample:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;simulate.coverage_qci&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;11&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;p=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.5&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;conf.level=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.95&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##   jmuOutlier_exact EnvStats_exact EnvStats_asymp asht_quantTest nyblom_exact
## 1           0.9873         0.9352          0.961         0.9873       0.9873
##   nyblom_interp   boot hs_interp
## 1        0.9462 0.9352    0.9462&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We note that the &lt;code&gt;EnvStats_exact&lt;/code&gt; procedure again has a lower coverage than the nominal required level, it must therefore implement a slightly different procedure than expected. That coverage is less than the nominal for an &lt;em&gt;exact&lt;/em&gt; method is, however, still somewhat &lt;em&gt;surprising&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;In this study for the median, the original &lt;span class=&quot;citation&quot; data-cites=&quot;hettmansperger_sheather1986&quot;&gt;Hettmansperger and Sheather (1986)&lt;/span&gt; procedure implemented in &lt;code&gt;quantileCI&lt;/code&gt; as function &lt;code&gt;median_confint_hs&lt;/code&gt; is also included in the comparison (&lt;code&gt;hs_interp&lt;/code&gt;). Note that the &lt;span class=&quot;citation&quot; data-cites=&quot;nyblom1992&quot;&gt;Nyblom (1992)&lt;/span&gt; procedure for &lt;span class=&quot;math inline&quot;&gt;\(p=\frac{1}{2}\)&lt;/span&gt; just boils down to this approach. Since the neighbouring order statistics are combined using a weighted mean, the actual level is just close to the nominal level. It can, as observed for the above setting, be slightly lower than the nominal level. The bootstrap method again doesn&#39;t look too impressive.&lt;/p&gt;
&lt;h4 id=&quot;simulation-3&quot;&gt;Simulation 3&lt;/h4&gt;
&lt;p&gt;We finally also add one of the scenarios from Table 1 of the &lt;span class=&quot;citation&quot; data-cites=&quot;nyblom1992&quot;&gt;Nyblom (1992)&lt;/span&gt; paper, which allows us to check our implementation against the numerical integration performed in the paper to assess coverage.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;simulate.coverage_qci&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;11&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;p=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.25&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;conf.level=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.90&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##   jmuOutlier_exact EnvStats_exact EnvStats_asymp asht_quantTest nyblom_exact
## 1           0.9249         0.7722         0.8472         0.9249       0.9249
##   nyblom_interp   boot
## 1        0.9033 0.8848&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In particular the results of &lt;code&gt;EnvStats_exact&lt;/code&gt; look disturbing. The coverage of the interpolated order statistic approach again looks convincing.&lt;/p&gt;
&lt;h4 id=&quot;simulation-4&quot;&gt;Simulation 4&lt;/h4&gt;
&lt;p&gt;Finally, a setup with a large sample, but now with the t-distribution with one degree of freedom:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;simulate.coverage_qci&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;101&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;p=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.9&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;rfunc=&lt;/span&gt;rt, &lt;span class=&quot;dt&quot;&gt;qfunc=&lt;/span&gt;qt, &lt;span class=&quot;dt&quot;&gt;conf.level=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.95&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;df=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##   jmuOutlier_exact EnvStats_exact EnvStats_asymp asht_quantTest nyblom_exact
## 1           0.9553         0.9343         0.9553         0.9553       0.9553
##   nyblom_interp   boot
## 1        0.9502 0.9306&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again the interpolation method provides the most convincing results. The bootstrap on the other hand again has the worst coverage, a larger &lt;span class=&quot;math inline&quot;&gt;\(R\)&lt;/span&gt; might have helped here, but would have made the simulation study even more time consuming.&lt;/p&gt;
&lt;h1 id=&quot;conclusion-and-future-work&quot;&gt;Conclusion and Future Work&lt;/h1&gt;
&lt;p&gt;Can we based on the above recommend one procedure to use in practice? Well, even though the simulation study is small, the exact &lt;code&gt;EnvStats::eqnpar&lt;/code&gt; approach appears to yield below nominal coverage intervals, sometimes even substantially, and hence is not to be recommended. On the other hand, &lt;code&gt;jmuOutlier_exact&lt;/code&gt;, &lt;code&gt;asht_quantTest&lt;/code&gt;, and &lt;code&gt;nyblom_exact&lt;/code&gt; in all four cases provide above nominal level coverage, i.e. the intervals are conservative in as much as they are too wide. Also slightly disturbing is that the results of the exact confidence interval methods varied somewhat between the different R implementations. Part of the differences arise from handling the discreteness of the procedure as well as the edge cases differently. The basic percentile bootstrap method is a simple approach, providing acceptable, but not optimal coverage and also depends in part on &lt;span class=&quot;math inline&quot;&gt;\(R\)&lt;/span&gt;. In particular for very large &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; or for a large number of replication in the simulation study, the method with a large &lt;span class=&quot;math inline&quot;&gt;\(R\)&lt;/span&gt; can be slow. Suggestions exist in the literature on how to improve the speed of coverage convergence by smoothing (see, e.g., &lt;span class=&quot;citation&quot; data-cites=&quot;deangelis_etal1993&quot;&gt;De Angelis, Hall, and Young (1993)&lt;/span&gt;), but such work is beyond the scope of this post.&lt;/p&gt;
&lt;p&gt;The &lt;span class=&quot;citation&quot; data-cites=&quot;hettmansperger_sheather1986&quot;&gt;Hettmansperger and Sheather (1986)&lt;/span&gt; and &lt;span class=&quot;citation&quot; data-cites=&quot;nyblom1992&quot;&gt;Nyblom (1992)&lt;/span&gt; method, respectively, provide very good coverage close to the nominal level. The method is fast to compute, available through the &lt;code&gt;quantileCI&lt;/code&gt; R package and would be our recommendation to use in practice.&lt;/p&gt;
&lt;p&gt;Altogether, we summarise our findings as follows: &lt;strong&gt;More confidence in confidence intervals for quantiles!&lt;/strong&gt; and let the following picture illustrating 90% confidence intervals for the 80% quantile of the standard normal distribution based on the above sample of size &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt;=25 say this in less than 1000 words.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-10-23-quantileCI/FIRSTPICTURE-1.png&quot; style=&quot;display: block; margin: auto;&quot; /&gt;&lt;/p&gt;
&lt;h1 id=&quot;appendix&quot;&gt;Appendix&lt;/h1&gt;
&lt;p&gt;Given PDF &lt;span class=&quot;math inline&quot;&gt;\(f\)&lt;/span&gt; and CDF &lt;span class=&quot;math inline&quot;&gt;\(F\)&lt;/span&gt; of the underlying distribution, the coverage probability of the one sided Nyblom &lt;span class=&quot;math inline&quot;&gt;\((1-\alpha/2)\cdot 100\%\)&lt;/span&gt; confidence interval &lt;span class=&quot;math inline&quot;&gt;\((1-\lambda) x_{(r)} + \lambda x_{(r+1)}\)&lt;/span&gt; for &lt;span class=&quot;math inline&quot;&gt;\(x_p\)&lt;/span&gt; can be found as follows: Let &lt;span class=&quot;math inline&quot;&gt;\(z = (1-\lambda) x_{(r)} + \lambda x_{(r+1)}\)&lt;/span&gt;. If the considered interval is a lower-confidence interval, we are interested in finding &lt;span class=&quot;math inline&quot;&gt;\(P( z \leq x_p)=\int_{-\infty}^{x_p} f_z(z) dz\)&lt;/span&gt;. Here, the PDF of &lt;span class=&quot;math inline&quot;&gt;\(z\)&lt;/span&gt; is found as&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
f_z(z) = \int_{-\infty}^{z} f_{x_{(r)},x_{(r+1)}}( x_{(r)},
x_{(r+1)}^*) dx_{(r)}, \quad\text{where}\quad x_{(r+1)}^* = \frac{z-(1-\lambda)x_{(r)}}{\lambda}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The &lt;a href=&quot;https://en.wikipedia.org/wiki/Order_statistic#The_joint_distribution_of_the_order_statistics_of_an_absolutely_continuous_distribution&quot;&gt;joint distribution of the order statistic&lt;/a&gt; is here&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
f_{x_{(r)},x_{(r+1)}}( x_{(r)},
x_{(r+1)}) = \frac{n!}{(r-1)!(n-r-1)!} F(x_{(r)})^{r-1}
\left( 1- F(x_{(r+1)})\right)^{n-r-1} f(x_{(r+1)}) f(x_{(r)}).
\]&lt;/span&gt; The two nested integrals can be solved by numerical integration using, e.g., the &lt;code&gt;integral&lt;/code&gt; function.&lt;/p&gt;
&lt;h1 id=&quot;references&quot; class=&quot;unnumbered&quot;&gt;References&lt;/h1&gt;
&lt;div id=&quot;refs&quot; class=&quot;references&quot;&gt;
&lt;div id=&quot;ref-deangelis_etal1993&quot;&gt;
&lt;p&gt;De Angelis, D., P. Hall, and G. A. Young. 1993. “A Note on Coverage Error of Bootstrap Confidence Intervals for Quantiles.” &lt;em&gt;Mathematical Proceedings of the Cambridge Philosophical Society&lt;/em&gt; 114: 517–31. &lt;a href=&quot;http://sci-prew.inf.ua/v114/3/S0305004100071802.pdf&quot; class=&quot;uri&quot;&gt;http://sci-prew.inf.ua/v114/3/S0305004100071802.pdf&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-falk_kaufmann1991&quot;&gt;
&lt;p&gt;Falk, Michael, and Edgar Kaufmann. 1991. “Coverage Probabilities of Bootstrap-Confidence Intervals for Quantiles.” &lt;em&gt;Ann. Statist.&lt;/em&gt; 19 (1). The Institute of Mathematical Statistics: 485–95. doi:&lt;a href=&quot;https://doi.org/10.1214/aos/1176347995&quot;&gt;10.1214/aos/1176347995&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-hettmansperger_sheather1986&quot;&gt;
&lt;p&gt;Hettmansperger, T. P., and S. J Sheather. 1986. “Confidence Intervals Based on Interpolated Order Statistics.” &lt;em&gt;Statistics and Probability Letters&lt;/em&gt; 4: 75–79. doi:&lt;a href=&quot;https://doi.org/10.1016/0167-7152(86)90021-0&quot;&gt;10.1016/0167-7152(86)90021-0&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-hoehle_hoehle2009&quot;&gt;
&lt;p&gt;Höhle, J., and M. Höhle. 2009. “Accuracy Assessment of Digital Elevation Models by Means of Robust Statistical Methods.” &lt;em&gt;ISPRS Journal of Photogrammetry and Remote Sensing&lt;/em&gt; 64 (4): 398–406. doi:&lt;a href=&quot;https://doi.org/10.1016/j.isprsjprs.2009.02.003&quot;&gt;10.1016/j.isprsjprs.2009.02.003&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-hyndman_fan1996&quot;&gt;
&lt;p&gt;Hyndman, R. J., and Y. Fan. 1996. “Sample Quantiles in Statistical Packages.” &lt;em&gt;American Statistician&lt;/em&gt; 50 (4): 361–65. doi:&lt;a href=&quot;https://doi.org/10.2307/2684934&quot;&gt;10.2307/2684934&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-nyblom1992&quot;&gt;
&lt;p&gt;Nyblom, J. 1992. “Note on Interpolated Order Statistics.” &lt;em&gt;Statistics and Probability Letters&lt;/em&gt; 14: 129–31. &lt;a href=&quot;10.1016/0167-7152(92)90076-H&quot; class=&quot;uri&quot;&gt;10.1016/0167-7152(92)90076-H&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
        <pubDate>Sun, 23 Oct 2016 00:00:00 +0200</pubDate>
        <link>http://staff.math.su.se/hoehle/blog/2016/10/23/quantileCI.html</link>
        <guid isPermaLink="true">http://staff.math.su.se/hoehle/blog/2016/10/23/quantileCI.html</guid>
        
        <category>rstats</category>
        
        <category>stats</category>
        
        <category>nonparametrics</category>
        
        
      </item>
    
      <item>
        <title>Cartograms with R</title>
        <description>&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;We show how to create &lt;a href=&quot;https://en.wikipedia.org/wiki/Cartogram&quot;&gt;cartograms&lt;/a&gt; with R by illustrating the population and age-distribution of the planning regions of Berlin by static plots and animations.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-10-10-cartograms/CARTOGRAM-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br&gt; &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width:0&quot; src=&quot;https://i.creativecommons.org/l/by-sa/4.0/88x31.png&quot;/&gt;&lt;/a&gt; This work is licensed under a &lt;a rel=&quot;license&quot;
href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt;. The markdown+Rknitr source code of this blog is available under a &lt;a href=&quot;https://www.gnu.org/licenses/gpl-3.0.html&quot;&gt;GNU General Public License (GPL v3)&lt;/a&gt; license from &lt;a href=&quot;https://github.com/hoehleatsu/hoehleatsu.github.io&quot;&gt;&lt;img src=&quot;/hoehle/blog/images/GitHub-Mark-32px.png&quot; alt=&quot;github&quot; /&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Every good lecture on sophisticated statistical modelling starts with underlining the importance of &lt;strong&gt;data visualization&lt;/strong&gt; as the first step of an analysis. &lt;a href=&quot;https://en.wikipedia.org/wiki/Choropleth_map&quot;&gt;Choropleth maps&lt;/a&gt; are a common choice for visualizing the spatial distribution of a feature recorded in administrative regions, e.g., population density or the incidence rate of a disease. Here, each region is shaded with a color selected in accordance with the feature variable, e.g., higher hue if the feature value is higher. Choosing the right palette for such visualizations is a science of its own, see e.g. &lt;span class=&quot;citation&quot; data-cites=&quot;zeileis_etal2009&quot;&gt;Zeileis, Hornik, and Murrell (2009)&lt;/span&gt; or the &lt;a href=&quot;http://colorbrewer2.org/&quot;&gt;ColorBrewer&lt;/a&gt; project, which is available in R through the &lt;a href=&quot;https://cran.r-project.org/web/packages/RColorBrewer/index.html&quot;&gt;&lt;code&gt;RColorBrewer&lt;/code&gt;&lt;/a&gt; package. A nice way to further spice up your spatial visualizations are &lt;strong&gt;area cartograms&lt;/strong&gt;, where the boundary shape of each region is warped such that its area becomes proportional to the value of the feature variable you want to illustrate. The difficult part here is to preserve the arrangement of the regions, see for example &lt;span class=&quot;citation&quot; data-cites=&quot;gastner_newman2004&quot;&gt;Gastner and Newman (2004)&lt;/span&gt; for the methodological challenges of this task.&lt;/p&gt;
&lt;p&gt;In this post we show how such area cartograms can easily be created with R using the packages &lt;code&gt;Rcartogram&lt;/code&gt; and &lt;code&gt;getcartr&lt;/code&gt; together with the powerful packages &lt;code&gt;sp&lt;/code&gt;, &lt;code&gt;rgeos&lt;/code&gt; and &lt;code&gt;rgdal&lt;/code&gt; for the spatial data wrangling. Both &lt;code&gt;Rcartogram&lt;/code&gt; and &lt;code&gt;getcartr&lt;/code&gt; are only available from github, because the license of the underlying &lt;a href=&quot;http://www-personal.umich.edu/~mejn/cart/&quot;&gt;&lt;code&gt;Cart&lt;/code&gt;&lt;/a&gt; C fragment implementing the method of &lt;span class=&quot;citation&quot; data-cites=&quot;gastner_newman2004&quot;&gt;Gastner and Newman (2004)&lt;/span&gt; does not appear to be GPL (or the like) compatible.&lt;/p&gt;
&lt;h1 id=&quot;the-data&quot;&gt;The Data&lt;/h1&gt;
&lt;p&gt;We use population numbers for the 447 planning regions of Berlin (Lebensweltlich orientierte Räume (LOR)). The boundaries of these regions are available as ESRI Shapefile through the &lt;a href=&quot;http://daten.berlin.de/datensaetze/rbs-lor-lebensweltlich-orientierte-r%C3%A4ume-dezember-2015&quot;&gt;open data portal of Berlin&lt;/a&gt; under the CC BY license. The 2015 population data of the LORs are available as CSV file through the same &lt;a href=&quot;http://daten.berlin.de/datensaetze/einwohnerinnen-und-einwohner-berlin-lor-planungsr%C3%A4umen-am-31122015&quot;&gt;data portal&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;tmpfile &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;paste0&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;tempfile&lt;/span&gt;(),&lt;span class=&quot;st&quot;&gt;&amp;quot;.zip&amp;quot;&lt;/span&gt;)
&lt;span class=&quot;kw&quot;&gt;download.file&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;https://www.statistik-berlin-brandenburg.de/opendata/RBS_OD_LOR_2015_12.zip&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;destfile=&lt;/span&gt;tmpfile)
&lt;span class=&quot;kw&quot;&gt;unzip&lt;/span&gt;(tmpfile,&lt;span class=&quot;dt&quot;&gt;exdir=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;file.path&lt;/span&gt;(filePath,&lt;span class=&quot;st&quot;&gt;&amp;quot;RBS_OD_LOR_2015_12&amp;quot;&lt;/span&gt;))
&lt;span class=&quot;kw&quot;&gt;download.file&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;https://www.statistik-berlin-brandenburg.de/opendata/EWR201512E_Matrix.csv&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;destfile=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;file.path&lt;/span&gt;(filePath,&lt;span class=&quot;st&quot;&gt;&amp;quot;EWR201512E_Matrix.csv&amp;quot;&lt;/span&gt;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;With the help of the &lt;code&gt;rgdal&lt;/code&gt;, &lt;code&gt;sp&lt;/code&gt; and the &lt;code&gt;rgeos&lt;/code&gt; CRAN packages, R can be used as a &lt;a href=&quot;https://en.wikipedia.org/wiki/Geographic_information_system&quot;&gt;geographic information system (GIS)&lt;/a&gt;. This allows for easy merging of these two data sources together with a spatial aggregation to the &lt;strong&gt;Prognoseräume&lt;/strong&gt; level, which is a slightly higher level of aggregation than the LORs (60 regions instead of 447). The output of these data wrangling steps will be a SpatialPolygonsDataFrame object &lt;code&gt;pgrs&lt;/code&gt; - see GitHub code for details.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;library&lt;/span&gt;(rgdal)
&lt;span class=&quot;kw&quot;&gt;library&lt;/span&gt;(sp)
&lt;span class=&quot;kw&quot;&gt;library&lt;/span&gt;(rgeos)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Read shapefile
lor &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;readOGR&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;dsn=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;file.path&lt;/span&gt;(filePath,&lt;span class=&quot;st&quot;&gt;&amp;quot;RBS_OD_LOR_2015_12&amp;quot;&lt;/span&gt;),&lt;span class=&quot;dt&quot;&gt;layer=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;RBS_OD_LOR_2015_12&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## OGR data source with driver: ESRI Shapefile 
## Source: &amp;quot;/Users/hoehle/Sandbox/Blog/figure/source/2016-10-10-cartograms//RBS_OD_LOR_2015_12&amp;quot;, layer: &amp;quot;RBS_OD_LOR_2015_12&amp;quot;
## with 447 features
## It has 8 fields&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;proj4string&lt;/span&gt;(lor)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;+proj=utm +zone=33 +ellps=GRS80 +units=m +no_defs&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Compute area of each LOR in km^2 area (unit: meters -&amp;gt; convert to square km)
lor$area &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;gArea&lt;/span&gt;(lor, &lt;span class=&quot;dt&quot;&gt;byid=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;) /&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;(&lt;span class=&quot;fl&quot;&gt;1e6&lt;/span&gt;)

##Read population
pop &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;readr::&lt;span class=&quot;kw&quot;&gt;read_csv2&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;file=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;file.path&lt;/span&gt;(filePath, &lt;span class=&quot;st&quot;&gt;&amp;quot;EWR201512E_Matrix.csv&amp;quot;&lt;/span&gt;))

##Merge SpatialPolygonsDataFrame with population information
lor_pop &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;merge&lt;/span&gt;(lor, pop, &lt;span class=&quot;dt&quot;&gt;by.x=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;PLR&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;by.y=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;RAUMID&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Plotting the result of the &lt;code&gt;pgrs&lt;/code&gt; object as an instance of &lt;code&gt;SpatialPolygonsDataFrame&lt;/code&gt; can be done using the standard &lt;code&gt;Spatial*&lt;/code&gt; plotting routines documented extensively in, e.g, &lt;span class=&quot;citation&quot; data-cites=&quot;bivand_etal2008&quot;&gt;Bivand, Pebesma, and Gómez-Rubio (2008)&lt;/span&gt; and its comprehensive &lt;a href=&quot;http://www.asdar-book.org/&quot;&gt;webpage&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;######################################################################
## Plotting the result, see nice tutorial by
## http://www.nickeubank.com/wp-content/uploads/2015/10/RGIS3_MakingMaps_part1_mappingVectorData.html
## or the Bivand et al. (2008) book - a must read!
## Note: there is a 2nd edition available nowadays.
######################################################################

&lt;span class=&quot;kw&quot;&gt;library&lt;/span&gt;(RColorBrewer)
my.palette &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;brewer.pal&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n =&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;6&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;name =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;Purples&amp;quot;&lt;/span&gt;)
##Helper function for making labels for each entry
sp.label &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(x, label) {&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;sp.text&amp;quot;&lt;/span&gt;, &lt;span class=&quot;kw&quot;&gt;coordinates&lt;/span&gt;(x), label,&lt;span class=&quot;dt&quot;&gt;cex=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.5&lt;/span&gt;)}
borderCol &amp;lt;-&lt;span class=&quot;st&quot;&gt; &amp;quot;white&amp;quot;&lt;/span&gt;

&lt;span class=&quot;co&quot;&gt;#Plot choropleth map&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;spplot&lt;/span&gt;(pgrs, &lt;span class=&quot;st&quot;&gt;&amp;quot;density&amp;quot;&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;col.regions =&lt;/span&gt; my.palette, &lt;span class=&quot;dt&quot;&gt;cuts =&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;length&lt;/span&gt;(my.palette)-&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;col =&lt;/span&gt; borderCol,&lt;span class=&quot;dt&quot;&gt;main=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;Choropleth map of Population Density&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;sp.layout=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;sp.label&lt;/span&gt;(pgrs, pgrs$EXTPGRNAME))
&lt;span class=&quot;kw&quot;&gt;require&lt;/span&gt;(grid)
&lt;span class=&quot;kw&quot;&gt;grid.text&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;expression&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;Population density (Persons / &amp;quot;&lt;/span&gt;~km^&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;~&lt;span class=&quot;st&quot;&gt;&amp;quot;)&amp;quot;&lt;/span&gt;), &lt;span class=&quot;dt&quot;&gt;x=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;unit&lt;/span&gt;(&lt;span class=&quot;fl&quot;&gt;0.95&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;&amp;quot;npc&amp;quot;&lt;/span&gt;), &lt;span class=&quot;dt&quot;&gt;y=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;unit&lt;/span&gt;(&lt;span class=&quot;fl&quot;&gt;0.50&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;&amp;quot;npc&amp;quot;&lt;/span&gt;), &lt;span class=&quot;dt&quot;&gt;rot=&lt;/span&gt;-&lt;span class=&quot;dv&quot;&gt;90&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-10-10-cartograms/CHOROPLETH-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;h2 id=&quot;installing-the-cartogram-r-packages&quot;&gt;Installing the Cartogram R packages&lt;/h2&gt;
&lt;p&gt;Two packages &lt;code&gt;Rcartogram&lt;/code&gt; and &lt;code&gt;getcartr&lt;/code&gt; make the functionality of the &lt;span class=&quot;citation&quot; data-cites=&quot;gastner_newman2004&quot;&gt;Gastner and Newman (2004)&lt;/span&gt; procedure available for working with objects of class &lt;code&gt;Spatial*&lt;/code&gt;. Installing &lt;code&gt;Rcartogram&lt;/code&gt; requires the &lt;a href=&quot;http://www.fftw.org/&quot;&gt;&lt;code&gt;fftw&lt;/code&gt; library&lt;/a&gt; to be installed. How to best do that depends on your system, for Mac OS X the &lt;a href=&quot;http://brew.sh/&quot;&gt;homebrew package system&lt;/a&gt; makes this installation easy.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##On command line in OS/X with homebrew. Wrapped in FALSE statement to not run system() unintentionally
if (&lt;span class=&quot;ot&quot;&gt;FALSE&lt;/span&gt;) {
  &lt;span class=&quot;kw&quot;&gt;system&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;brew install fftw&amp;quot;&lt;/span&gt;)
}
##Install the R implementation of Cart by Gastner and Newman (2004)
devtools::&lt;span class=&quot;kw&quot;&gt;install_github&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;omegahat/Rcartogram&amp;quot;&lt;/span&gt;)
devtools::&lt;span class=&quot;kw&quot;&gt;install_github&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;#39;chrisbrunsdon/getcartr&amp;#39;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;subdir=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;#39;getcartr&amp;#39;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We are now ready to compute our first cartogram using the &lt;code&gt;getcartr::quick.carto&lt;/code&gt; function.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;library&lt;/span&gt;(Rcartogram)
&lt;span class=&quot;kw&quot;&gt;library&lt;/span&gt;(getcartr)

##Make a cartogram
pgrs_carto &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;quick.carto&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;spdf=&lt;/span&gt;pgrs,&lt;span class=&quot;dt&quot;&gt;v=&lt;/span&gt;pgrs$E_E,&lt;span class=&quot;dt&quot;&gt;res=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;256&lt;/span&gt;)

##Display it using sp functionality
&lt;span class=&quot;kw&quot;&gt;spplot&lt;/span&gt;(pgrs_carto, &lt;span class=&quot;st&quot;&gt;&amp;quot;area&amp;quot;&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;col.regions =&lt;/span&gt; my.palette, &lt;span class=&quot;dt&quot;&gt;cuts =&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;length&lt;/span&gt;(my.palette)-&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;col =&lt;/span&gt; borderCol,&lt;span class=&quot;dt&quot;&gt;main=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;Population Cartogram as Choropleth of Area&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;sp.layout=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;sp.label&lt;/span&gt;(pgrs_carto, &lt;span class=&quot;dt&quot;&gt;label=&lt;/span&gt;pgrs_carto$EXTPGRNAME))
grid::&lt;span class=&quot;kw&quot;&gt;grid.text&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;expression&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;Area (km&amp;quot;&lt;/span&gt;^&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;*&lt;span class=&quot;st&quot;&gt;&amp;quot;)&amp;quot;&lt;/span&gt;), &lt;span class=&quot;dt&quot;&gt;x=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;unit&lt;/span&gt;(&lt;span class=&quot;fl&quot;&gt;0.95&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;&amp;quot;npc&amp;quot;&lt;/span&gt;), &lt;span class=&quot;dt&quot;&gt;y=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;unit&lt;/span&gt;(&lt;span class=&quot;fl&quot;&gt;0.50&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;&amp;quot;npc&amp;quot;&lt;/span&gt;), &lt;span class=&quot;dt&quot;&gt;rot=&lt;/span&gt;-&lt;span class=&quot;dv&quot;&gt;90&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-10-10-cartograms/CARTOGRAM-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;With the cartogram functionality now being directly available through R allows one to embedd cartogram making in a full R pipeline. We illustrate this by generating a sequence of cartograms into an animated GIF file using the &lt;code&gt;animation&lt;/code&gt; package. The animation below shows a cartogram for the population size for each of the 32 age groups in the Berlin data set. One observes that the 25-45 year old tend to live in the city centre, while the 95-110 year old seem to concentrate in the wealthy regions in the south west.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-10-10-cartograms/pop-cartograms.gif&quot; /&gt;
&lt;/figure&gt;
&lt;h1 id=&quot;outlook&quot;&gt;Outlook&lt;/h1&gt;
&lt;p&gt;While writing this posts some other useRs have posted on how to create &lt;a href=&quot;https://twitter.com/Victpir/status/785852075129315333&quot;&gt;interactive cartograms&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&quot;references&quot; class=&quot;unnumbered&quot;&gt;References&lt;/h1&gt;
&lt;div id=&quot;refs&quot; class=&quot;references&quot;&gt;
&lt;div id=&quot;ref-bivand_etal2008&quot;&gt;
&lt;p&gt;Bivand, R. S., E. J. Pebesma, and V. Gómez-Rubio. 2008. &lt;em&gt;Applied Spatial Data Analysis with R&lt;/em&gt;. Springer-Verlag.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-gastner_newman2004&quot;&gt;
&lt;p&gt;Gastner, Michael T., and M. E. J. Newman. 2004. “Diffusion-Based Method for Producing Density-Equalizing Maps.” &lt;em&gt;Proceedings of the National Academy of Sciences of the United States of America&lt;/em&gt; 101 (20): 7499–7504. doi:&lt;a href=&quot;https://doi.org/10.1073/pnas.0400280101&quot;&gt;10.1073/pnas.0400280101&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-zeileis_etal2009&quot;&gt;
&lt;p&gt;Zeileis, Achim, Kurt Hornik, and Paul Murrell. 2009. “Escaping RGBland: Selecting Colors for Statistical Graphics.” &lt;em&gt;Computational Statistics &amp;amp; Data Analysis&lt;/em&gt; 53 (9): 3259–70. doi:&lt;a href=&quot;https://doi.org/http://dx.doi.org/10.1016/j.csda.2008.11.033&quot;&gt;http://dx.doi.org/10.1016/j.csda.2008.11.033&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
        <pubDate>Mon, 10 Oct 2016 00:00:00 +0200</pubDate>
        <link>http://staff.math.su.se/hoehle/blog/2016/10/10/cartograms.html</link>
        <guid isPermaLink="true">http://staff.math.su.se/hoehle/blog/2016/10/10/cartograms.html</guid>
        
        <category>dataviz</category>
        
        <category>rstats</category>
        
        <category>spatial</category>
        
        <category>GIS</category>
        
        
      </item>
    
      <item>
        <title>Surveillance Out of the Box - The #Zombie Experiment</title>
        <description>&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;We perform a social experiment to investigate, if zombie related twitter posts can be used as a reliable indicator for an early warning system. We show how such a system can be set up almost out-of-the-box using R - a free software environment for statistical computing and graphics. &lt;strong&gt;Warning&lt;/strong&gt;: This blog entry contains toxic doses of Danish irony and sarcasm as well as disturbing graphs. &lt;strong&gt;Update&lt;/strong&gt;: The blog post was extended with additional data, graphs and text at 2016-11-03 00:08:27. Scroll to the end of the post for details.&lt;/p&gt;
&lt;p&gt;&lt;br&gt; &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width:0&quot; src=&quot;https://i.creativecommons.org/l/by-sa/4.0/88x31.png&quot;/&gt;&lt;/a&gt; This work is licensed under a &lt;a rel=&quot;license&quot;
href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt;. The markdown+Rknitr source code of this blog is available under a &lt;a href=&quot;https://www.gnu.org/licenses/gpl-3.0.html&quot;&gt;GNU General Public License (GPL v3)&lt;/a&gt; license from &lt;a href=&quot;https://github.com/hoehleatsu/hoehleatsu.github.io&quot;&gt;&lt;img src=&quot;/hoehle/blog/images/GitHub-Mark-32px.png&quot; alt=&quot;github&quot; /&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Proposing statistical methods is only mediocre fun if nobody applies them. As an act of desperation the prudent statistician has been forced to provide R packages supplemented with a CRAN, github, useR! or word-of-mouth advertising strategy. To underpin efforts, a reproducibility-crisis has been announced in order to scare decent comma-separated scientists &lt;a href=&quot;https://www.washingtonpost.com/news/wonk/wp/2016/08/26/an-alarming-number-of-scientific-papers-contain-excel-errors/&quot;&gt;from using Excel&lt;/a&gt;. Social media marketing strategies of your R package include hashtag &lt;code&gt;#rstats&lt;/code&gt; twitter announcements, possibly enhanced by a picture or animation showing your package at its best:&lt;/p&gt;
&lt;center&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;
Introducing gganimate: &lt;a href=&quot;https://twitter.com/hashtag/rstats?src=hash&quot;&gt;#rstats&lt;/a&gt; package for adding animation to any ggplot2 figure &lt;a href=&quot;https://t.co/UBWKHmIc0e&quot;&gt;https://t.co/UBWKHmIc0e&lt;/a&gt; &lt;a href=&quot;https://t.co/oQhQaYBqOj&quot;&gt;pic.twitter.com/oQhQaYBqOj&lt;/a&gt;
&lt;/p&gt;
— David Robinson (@drob) &lt;a href=&quot;https://twitter.com/drob/status/694274942813102080&quot;&gt;February 1, 2016&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/center&gt;
&lt;p&gt;
&lt;p&gt;Unfortunately, little experience with the interactive aspect of this statistical software marketing strategy appears to be available. In order to fill this scientific advertising gap, this blog post constitutes an advertisement for the &lt;strong&gt;out-of-the-box-functionality&lt;/strong&gt; of the &lt;code&gt;surveillance&lt;/code&gt; package hidden as social experiment. It shows shows what you can do with R when combining a couple of packages, wrangle the data, cleverly visualize the results and then team up with the fantastic R community.&lt;/p&gt;
&lt;h2 id=&quot;the-setup-detecting-a-zombie-attack&quot;&gt;The Setup: Detecting a Zombie Attack&lt;/h2&gt;
&lt;p&gt;As previously explained in an &lt;a href=&quot;http://user2015.math.aau.dk/lightning_talks&quot;&gt;useR! 2015 lightning talk&lt;/a&gt;, Max Brooks&#39; &lt;a href=&quot;https://en.wikipedia.org/wiki/The_Zombie_Survival_Guide&quot;&gt;Zombie Survival Guide&lt;/a&gt; is very concerned about the &lt;strong&gt;early warning&lt;/strong&gt; of Zombie outbreaks.&lt;/p&gt;
&lt;center&gt;
&lt;a href=&quot;http://staff.math.su.se/hoehle/software/surveillance/hoehle-userR2015-web.pdf&quot;&gt;&lt;img src=&quot;/hoehle/blog/figure/source/2016-09-25-sootb/zombiepreparedness.png&quot;&gt;&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;However, despite of extensive research and recommendations, no reliable service appears available for the early detection of such upcoming events. Twitter, on the other hand, has become the media darling to stay informed about news as they unfold. Hence, continuous monitoring of hashtags like &lt;code&gt;#zombie&lt;/code&gt; or &lt;code&gt;#zombieattack&lt;/code&gt; appears an essential component of your zombie survival strategy.&lt;/p&gt;
&lt;h1 id=&quot;tight-clothes-short-hair-and-r&quot;&gt;Tight Clothes, Short Hair and R&lt;/h1&gt;
&lt;p&gt;Extending the recommendations of the Zombie Survival guide we provide an out-of-the-box (OOTB) monitoring system by using the &lt;code&gt;rtweet&lt;/code&gt; R package to obtain all individual tweets containing the hashtags &lt;code&gt;#zombie&lt;/code&gt; or &lt;code&gt;#zombieattack&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;the_query &amp;lt;-&lt;span class=&quot;st&quot;&gt; &amp;quot;#zombieattack OR #zombie&amp;quot;&lt;/span&gt;
geocode &amp;lt;-&lt;span class=&quot;st&quot;&gt; &amp;quot;&amp;quot;&lt;/span&gt;  &lt;span class=&quot;co&quot;&gt;#To limit the seach to berlin &amp;amp; surroundings: geocode &amp;lt;- &amp;quot;52.520583,13.402765,25km&amp;quot;&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#Converted query string which works for storing as file&lt;/span&gt;
safe_query &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;stringr::&lt;span class=&quot;kw&quot;&gt;str_replace_all&lt;/span&gt;(the_query, &lt;span class=&quot;st&quot;&gt;&amp;quot;[^[:alnum:]]&amp;quot;&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;&amp;quot;X&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In particular, the &lt;a href=&quot;https://github.com/mkearney/rtweet&quot;&gt;README&lt;/a&gt; of the &lt;code&gt;rtweet&lt;/code&gt; package provides helpful information on how to create a twitter app to automatically search tweets using the twitter API. One annoyance of the twitter REST API is that only the tweets of the past 7 days are kept in the index. Hence, your time series are going to be short unless you accumulate data over several queries spread over a time period. Instead of using a fancy database setup for this data collection, we provide a simple R solution based on &lt;code&gt;dplyr&lt;/code&gt; and &lt;code&gt;saveRDS&lt;/code&gt; - see the underlying R code of this post by clicking on the github logo in the license statement of this post. Basically,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;all tweets fulfilling the above hashtag search queries are extracted&lt;/li&gt;
&lt;li&gt;each tweet is extended with a time stamp of the query-time&lt;/li&gt;
&lt;li&gt;the entire result of each query us stored into a separate RDS-files using &lt;code&gt;saveRDS&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In a next step, all stored queries are loaded from the RDS files and put together. Subsequently, only the newest time stamped entry about each tweet is kept - this ensures that the re-tweeted counts are up-to-date and no post is counted twice. All these data wrangling operations are easily conducted using &lt;code&gt;dplyr&lt;/code&gt;. Of course a full database solution would have been more elegant, but R does the job just as well as long it&#39;s not millions of queries. Actually, in the example we are going to use the results of a single query. No matter the data backend, at the end of this pipeline we have a database of tweets.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;co&quot;&gt;#Read the tweet database&lt;/span&gt;
tw &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;readRDS&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;file=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;paste0&lt;/span&gt;(filePath,&lt;span class=&quot;st&quot;&gt;&amp;quot;Tweets-Database-&amp;quot;&lt;/span&gt;,safe_query,&lt;span class=&quot;st&quot;&gt;&amp;quot;-&amp;quot;&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;2016-09-25&amp;quot;&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;.RDS&amp;quot;&lt;/span&gt;))
&lt;span class=&quot;kw&quot;&gt;options&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;width=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;300&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;tibble.width =&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;Inf&lt;/span&gt;)
tw %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt;(created_at, retweet_count,screen_name,text,hashtags,query_at)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10,974 × 6
##             created_at retweet_count    screen_name                                                                                                                                          text  hashtags            query_at
##                 &amp;lt;dttm&amp;gt;         &amp;lt;int&amp;gt;          &amp;lt;chr&amp;gt;                                                                                                                                         &amp;lt;chr&amp;gt;    &amp;lt;list&amp;gt;              &amp;lt;dttm&amp;gt;
## 1  2016-09-25 10:26:28             0       Lovebian                                               The latest #Zombie Nation! https://t.co/8ZkOFSZH2v Thanks to @NJTVNews @MaxfireXSA @Xtopgun901X &amp;lt;chr [1]&amp;gt; 2016-09-25 10:30:44
## 2  2016-09-25 10:25:49             2  MilesssAwaaay RT @Shaaooun: I&amp;#39;m gonna turn to a zombie soon! xdxdxdxd #AlmostSurvived #204Days #ITried #Zombie #StuckInMyRoom #Haha\n\n#MediaDoomsDay #Kame &amp;lt;chr [7]&amp;gt; 2016-09-25 10:30:44
## 3  2016-09-25 10:21:10             6 catZzinthecity          RT @ZombieEventsUK: 7 reasons #TheGirlWithAllTheGifts is the best #zombie movie in years https://t.co/MB82ssxss2 via @MetroUK #Metro &amp;lt;chr [3]&amp;gt; 2016-09-25 10:30:44
## 4  2016-09-25 10:19:41             0  CoolStuff2Get                             Think Geek Zombie Plush Slippers https://t.co/0em920WCMh #Zombie #Slippers #MyFeetAreCold https://t.co/iCEkPBykCa &amp;lt;chr [3]&amp;gt; 2016-09-25 10:30:44
## 5  2016-09-25 10:19:41             4  TwitchersNews    RT @zOOkerx: Nur der frhe Vogel fngt den #zombie also schaut gemtlich rein bei @booty_pax! Now live #dayz on #twitch \n\nhttps://t.co/OIk6 &amp;lt;chr [3]&amp;gt; 2016-09-25 10:30:44
## 6  2016-09-25 10:17:45             0 ZombieExaminer     Washington mall shooting suspect Arcan Cetin was &amp;#39;#Zombie-like&amp;#39; during arrest - USA TODAY https://t.co/itoDXG3L8T https://t.co/q2mURi24DB &amp;lt;chr [1]&amp;gt; 2016-09-25 10:30:44
## 7  2016-09-25 10:17:44             4       SpawnRTs    RT @zOOkerx: Nur der frhe Vogel fngt den #zombie also schaut gemtlich rein bei @booty_pax! Now live #dayz on #twitch \n\nhttps://t.co/OIk6 &amp;lt;chr [3]&amp;gt; 2016-09-25 10:30:44
## 8  2016-09-25 10:17:23             0   BennyPrabowo                   bad miku - bad oni-chan... no mercy\n.\n.\n.\n.\n#left4dead #games #hatsunemiku #fps #zombie #witch https://t.co/YP0nRDFFj7 &amp;lt;chr [6]&amp;gt; 2016-09-25 10:30:44
## 9  2016-09-25 10:12:53            62   Nblackthorne  RT @PennilessScribe: He would end her pain, but he could no longer live in a world that demanded such sacrifice. #zombie #apocalypse\nhttps: &amp;lt;chr [2]&amp;gt; 2016-09-25 10:30:44
## 10 2016-09-25 10:06:46             0   mthvillaalva                                                             Pak ganern!!! Kakatapos ko lang kumain ng dugo! \n#Zombie https://t.co/Zyd0btVJH4 &amp;lt;chr [1]&amp;gt; 2016-09-25 10:30:44
## # ... with 10,964 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;ootb-zombie-surveillance&quot;&gt;OOTB Zombie Surveillance&lt;/h3&gt;
&lt;p&gt;We are now ready to prospectively detect changes using the &lt;code&gt;surveillance&lt;/code&gt; R package &lt;span class=&quot;citation&quot; data-cites=&quot;salmon_etal2016a&quot;&gt;(Salmon, Schumacher, and Höhle 2016)&lt;/span&gt;.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;library&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;surveillance&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We shall initially focus on the &lt;code&gt;#zombie&lt;/code&gt; series as it contains more counts. The first step is to convert the &lt;code&gt;data.frame&lt;/code&gt; of individual tweets into a time series of daily counts.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;co&quot;&gt;#&amp;#39; Function to convert data.frame to queries. For convenience we store the time series&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#&amp;#39; and the data.frame jointly as a list. This allows for easy manipulations later on&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#&amp;#39; as we see data.frame and time series to be a joint package.&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#&amp;#39;&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#&amp;#39; @param tw data.frame containing the linelist of tweets.&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#&amp;#39; @param the_query_subset String containing a regexp to restrict the hashtags&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#&amp;#39; @param delete_first_day (boolean) Delete first day of the series due to it being incomplete&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#&amp;#39; @return List containing sts object as well as the original data frame.&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#&amp;#39;&lt;/span&gt;
df_2_timeseries &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(tw, the_query_subset, &lt;span class=&quot;dt&quot;&gt;delete_first_day=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;) {
  tw_subset &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;tw %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;filter&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;grepl&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;gsub&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;#&amp;quot;&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;&amp;quot;&lt;/span&gt;,the_query_subset),hashtags))

  &lt;span class=&quot;co&quot;&gt;#Aggregate data per day and convert times series to sts object&lt;/span&gt;
  ts &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;surveillance::&lt;span class=&quot;kw&quot;&gt;linelist2sts&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;as.data.frame&lt;/span&gt;(tw_subset), &lt;span class=&quot;dt&quot;&gt;dateCol=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;created_at_Date&amp;quot;&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;aggregate.by=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;1 day&amp;quot;&lt;/span&gt;)
  &lt;span class=&quot;co&quot;&gt;#Drop first day with observations, due to the moving window of the twitter index, this count is incomplete&lt;/span&gt;
  if (delete_first_day) ts &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;ts[-&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,]

  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;tw=&lt;/span&gt;tw_subset,&lt;span class=&quot;dt&quot;&gt;ts=&lt;/span&gt;ts, &lt;span class=&quot;dt&quot;&gt;the_query_subset=&lt;/span&gt;the_query_subset))
}

zombie &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;df_2_timeseries&lt;/span&gt;(tw, &lt;span class=&quot;dt&quot;&gt;the_query_subset =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;#zombie&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It&#39;s easy to visualize the resulting time series using the plotting functionality of the surveillance package.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-09-25-sootb/unnamed-chunk-9-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;We see that the counts on the last day are incomplete. This is because the query was performed at 10:30 CEST and not at midnight. We therefore adjust counts on the last day based on simple inverse probability weighting. This just means that we scale up the counts by the inverse of the fraction the query-hour (10:30 CEST) makes up of 24h (see github code for details). The usefulness of this adjustment relies on the assumption that queries are evenly distributed over the day.&lt;/p&gt;
&lt;p&gt;We are now ready to apply a surveillance algorithm to the pre-processed time series. We shall pick the so called C1 version of the EARS algorithm documented in &lt;span class=&quot;citation&quot; data-cites=&quot;hutwagner_etal2003&quot;&gt;Hutwagner et al. (2003)&lt;/span&gt; or &lt;span class=&quot;citation&quot; data-cites=&quot;fricker_etal2008&quot;&gt;Fricker, Hegler, and Dunfee (2008)&lt;/span&gt;. For a monitored time point &lt;span class=&quot;math inline&quot;&gt;\(s\)&lt;/span&gt; (here: a particular day, say, 2016-09-23), this simple algorithm takes the previous seven observations before &lt;span class=&quot;math inline&quot;&gt;\(s\)&lt;/span&gt; in order to compute the mean and standard deviation, i.e. &lt;span class=&quot;math display&quot;&gt;\[
\begin{align*}
\bar{y}_s             &amp;amp;= \frac{1}{7} \sum_{t=s-8}^{s-1} y_t, \\
\operatorname{sd}_s^2   &amp;amp;= \frac{1}{7-1} \sum_{t=s-8}^{s-1} (y_t - \bar{y}_s)^2.
\end{align*}
\]&lt;/span&gt; The algorithm then computes the z-statistic &lt;span class=&quot;math inline&quot;&gt;\(\operatorname{C1}_s = (y_s - \bar{y}_s)/\operatorname{sd}_s\)&lt;/span&gt; for each time point to monitor. Once the value of this statistic is above 3 an alarm is flagged. This means that we assume that the previous 7 observations are what is to be expected when no unusual activity is going on. One can interpret the statistic as a transformation to (standard) normality: once the current observation is too extreme under this model an alarm is sounded. Such normal-approximations are justified given the large number of daily counts in the zombie series we consider, but does not take secular trends or day of the week effects into account. Note also that the calculations can also be reversed in order to determine how large the number of observations needs to be in order to generate an alarm (shown as a red line in the graph).&lt;/p&gt;
&lt;p&gt;We now apply the EARS C1 monitoring procedure to the zombie time series starting at the 8th day of the time series. It is important to realize that the result of monitoring a time point in the graphic is obtained by only &lt;strong&gt;looking into the past&lt;/strong&gt;. Hence, the relevant time point to consider today is if an alarm would have occurred 2016-09-25. We also show the other time points to see, if we could have detected potential alarms earlier.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;zombie[[&lt;span class=&quot;st&quot;&gt;&amp;quot;sts&amp;quot;&lt;/span&gt;]] &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;earsC&lt;/span&gt;(zombie$ts, &lt;span class=&quot;dt&quot;&gt;control=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;range =&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;8&lt;/span&gt;:&lt;span class=&quot;kw&quot;&gt;nrow&lt;/span&gt;(zombie$ts),
                         &lt;span class=&quot;dt&quot;&gt;method =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;C1&amp;quot;&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;alpha =&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;-&lt;span class=&quot;kw&quot;&gt;pnorm&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;)))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-09-25-sootb/ZOMBIE-TS-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;What a relief! No suspicious zombie activity appears to be ongoing. Actually, it would have taken 511 additional tweets before we would have raised an alarm on 2016-09-25. This is quite a number.&lt;/p&gt;
&lt;p&gt;As an additional sensitivity analysis we redo the analyses for the &lt;code&gt;#zombieattack&lt;/code&gt; hashtag. Here the use of the normal approximation in the computation of the alerts is more questionable. Still, we can get a time series of counts together with the alarm limits.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-09-25-sootb/ZOMBIEATTACK-TS-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;Also no indication of zombie activity. The number of additional tweets needed before alarm in this case is: 21. Altogether, it looks safe out there...&lt;/p&gt;
&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;
&lt;p&gt;R provides ideal functionality to quickly extract and monitor twitter time series. Combining with statistical process control methods allows you to prospectively monitor the use of hashtags. Twitter has released a dedicated package for this purpose, however, in case of low count time series it is better to use count-time series monitoring devices as implemented in the &lt;code&gt;surveillance&lt;/code&gt; package. &lt;span class=&quot;citation&quot; data-cites=&quot;salmon_etal2016a&quot;&gt;Salmon, Schumacher, and Höhle (2016)&lt;/span&gt; contains further details on how to proceed in this case.&lt;/p&gt;
&lt;p&gt;The important question although remains: Does this really work in practice? Can you sleep tight, while your R zombie monitor scans twitter? Here is where the &lt;strong&gt;social experiment&lt;/strong&gt; starts: Please help by retweeting the post below to create a drill alarm situation. More than 511 (!) and 21 additional tweets, respectively, are needed before an alarm will sound.&lt;/p&gt;
&lt;center&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;de&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;
New blog entry: Please RT to help me evaluate my &lt;a href=&quot;https://twitter.com/hashtag/zombie?src=hash&quot;&gt;#zombie&lt;/a&gt; monitoring system - &lt;a href=&quot;https://t.co/b0gNfpJ0RM&quot;&gt;https://t.co/b0gNfpJ0RM&lt;/a&gt; &lt;a href=&quot;https://twitter.com/hashtag/zombieattack?src=hash&quot;&gt;#zombieattack&lt;/a&gt; &lt;a href=&quot;https://twitter.com/hashtag/biosurveillance?src=hash&quot;&gt;#biosurveillance&lt;/a&gt; &lt;a href=&quot;https://twitter.com/hashtag/rstats?src=hash&quot;&gt;#rstats&lt;/a&gt; &lt;a href=&quot;https://t.co/N3PTZBnaw4&quot;&gt;pic.twitter.com/N3PTZBnaw4&lt;/a&gt;
&lt;/p&gt;
— Michael Höhle (@m_hoehle) &lt;a href=&quot;https://twitter.com/m_hoehle/status/780037067183157248&quot;&gt;25. September 2016&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/center&gt;
&lt;p&gt;I will continuously update the graphs in this post to see how our efforts are reflected in the time series of tweets containing the &lt;code&gt;#zombieattack&lt;/code&gt; and &lt;code&gt;#zombie&lt;/code&gt; hashtags. Thanks for your help!&lt;/p&gt;
&lt;p&gt;
&lt;center&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-09-25-sootb/zombie.png&quot; title=&quot;Source: https://openclipart.org/detail/201838/zombie-head&quot; /&gt; &lt;img src=&quot;/hoehle/blog/figure/source/2016-09-25-sootb/zombie.png&quot; title=&quot;Source: https://openclipart.org/detail/201838/zombie-head&quot; /&gt; &lt;img src=&quot;/hoehle/blog/figure/source/2016-09-25-sootb/zombie.png&quot; title=&quot;Source: https://openclipart.org/detail/201838/zombie-head&quot; /&gt;
&lt;/center&gt;
&lt;p&gt;
&lt;p&gt;
&lt;h3 id=&quot;update-at-2016-11-03-000831&quot;&gt;Update at 2016-11-03 00:08:31&lt;/h3&gt;
&lt;p&gt;Below we show how the &lt;code&gt;#zombieattack&lt;/code&gt; series developed after the post was made public:&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-09-25-sootb/ZOMBIEATTACK_UPDATED-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;The orange part of the bars indicates the fake outbreak tweet (1) as well as its retweets (10). It is obvious that despite the increased activity due to the fake outbreak tweets, no alarm was generated because of them. In parts this is explained by the high activity during 20-21 Sep. A previous outbreak? No, advertisements of &lt;a href=&quot;https://www.etsy.com/listing/480088383/zombie-pin-up-badges-zombie-themed-gifts?ref=shop_home_feat_4&quot;&gt;zombie pinup badges on etsy&lt;/a&gt;. Since the EARS algorithm sequentially estimates the variance of the baseline counts, the peak on 20-21 Sep inflates the mean and variance and thus results in a high upperbound as long as it enters the baseline. Despite some extra activity 25-27 Sep due to the fake outbreak tweets, none of the days are above this bound. However, once the 20-21 Sep peak is out of the previous 7 days baseline, the alarm threshold decreases noticeably. We thus get an alarm for the peak on 30 September, even though it&#39;s not higher than the previous peak on 20-21 Sep and it appears to be caused by other phenomena not related to our fake outbreak. A more careful analysis of the tweets reveals that they are caused by a &lt;a href=&quot;http://charityfunrun2016.tumblr.com/post/149930159797/charity-fun-run-2016&quot;&gt;charity fun run&lt;/a&gt; near Kuala Lumpur with a &lt;a href=&quot;https://www.instagram.com/p/BK-_l8oDD38/&quot;&gt;zombie attack theme&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;
SPAM FAM 😋 &lt;a href=&quot;https://twitter.com/hashtag/zombieattack?src=hash&quot;&gt;#zombieattack&lt;/a&gt; &lt;a href=&quot;https://twitter.com/hashtag/charityfunrun2016?src=hash&quot;&gt;#charityfunrun2016&lt;/a&gt; &lt;a href=&quot;https://t.co/YJW8Mjpd0L&quot;&gt;pic.twitter.com/YJW8Mjpd0L&lt;/a&gt;
&lt;/p&gt;
— PAAN (@noorfarhan_) &lt;a href=&quot;https://twitter.com/noorfarhan_/status/781887252519460864&quot;&gt;September 30, 2016&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;p&gt;
&lt;p&gt;For further comparison, we also use a negative binomial CUSUM, which keeps the baseline steady, but allows the detection of sustained increases.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-09-25-sootb/ZOMBIEUPDATE-NBINOM-CUSUM-PLOT-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;The gray line shows the estimated mean from the eight base-line counts, the orange line shows the corresponding upper 99% quantile of this estimated distribution. The red line shows the alarm limit of a CUSUM method where the potential shift in the mean is estimated by maximum likelihood at each monitoring instance. The threshold is tuned such that it initially roughly coincides with the 99% quantile of the estimated distribution. Here, no signal is detected. Of course this depends on the quantile used for the detection and the 20-21 September peak being included fully in the baseline. Still, according to this metric occasional fake zombie runs are part of the routine.&lt;/p&gt;
&lt;p&gt;Altogether, the &amp;quot;failed&amp;quot;&amp;quot; test proves several points:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;its hard to distinguish between previous outbreaks and irregular tweeting behaviour&lt;/li&gt;
&lt;li&gt;robust estimation of the baseline parameters might be needed&lt;/li&gt;
&lt;li&gt;the results are sensitive to the choice of which values to include in the baseline and the underlying probability model&lt;/li&gt;
&lt;li&gt;is twitter monitoring really sensitive enough to detect weak signals early enough?&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;the-take-home-message-of-this-update&quot;&gt;The take home message of this update&lt;/h4&gt;
&lt;p&gt;To enhance statistical competence and preserve sleep: stick with the negative binomial CUSUM!&lt;/p&gt;
&lt;h1 id=&quot;references&quot; class=&quot;unnumbered&quot;&gt;References&lt;/h1&gt;
&lt;div id=&quot;refs&quot; class=&quot;references&quot;&gt;
&lt;div id=&quot;ref-fricker_etal2008&quot;&gt;
&lt;p&gt;Fricker, R. D., B. L. Hegler, and D. A. Dunfee. 2008. “Comparing syndromic surveillance detection methods: EARS’ versus a CUSUM-based methodology.” &lt;em&gt;Stat Med&lt;/em&gt; 27 (17): 3407–29.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-hutwagner_etal2003&quot;&gt;
&lt;p&gt;Hutwagner, L., W. Thompson, G. M. Seeman, and T. Treadwell. 2003. “The bioterrorism preparedness and response Early Aberration Reporting System (EARS).” &lt;em&gt;J Urban Health&lt;/em&gt; 80 (2 Suppl 1): 89–96.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-salmon_etal2016a&quot;&gt;
&lt;p&gt;Salmon, M., D. Schumacher, and M. Höhle. 2016. “Monitoring Count Time Series in R: Aberration Detection in Public Health Surveillance.” &lt;em&gt;Journal of Statistical Software&lt;/em&gt; 70 (10). doi:&lt;a href=&quot;https://doi.org/10.18637/jss.v070.i10&quot;&gt;10.18637/jss.v070.i10&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
        <pubDate>Sun, 25 Sep 2016 00:00:00 +0200</pubDate>
        <link>http://staff.math.su.se/hoehle/blog/2016/09/25/sootb.html</link>
        <guid isPermaLink="true">http://staff.math.su.se/hoehle/blog/2016/09/25/sootb.html</guid>
        
        <category>datascience</category>
        
        <category>rstats</category>
        
        <category>statistical process control</category>
        
        <category>biosurveillance</category>
        
        
      </item>
    
      <item>
        <title>The Olympic Medal Table Visualized Gapminder Style</title>
        <description>&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Following Hans Rosling&#39;s Gapminder animation style we visualize the total number of medals a country wins during each olympic summer games in relation to the country&#39;s &lt;a href=&quot;https://en.wikipedia.org/wiki/Gross_domestic_product&quot;&gt;gross domestic product&lt;/a&gt; (GDP) per capita. We illustrate how R&#39;s data wrangling capabilities provide a useful toolbox to make such an analysis happen.&lt;/p&gt;
&lt;p&gt;&lt;br&gt; &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width:0&quot; src=&quot;https://i.creativecommons.org/l/by-sa/4.0/88x31.png&quot;/&gt;&lt;/a&gt; This work is licensed under a &lt;a rel=&quot;license&quot;
href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt;. The markdown+Rknitr source code of this blog is available under a &lt;a href=&quot;https://www.gnu.org/licenses/gpl-3.0.html&quot;&gt;GNU General Public License (GPL v3)&lt;/a&gt; license from &lt;a href=&quot;https://github.com/hoehleatsu/hoehleatsu.github.io&quot;&gt;&lt;img src=&quot;/hoehle/blog/images/GitHub-Mark-32px.png&quot; alt=&quot;github&quot; /&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Long Swedish winter nights are best spent watching &lt;a href=&quot;https://en.wikipedia.org/wiki/Hans_Rosling&quot;&gt;Hans Rosling&lt;/a&gt;&#39;s inspiring &lt;a href=&quot;https://www.youtube.com/watch?v=hVimVzgtD6w&quot;&gt;TED talks&lt;/a&gt;. Such visualizations help the statistician make points about temporal trends in a x-axis to y-axis relationship, which otherwise might drown in modelling details. Recently, I stumbled over a &lt;a href=&quot;https://rpubs.com/sjackman/gapminder-gganimate&quot;&gt;blog post&lt;/a&gt; on how to use the &lt;a href=&quot;https://github.com/dgrtwo/gganimate&quot;&gt;&lt;code&gt;gganimate&lt;/code&gt;&lt;/a&gt; R package to animate the Gapminder data available from the &lt;code&gt;gapminder&lt;/code&gt; package. In order to perform a similar &lt;em&gt;Rosling style&lt;/em&gt; animation consider the following: Today, the Olympic Summer Games in Rio de Janeiro end. As usual this spawns a debate, whether the nation&#39;s participation has been successful. For this purpose the &lt;a href=&quot;https://en.wikipedia.org/wiki/Olympic_medal_table&quot;&gt;olympic medal table&lt;/a&gt; is often taken as basis for comparisons, e.g., to mock your &lt;a href=&quot;http://politiken.dk/sport/ol/ECE3349634/danmark-og-sverige-kaemper-til-det-sidste---men-hvor-daelen-er-norge-henne/&quot;&gt;neighbouring countries&lt;/a&gt;. Recent analyses and visualization have been interested in how to correct these tables for, e.g., population size or, more interesting, analyse the influence of GDP. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Google provides &lt;a href=&quot;https://landing.google.com/altmedaltable/&quot;&gt;alternative Olympics medal tables&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Time Magazine discusses whether it is fair &lt;a href=&quot;http://time.com/4452128/olympics-medals-per-capita-rankings/&quot;&gt;to rank countries by medals achieved alone&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The aim of the present blog note is to visualize how countries perform in the medal table in relation to their GDP per capita. From a technical viewpoint we experiment with using R to scrape the olympic medal tables from Wikipedia and animate the results Gapminder style. &lt;strong&gt;Disclaimer&lt;/strong&gt;: We only show the potential of such an analysis and, hence, worry less about the scientific validity of the analysis.&lt;/p&gt;
&lt;h1 id=&quot;data&quot;&gt;Data&lt;/h1&gt;
&lt;p&gt;We use the data of &lt;a href=&quot;https://www.gapminder.org/&quot;&gt;Gapminder&lt;/a&gt; in order to obtain country specific population and GDP per capita data for each of the years in the period of 1960-2016. The olympic medal tables are &#39;harvested&#39; from Wikipedia.&lt;/p&gt;
&lt;h2 id=&quot;olympic-medal-tables&quot;&gt;Olympic medal tables&lt;/h2&gt;
&lt;p&gt;Olympic medal tables were extracted using the &lt;code&gt;rvest&lt;/code&gt; package from the corresponding Wikipedia pages by using table-extracting-code described in the post by &lt;a href=&quot;http://blog.corynissen.com/2015/01/using-rvest-to-scrape-html-table.html&quot;&gt;Cory Nissen&lt;/a&gt;. The Wikipedia tables contain the current state of the medal table and hence take changes in the medal distribution, e.g. deprivation due to doping, into account. For details on such a table, see for example the &lt;a href=&quot;https://en.wikipedia.org/wiki/2012_Summer_Olympics_medal_table&quot;&gt;medal table of the 2012 summer games&lt;/a&gt; in London. In order to stay focused we hide the scraping functionality in the function &lt;code&gt;scrape_medaltab&lt;/code&gt; - see the code on GitHub for more details.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;co&quot;&gt;#Years which had olympic games&lt;/span&gt;
olympic_years &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;seq&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1960&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;2016&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;by=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;4&lt;/span&gt;)

&lt;span class=&quot;co&quot;&gt;# Extract olympic medal table from all olympic years since 1960&lt;/span&gt;
medals &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;bind_rows&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;lapply&lt;/span&gt;(olympic_years, scrape_medaltab))

&lt;span class=&quot;co&quot;&gt;# Show result&lt;/span&gt;
DT::&lt;span class=&quot;kw&quot;&gt;datatable&lt;/span&gt;(medals)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-08-21-gapMedal/unnamed-chunk-2-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;h2 id=&quot;gapminder-data&quot;&gt;Gapminder data&lt;/h2&gt;
&lt;p&gt;We obtain GDP per capita and population data from &lt;a href=&quot;https://www.gapminder.org/data/&quot;&gt;Gapminder&lt;/a&gt;. Unfortunately, these need to be fetched and merged manually. A more convenient way would have been to take these directly from the package &lt;a href=&quot;https://cran.r-project.org/web/packages/gapminder/index.html&quot;&gt;&lt;code&gt;gapminder&lt;/code&gt;&lt;/a&gt;, but newer &lt;a href=&quot;https://www.gapminder.org/data/documentation/gd001/&quot;&gt;GDP data&lt;/a&gt; are now available. Again, we hide the details of the data wrangling activities and refer to GitHub code.&lt;/p&gt;
&lt;p&gt;For convenience, we also extract the corresponding continent each country belongs to. This can be done conveniently by comparing with the &lt;code&gt;gapminder&lt;/code&gt; dataset (see code for details).&lt;/p&gt;
&lt;h2 id=&quot;joining-the-two-data-sources&quot;&gt;Joining the two data sources&lt;/h2&gt;
&lt;p&gt;In principle, all that is left to do is to join the two data sources using the country name of the gapminder dataset and the nation names of the olympic medal tables. However, a challenge of the present country based analysis is how to incorporate the many political changes which happened during the analysis period. As an example, East Germany participated as independent national olympic committee during 1968-1988, but the gapminder data only contain GDP data for Germany as a total. We therefore aggregate the results of the two countries for the analysis. A further important change is the split of the former Soviet Union into several independent states. As a consequence, in 1992 a subset of the former Soviet republics participated as &lt;a href=&quot;https://en.wikipedia.org/wiki/Unified_Team_at_the_1992_Summer_Olympics&quot;&gt;Unified Team&lt;/a&gt;. The GDP values for the Soviet Union thus have to be computed from the Gapminder data by manually summing the individual Soviet republic GDP values. Again we skip further data munging details and simply refer to the GitHub code for a &lt;strong&gt;transparent &amp;amp; reproducible&lt;/strong&gt; account. Warning: Only few of the entries in the list of &lt;a href=&quot;https://en.wikipedia.org/wiki/All-time_Olympic_Games_medal_table#Notes&quot;&gt;obsolete nations &amp;amp; name changes&lt;/a&gt; are taken into account.&lt;/p&gt;
&lt;p&gt;Conditioned on the success of the previous wrangling step, we can now join the two data sources:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;medals_gm &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;left_join&lt;/span&gt;(medals_mod, gapminder_manual, &lt;span class=&quot;dt&quot;&gt;by=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;Nation&amp;quot;&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;Year&amp;quot;&lt;/span&gt;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1 id=&quot;results&quot;&gt;Results&lt;/h1&gt;
&lt;p&gt;First we analyse the &lt;a href=&quot;https://en.wikipedia.org/wiki/All-time_Olympic_Games_medal_table&quot;&gt;all-time summer olympic medal table&lt;/a&gt; for the period 1960-2016.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;medals_alltime &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;medals_gm  %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;group_by&lt;/span&gt;(Nation)  %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;summarise&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;Total=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;sum&lt;/span&gt;(Total))  %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;arrange&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;desc&lt;/span&gt;(Total))
DT::&lt;span class=&quot;kw&quot;&gt;datatable&lt;/span&gt;(medals_alltime)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-08-21-gapMedal/unnamed-chunk-7-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;We now plot of the total number of medals awarded for each summer games in the period of 1960-2016.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;nTotal &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;medals_gm %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;group_by&lt;/span&gt;(Year) %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;summarise&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;TotalOfGames=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;sum&lt;/span&gt;(Total))
&lt;span class=&quot;kw&quot;&gt;ggplot&lt;/span&gt;(nTotal, &lt;span class=&quot;kw&quot;&gt;aes&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;x=&lt;/span&gt;Year,&lt;span class=&quot;dt&quot;&gt;y=&lt;/span&gt;TotalOfGames)) +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;geom_line&lt;/span&gt;() +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;ylab&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;Total number of medals per Summer Games&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-08-21-gapMedal/TOTALMEDALSPERGAME-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;A distinct increasing trend is observed in the above figure. Hence, in order to make between-country comparisons over time based on the number of medals won, we normalize the medals by the total number of medals awarded during the corresponding games. The result is stored in the column &lt;code&gt;Frac&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;medals_gm &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;medals_gm %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;left_join&lt;/span&gt;(nTotal, &lt;span class=&quot;dt&quot;&gt;by=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;Year&amp;quot;&lt;/span&gt;) %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;mutate&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;Frac =&lt;/span&gt; Total /&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;TotalOfGames)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After all these pre-processing steps, we can now compare country results for all summer games in the period 2000-2016.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-08-21-gapMedal/FACET2000ANDBEYOND-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;Note that for better visualization of the many countries with a small number of medals, an &lt;span class=&quot;math inline&quot;&gt;\(\sqrt{}\)&lt;/span&gt;-transform of the y-axis is used.&lt;/p&gt;
&lt;p&gt;Finally, we can use the &lt;code&gt;gganimate&lt;/code&gt; package to visualize the dependence of the total number of medals won in the summer games 1960-2016 as a function of GDP per capita.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-08-21-gapMedal/olympicMedals-gapminder-style.gif&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;As before a &lt;span class=&quot;math inline&quot;&gt;\(\sqrt{}\)&lt;/span&gt;-transform of the y-axis is used for better visualization. One interesting observation we see from the animation is that the home-country of the Olympics always appears to do well in the following Olympics. Also note that the &lt;a href=&quot;https://en.wikipedia.org/wiki/1980_Summer_Olympics_boycott&quot;&gt;1980&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/1984_Summer_Olympics_boycott&quot;&gt;1984&lt;/a&gt; were special due to boycotts. With respect to the top-5 nations it is also worth noticing that China, due to protests against the participation of Taiwan, did not participate in the Olympics 1956-1980. Furthermore, up to 1988 the team denoted &amp;quot;Germany&amp;quot; in the animation consists of the combined number of medals of &amp;quot;East Germany&amp;quot; and &amp;quot;West Germany&amp;quot;.&lt;/p&gt;
&lt;h3 id=&quot;fun-with-flags&quot;&gt;Fun with Flags&lt;/h3&gt;
&lt;p&gt;Update: After being made aware of the concurrent &lt;a href=&quot;http://pmassicotte.github.io/2016-08-25-olympics2016&quot;&gt;blog entry&lt;/a&gt; by &lt;a href=&quot;https://www.researchgate.net/profile/Philippe_Massicotte&quot;&gt;Philippe Massicotte&lt;/a&gt; on how to visualize the Rio medal table using the &lt;code&gt;ggflags&lt;/code&gt; package, the above gapminder visualization can easily be extended to use flags instead of nation names. As the &lt;code&gt;ggflags&lt;/code&gt; package only contains the flags of currently existing countries we start the visualization in 1990. For better visability we also add the trajectory of each nation.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-08-21-gapMedal/olympicMedals-flags.gif&quot; /&gt;
&lt;/figure&gt;
&lt;h3 id=&quot;number-of-medals-per-population&quot;&gt;Number of Medals per Population&lt;/h3&gt;
&lt;p&gt;To see the medal tables in a different light, we instead visualize a quantity relative to the number of medals per population. To enable cross-year comparisons we therefore compute the following index for each country and olympic summer games: &lt;span class=&quot;math display&quot;&gt;\[
\frac{\text{Fraction of All Medals the Country got in that Year}}{\text{Population in the Country that Year}} \times 10^6.
\]&lt;/span&gt; We shall call this index a country&#39;s fraction of all medals per million population. A similar animation as above, now with logarithmic y-axis, illustrates the dynamics. To provide &lt;strong&gt;evidence supported neighbour mocking&lt;/strong&gt;, we highlight the position of the three Nordic countries (Denmark, Sweden and Norway).&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-08-21-gapMedal/olympicMedals-perpop-gapminder-style.gif&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;Jamaica, Bahamas and Grenada appear to do reasonably well lately compared to their population size. However, more more important - did you noticed the position of Denmark at the 2016 games in Rio?&lt;/p&gt;
&lt;div id=&quot;refs&quot; class=&quot;references&quot;&gt;

&lt;/div&gt;
</description>
        <pubDate>Sun, 21 Aug 2016 00:00:00 +0200</pubDate>
        <link>http://staff.math.su.se/hoehle/blog/2016/08/21/gapMedal.html</link>
        <guid isPermaLink="true">http://staff.math.su.se/hoehle/blog/2016/08/21/gapMedal.html</guid>
        
        <category>datascience</category>
        
        <category>rstats</category>
        
        <category>olympic games</category>
        
        
      </item>
    
      <item>
        <title>No Sleep During the Reproducibility Session</title>
        <description>&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;R code is provided for implementing a statistical method by &lt;span class=&quot;citation&quot; data-cites=&quot;nishiura_etal2016&quot;&gt;Nishiura, Miyamatsu, and Mizumoto (2016)&lt;/span&gt; to assess when to declare the end of an outbreak of a person-to-person transmitted disease. The motivating example is the MERS-CoV outbreak in Korea, 2015. From a greater perspective, the blog entry is an attempt to advocate for spicing up statistical conferences by a &lt;strong&gt;reproducibility session&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;br&gt; &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width:0&quot; src=&quot;https://i.creativecommons.org/l/by-sa/4.0/88x31.png&quot;/&gt;&lt;/a&gt; This work is licensed under a &lt;a rel=&quot;license&quot;
href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt;. The markdown+Rknitr source code of this blog is available under a &lt;a href=&quot;https://www.gnu.org/licenses/gpl-3.0.html&quot;&gt;GNU General Public License (GPL v3)&lt;/a&gt; license from &lt;a href=&quot;https://github.com/hoehleatsu/hoehleatsu.github.io&quot;&gt;&lt;img src=&quot;/hoehle/blog/images/GitHub-Mark-32px.png&quot; alt=&quot;github&quot; /&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;A few weeks ago I went to the &lt;a href=&quot;https://biometricconference.org/&quot;&gt;International Biometric Conference (IBC)&lt;/a&gt; in Victoria. Conferences are good for meeting people, but with respect to scientific content, there is typically no more than 2-3 talks in a week, which you really remember. Partly, this is due to the format of statistics conferences not developing much in recent decades: it is plenary talks, invited sessions, contributed sessions, showcase sessions and poster sessions all over. However, some developments have occurred, e.g.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the German joint statistical meeting introduced the concept of a &lt;a href=&quot;http://www.uni-goettingen.de/de/501387.html&quot;&gt;stats bazaar&lt;/a&gt; talk.&lt;/li&gt;
&lt;li&gt;the &lt;a href=&quot;http://user2016.org/&quot;&gt;R User Conference&lt;/a&gt; has added some interesting additional formats, e.g. lightning talks, in order to make life at a conference more interesting. Thomas Leeper has written an inspiring &lt;a href=&quot;http://thomasleeper.com/2015/07/user2015-lessons/&quot;&gt;blog post&lt;/a&gt; about this issue.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Not all science is &#39;fun&#39;, but when balancing between adding yet-another-table-from-a-simulation-study against 95% of the audience dozing off, I urge you to aim for an awake audience.&lt;/p&gt;
&lt;p&gt;So here is an additional session format in the spirit of &lt;strong&gt;reproducible science&lt;/strong&gt;, which might help make statistics conference more alive again: Take the contents of a talk, find the corresponding paper/technical report/slides, download the data (of course these are available) and start implementing. After all, hacking a statistical method is the best way to understand it and reproducing the results of an analysis is a form of peer-review we should do much more as statisticians. The important &lt;a href=&quot;The%20Importance%20of%20Reproducible%20Research%20in%20High-Throughput%20Biology:%20Case%20Studies%20in%20Forensic%20Bioinformatics&quot;&gt;talk&lt;/a&gt; by &lt;a href=&quot;http://odin.mdacc.tmc.edu/~kabaggerly/&quot;&gt;Keith A. Baggerly&lt;/a&gt; about reproducibility in bioinformatics more than underlines this.&lt;/p&gt;
&lt;p&gt;As a consequence, this blog entry is my attempt of a &lt;strong&gt;repro-session&lt;/strong&gt; in connection with the IBC: The talk entitled &lt;em&gt;&lt;a href=&quot;https://biometricconference.org/contributed-sessions/oral/detail/?sessionID=CS.15&quot;&gt;Determining the end of an epidemic with human-to-human transmission&lt;/a&gt;&lt;/em&gt; by &lt;a href=&quot;http://plaza.umin.ac.jp/~infepi/hnishiura.htm&quot;&gt;Hiroshi Nishiura&lt;/a&gt; was both interesting, from a field I&#39;m interested in (infectious disease epidemiology) and the method looked like it could be re-implemented in finite time. The question the method tries to answer is the following: at which time point can one declare an outbreak of a person-to-person transmitted disease as having ended? Answering this question can be important in order to calm the population, attract tourists again, export goods or reduce alertness status. The current WHO method for answering the question requires that a period of two times the longest possible incubation time needs to have passed since the last cases before an outbreak can be declared as being over. However, as stated in their paper (&lt;span class=&quot;citation&quot; data-cites=&quot;nishiura_etal2016&quot;&gt;Nishiura, Miyamatsu, and Mizumoto (2016)&lt;/span&gt;), the criterion clearly lacks a statistical motivation. As an improvement Nishiura and co-workers formulate a statistical criterion based on the serial interval distribution and the offspring distribution.&lt;/p&gt;
&lt;p&gt;In what follows we shall quickly describe their method and apply it to their motivating example, which was the 2015 MERS-CoV outbreak in Korea. As a small outlook, we shall implement some own thoughts on how to answer the posed questions using a hierarchical model.&lt;/p&gt;
&lt;h1 id=&quot;method&quot;&gt;Method&lt;/h1&gt;
&lt;p&gt;Let &lt;span class=&quot;math inline&quot;&gt;\(Y_t\)&lt;/span&gt; be a count variable representing the number of symptom onset in cases we observe on a given day &lt;span class=&quot;math inline&quot;&gt;\(t\)&lt;/span&gt; during the outbreak. The sequence of the &lt;span class=&quot;math inline&quot;&gt;\(Y_t\)&lt;/span&gt; is also called the &lt;a href=&quot;http://www.cdc.gov/foodsafety/outbreaks/investigating-outbreaks/epi-curves.html&quot;&gt;&lt;strong&gt;epidemic cuve&lt;/strong&gt;&lt;/a&gt; of the outbreak. Furthermore, let &lt;span class=&quot;math inline&quot;&gt;\(D=\{t_i; i=1,\ldots,n\}\)&lt;/span&gt;, be the currently available outbreak data containing the time of symptom onset in in each of the &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; cases of the outbreak. In what follows we will be interested in what happens with &lt;span class=&quot;math inline&quot;&gt;\(Y_t\)&lt;/span&gt; for future time points, i.e. time points after the last currently observed onset time. In particular we will be interested in, whether we will observe zero cases or more than zero cases.&lt;/p&gt;
&lt;p&gt;The important result of &lt;span class=&quot;citation&quot; data-cites=&quot;nishiura_etal2016&quot;&gt;Nishiura, Miyamatsu, and Mizumoto (2016)&lt;/span&gt; is that the probability &lt;span class=&quot;math inline&quot;&gt;\(\pi_t = P(Y_t &amp;gt; 0\&amp;gt;|\&amp;gt;D)\)&lt;/span&gt; can be computed as follows: &lt;span class=&quot;math display&quot;&gt;\[
\begin{align*}
\pi_t = 1 - \prod_{i=1}^n \sum_{o=0}^{\infty} f_{\text{offspring}}(o; R_0, k) \cdot \left[ F_{\text{serial}}(t-t_i) \right]^{o},
\end{align*}
\]&lt;/span&gt; where &lt;span class=&quot;math inline&quot;&gt;\(f_{\text{offspring}}\)&lt;/span&gt; denotes the PMF for the number of secondary cases one primary case induces. It is assumed that this distribution is negative binomial with expectation &lt;span class=&quot;math inline&quot;&gt;\(R_0&amp;gt;0\)&lt;/span&gt; and clumping parameter &lt;span class=&quot;math inline&quot;&gt;\(k&amp;gt;0\)&lt;/span&gt;. In other words, &lt;span class=&quot;math inline&quot;&gt;\(\operatorname{E}(O)=R_0\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(\operatorname{Var}(O)=R_0 + R_0^2/k\)&lt;/span&gt;. Furthermore, &lt;span class=&quot;math inline&quot;&gt;\(F_{\text{serial}}\)&lt;/span&gt; denotes the CDF of the serial interval distribution of the disease of interest. The serial interval is the time period between the onset of symptoms in the primary and onset of symptoms in the secondary case, see &lt;span class=&quot;citation&quot; data-cites=&quot;svensson2007&quot;&gt;Svensson (2007)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Once &lt;span class=&quot;math inline&quot;&gt;\(\pi_t\)&lt;/span&gt; is below some pre-defined threshold &lt;span class=&quot;math inline&quot;&gt;\(c\)&lt;/span&gt;, say &lt;span class=&quot;math inline&quot;&gt;\(c=0.05\)&lt;/span&gt;, one would declare the outbreak to be over, if no new cases have been observed by time &lt;span class=&quot;math inline&quot;&gt;\(t\)&lt;/span&gt;. In other words: &lt;span class=&quot;math display&quot;&gt;\[
T_{\text{end}} = \min_{t&amp;gt;t^*} \{ \pi_t &amp;lt; c \}.
\]&lt;/span&gt; where &lt;span class=&quot;math inline&quot;&gt;\(t^* = \max_{i=1,\ldots,n} t_i\)&lt;/span&gt;, i.e. the onset time in the last observed case.&lt;/p&gt;
&lt;p&gt;Note that the formulated approach is conservative, because every available case is treated as having the potential to generate new secondary cases according to the entire offspring distribution. In practice, however, observed cases towards the end will be secondary cases of some of the earlier cases. Hence, these primary cases will be attributed as having the ability to generate more secondary cases than they actually have in practice. Another important assumption of the method is that all cases are observed: no asymptomatic cases nor under-reporting is taken into account.&lt;/p&gt;
&lt;h2 id=&quot;data-from-the-mers-cov-oubtreak-in-korea-2015&quot;&gt;Data from the MERS-Cov Oubtreak in Korea, 2015&lt;/h2&gt;
&lt;p&gt;The data basis for our analysis is the WHO data set on the &lt;a href=&quot;http://www.who.int/csr/don/21-july-2015-mers-korea/en/&quot;&gt;MERS-Cov outbreak in Korea&lt;/a&gt;, which occurred during May-July 2015. It contains the information about 185 cases of the MERS-CoV outbreak in Korea, 2015. These were already analysed in a previous &lt;a href=&quot;./2016-07-19-nowCast.Rmd&quot;&gt;blog entry&lt;/a&gt; for the purpose of nowcasting. However, we shall now be interested in answering the following question: Given the observations of symptoms on the last (known) case on 2015-07-02. How many days without new infections would have to pass, before we would declare the outbreak as having &lt;strong&gt;ended&lt;/strong&gt;?&lt;/p&gt;
&lt;h2 id=&quot;results&quot;&gt;Results&lt;/h2&gt;
&lt;p&gt;In what follows we shall distinguish results between model parameters to be estimated from data and the computation of the probability &lt;span class=&quot;math inline&quot;&gt;\(\pi_t\)&lt;/span&gt;. Focus of this blog entry is on the later part. Details on the first part is available in the code.&lt;/p&gt;
&lt;h2 id=&quot;parameter-estimation&quot;&gt;Parameter Estimation&lt;/h2&gt;
&lt;p&gt;The parameters to estimate are the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;parameters of the parametric distributional family governing the serial interval distribution (in &lt;span class=&quot;citation&quot; data-cites=&quot;nishiura_etal2016&quot;&gt;Nishiura, Miyamatsu, and Mizumoto (2016)&lt;/span&gt; this is assumed to be a gamma distribution)&lt;/li&gt;
&lt;li&gt;parameters of the offspring distribution, which here is assumed to be negative binomial with mean &lt;span class=&quot;math inline&quot;&gt;\(R_0\)&lt;/span&gt; and clumping parameter &lt;span class=&quot;math inline&quot;&gt;\(k\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The first step is easily accomplished in &lt;span class=&quot;citation&quot; data-cites=&quot;nishiura_etal2015&quot;&gt;Nishiura et al. (2015)&lt;/span&gt; by solving for given mean and standard deviation for the serial interval distribution observed in secondary data - see the paper for details. The solution can be found analytically given the values.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;E &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;12.6&lt;/span&gt;
SD &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;2.8&lt;/span&gt;
(theta_serial &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(E^&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;/SD^&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;,E/SD^&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## [1] 20.25  1.61&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The second part is addressed in &lt;span class=&quot;citation&quot; data-cites=&quot;nishiura_etal2015&quot;&gt;Nishiura et al. (2015)&lt;/span&gt; by analysing final-size and generation data using a maximum likelihood approach. We will here only implement the methods using the data presented in Figure 1 and Table 1 of the paper. Unfortunately, one cluster size is not immediately reconstructable from the data in the paper, but guesstimating from the table on p.4 of the &lt;a href=&quot;http://ecdc.europa.eu/en/publications/Publications/RRA-Middle-East-respiratory-syndrome-coronavirus-Korea.pdf&quot;&gt;ECDC Rapid Risk Assessment&lt;/a&gt; it appears to be the outbreak in Jordan with a size of 19. The likelihood is then maximized for &lt;span class=&quot;math inline&quot;&gt;\(\mathbf{\theta}=(\log(R_0),\log(k))&amp;#39;\)&lt;/span&gt; using &lt;code&gt;optim&lt;/code&gt;. Based on the Hessian, a numeric approximation of the variance-covariance matrix of &lt;span class=&quot;math inline&quot;&gt;\(\hat{\mathbf{\theta}}\)&lt;/span&gt; can be obtained.&lt;/p&gt;
&lt;p&gt;Altogether, we maximize the combined likelihood consisting of 36 as well as the corresponding number of generations by:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;theta_mle &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;optim&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;log&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;),&lt;span class=&quot;kw&quot;&gt;log&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)),ll_combine, &lt;span class=&quot;dt&quot;&gt;outbreaks=&lt;/span&gt;outbreaks, &lt;span class=&quot;dt&quot;&gt;control=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;fnscale=&lt;/span&gt;-&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;),&lt;span class=&quot;dt&quot;&gt;hessian=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;)
&lt;span class=&quot;kw&quot;&gt;exp&lt;/span&gt;(theta_mle$par)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.826 0.128&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These numbers deviate slightly from the values of &lt;span class=&quot;math inline&quot;&gt;\(\hat{R}_0=0.75\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(\hat{k}=0.14\)&lt;/span&gt; reported by &lt;span class=&quot;citation&quot; data-cites=&quot;nishiura_etal2015&quot;&gt;Nishiura et al. (2015)&lt;/span&gt;. One explanation might be the unclear cluster size of the Jordan outbreak, here it would have been helpful to have had all data directly available in electronic form.&lt;/p&gt;
&lt;h2 id=&quot;outbreak-end&quot;&gt;Outbreak End&lt;/h2&gt;
&lt;p&gt;The above &lt;span class=&quot;math inline&quot;&gt;\(\pi_t\)&lt;/span&gt; equation is implemented below as function &lt;code&gt;p_oneormore&lt;/code&gt;. It requires the use of the PMF of the offspring distribution (&lt;code&gt;doffspring&lt;/code&gt;), which here is the negative binomial offspring distribution.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Offspring distribution, this is just the negative binomial PMF.
doffspring &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(y, R_0, k, &lt;span class=&quot;dt&quot;&gt;log=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;FALSE&lt;/span&gt;) {
  &lt;span class=&quot;kw&quot;&gt;dnbinom&lt;/span&gt;(y, &lt;span class=&quot;dt&quot;&gt;mu=&lt;/span&gt;R_0, &lt;span class=&quot;dt&quot;&gt;size=&lt;/span&gt;k, &lt;span class=&quot;dt&quot;&gt;log=&lt;/span&gt;log)
}

##Probability for one or more cases at time t.
p_oneormore &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;Vectorize&lt;/span&gt;(function(t,R_0,k,theta_serial,&lt;span class=&quot;dt&quot;&gt;yMax=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;1e4&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;verbose=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;FALSE&lt;/span&gt;) {
  if (verbose) &lt;span class=&quot;kw&quot;&gt;cat&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;paste0&lt;/span&gt;(t,&lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;ch&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;))
  res &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;

  ##Loop over all cases as in eqn (1) of the suppl. of Nishiura (2016).
  ##Setup process bar for this action.
  if (verbose) {
    pb &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;startpb&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;kw&quot;&gt;nrow&lt;/span&gt;(linelist))
    &lt;span class=&quot;kw&quot;&gt;on.exit&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;closepb&lt;/span&gt;(pb))
  }

  for (i in &lt;span class=&quot;kw&quot;&gt;seq_len&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;nrow&lt;/span&gt;(linelist))) {
    if (verbose) { &lt;span class=&quot;kw&quot;&gt;setpb&lt;/span&gt;(pb, i) }
    serial_time &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;as.numeric&lt;/span&gt;(t -&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;linelist$Date.of.symptoms.onset[i])
    cdf &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;pgamma&lt;/span&gt;(serial_time, theta_serial[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;], theta_serial[&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;])
    y &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;0L:yMax
    ysum &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;sum&lt;/span&gt;( &lt;span class=&quot;kw&quot;&gt;doffspring&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;y=&lt;/span&gt;y,&lt;span class=&quot;dt&quot;&gt;R_0=&lt;/span&gt;R_0,&lt;span class=&quot;dt&quot;&gt;k=&lt;/span&gt;k)*cdf^y)
    res &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;res *&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;ysum
  }
  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;-res)
},&lt;span class=&quot;dt&quot;&gt;vectorize.args=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;t&amp;quot;&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;R_0&amp;quot;&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;k&amp;quot;&lt;/span&gt;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The function allows us to re-calculate the results of &lt;span class=&quot;citation&quot; data-cites=&quot;nishiura_etal2016&quot;&gt;Nishiura, Miyamatsu, and Mizumoto (2016)&lt;/span&gt;:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Results from the Nishiura et al. (2015) paper
##R_0_hat &amp;lt;- 0.75 ; k_hat &amp;lt;- 0.14
##Use MLE found with the data we were able to extract.
R_0_hat &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;exp&lt;/span&gt;(theta_mle$par[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;])
k_hat   &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;exp&lt;/span&gt;(theta_mle$par[&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;])

## Compute prob for one or more cases on a grid of dates
df &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;data_frame&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;t=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;seq&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;as.Date&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;2015-07-15&amp;quot;&lt;/span&gt;),&lt;span class=&quot;kw&quot;&gt;as.Date&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;2015-08-05&amp;quot;&lt;/span&gt;),&lt;span class=&quot;dt&quot;&gt;by=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;1 day&amp;quot;&lt;/span&gt;))
df &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;df %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;mutate&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;pi =&lt;/span&gt;  &lt;span class=&quot;kw&quot;&gt;p_oneormore&lt;/span&gt;(t,&lt;span class=&quot;dt&quot;&gt;R_0=&lt;/span&gt;R_0_hat, &lt;span class=&quot;dt&quot;&gt;k=&lt;/span&gt;k_hat, &lt;span class=&quot;dt&quot;&gt;theta_serial=&lt;/span&gt;theta_serial, &lt;span class=&quot;dt&quot;&gt;yMax=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;250&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;verbose=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;FALSE&lt;/span&gt;))
&lt;span class=&quot;kw&quot;&gt;head&lt;/span&gt;(df, &lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## Source: local data frame [3 x 2]
## 
##            t    pi
##       (date) (dbl)
## 1 2015-07-15 0.366
## 2 2015-07-16 0.297
## 3 2015-07-17 0.226&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can embed estimation uncertainty originating from the estimation of &lt;span class=&quot;math inline&quot;&gt;\(R_0\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(k\)&lt;/span&gt; by adding an additional bootstrap step with values of &lt;span class=&quot;math inline&quot;&gt;\((\log R_0, \log k)&amp;#39;\)&lt;/span&gt; sampled from the asymptotic normal distribution. This distribution has expectation equal to the MLE and variance-covariance matrix equal to the observed Fisher information. Pointwise percentile-based 95% confidence intervals are then easily computed. The figure below shows this 95% CI (shaded area) together with the &lt;span class=&quot;math inline&quot;&gt;\(\pi_t\)&lt;/span&gt; curve.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-08-04-outbreakEnd/unnamed-chunk-8-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;Altogether, the date where we would declare the outbreak to be over is found as:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;c_threshold &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.05&lt;/span&gt;
(tEnd &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;df2 %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;filter&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;dt&quot;&gt;quantile.97.5%&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;`&lt;/span&gt; &amp;lt;&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;c_threshold) %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;slice&lt;/span&gt;(1L))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##            t     pi quantile.2.5% quantile.97.5%
## 1 2015-07-21 0.0345        0.0253         0.0454&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In other words, given the assumptions of the model and the chosen threshold, we would declare the outbreak to be over, if no new cases are observed by 2015-07-21. The adequate choice of &lt;span class=&quot;math inline&quot;&gt;\(c\)&lt;/span&gt; as cut-off in the procedure in general depends on what is at stake. Hence, choosing &lt;span class=&quot;math inline&quot;&gt;\(c=0.05\)&lt;/span&gt; without additional thought is more than arbitrary, but a more careful discussion is beyond the scope of this blog note.&lt;/p&gt;
&lt;h2 id=&quot;hierarchical-model&quot;&gt;Hierarchical model&lt;/h2&gt;
&lt;p&gt;Commenting on the derivations done in &lt;span class=&quot;citation&quot; data-cites=&quot;nishiura_etal2016&quot;&gt;Nishiura, Miyamatsu, and Mizumoto (2016)&lt;/span&gt; from a Bayesian viewpoint, it appears more natural to formulate the model directly in hierarchical terms:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
\begin{align*}
N_i                  &amp;amp;\sim \operatorname{NegBin}(R_0,k),                    &amp;amp; i&amp;amp;=1,\ldots,n,\\
\mathbf{O}_i\&amp;gt;|\&amp;gt;N_i &amp;amp;\sim \operatorname{M}(N_i,\mathbf{p}_{\text{serial}}),&amp;amp; i&amp;amp;=1,\ldots,n,\\
Y_t\&amp;gt;|\&amp;gt; \mathbf{O}  &amp;amp;= \sum_{i=1}^n O_{i,t_i-t}, &amp;amp; t&amp;amp;=t^*+1,t^*+2,\ldots,\\
\end{align*}
\]&lt;/span&gt; where &lt;span class=&quot;math inline&quot;&gt;\(\mathbf{p}_{\text{serial}}\)&lt;/span&gt; is the PMF of the discretized serial interval distribution for exampling obtained by computing &lt;span class=&quot;math inline&quot;&gt;\(p_{y} = F_{\text{serial}}(y) - F_{\text{serial}}(y-1)\)&lt;/span&gt; for &lt;span class=&quot;math inline&quot;&gt;\(0&amp;lt;y\leq S\)&lt;/span&gt;, where &lt;span class=&quot;math inline&quot;&gt;\(S\)&lt;/span&gt; is the largest possible/relevant serial interval to consider, and letting &lt;span class=&quot;math inline&quot;&gt;\(p_{0} = 0\)&lt;/span&gt;. Furthermore, &lt;span class=&quot;math inline&quot;&gt;\(O_{i,t_i-t}=0\)&lt;/span&gt; if &lt;span class=&quot;math inline&quot;&gt;\(t_i-t&amp;lt;0\)&lt;/span&gt; or &lt;span class=&quot;math inline&quot;&gt;\(t_i-t&amp;gt;S\)&lt;/span&gt; and corresponds to the value obtained from &lt;span class=&quot;math inline&quot;&gt;\(M(N_i,\mathbf{p}_{\text{serial}})\)&lt;/span&gt; otherwise. Finally, &lt;span class=&quot;math inline&quot;&gt;\(\mathbf{O}=(\mathbf{O}_1,\ldots,\mathbf{O}_n)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Given &lt;span class=&quot;math inline&quot;&gt;\(R_0\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(k\)&lt;/span&gt; it is easy to use Monte Carlo simulation to obtain instances of &lt;span class=&quot;math inline&quot;&gt;\(Y_t\)&lt;/span&gt; for a selected time-range from the above model. The code for this function &lt;code&gt;simulation&lt;/code&gt; is available as part of this R-markdown document (again, see the underlying source on the github repository for details). Similarly to the previous model the hierarchical model is also slightly conservative, because it does not take existing secondary cases in the data into account and samples &lt;span class=&quot;math inline&quot;&gt;\(N_i\)&lt;/span&gt; new secondary cases for each observed case.&lt;/p&gt;
&lt;p&gt;Since we for this model will be using simulations it is easy to modify the criterion for fade-out slightly to the more natural probability &lt;span class=&quot;math inline&quot;&gt;\(\pi_t^*\)&lt;/span&gt; that no case at &lt;span class=&quot;math inline&quot;&gt;\(t\)&lt;/span&gt; &lt;em&gt;nor beyond &lt;span class=&quot;math inline&quot;&gt;\(t\)&lt;/span&gt;&lt;/em&gt; will occur, i.e. &lt;span class=&quot;math display&quot;&gt;\[
\pi_t^* = P\left( \bigwedge_{i=t}^\infty \{Y_t = 0\} \right).
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We perform a study with 10000 different simulations each evaluated on a grid from 2015-07-03 to 2015-07-27. The resulting values are stored in the &lt;span class=&quot;math inline&quot;&gt;\(25 \times 10000\)&lt;/span&gt; matrix &lt;code&gt;Y&lt;/code&gt; from which we can compute:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;pi &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;apply&lt;/span&gt;(Y,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,mean)
pi[pi &amp;lt;&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;c_threshold]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## 2015-07-21 2015-07-22 2015-07-23 2015-07-24 2015-07-25 2015-07-26 2015-07-27 
##     0.0341     0.0197     0.0095     0.0037     0.0021     0.0013     0.0004&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Better way to calc extinction prob.
pi_star &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;rev&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;apply&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;apply&lt;/span&gt;(Y,&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;,function(x) &lt;span class=&quot;kw&quot;&gt;cumsum&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;rev&lt;/span&gt;(x))&amp;gt;&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;),&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,mean))
pi_star[pi_star &amp;lt;&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;c_threshold]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## 2015-07-22 2015-07-23 2015-07-24 2015-07-25 2015-07-26 2015-07-27 
##     0.0343     0.0168     0.0075     0.0038     0.0017     0.0004&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We note that the result, when using &lt;span class=&quot;math inline&quot;&gt;\(\pi_t^*\)&lt;/span&gt; instead of &lt;span class=&quot;math inline&quot;&gt;\(\pi_t\)&lt;/span&gt;, leads to the outbreak being declared over one day later. Additional uncertainty handling is performed as before by obtaining bootstrap samples for &lt;span class=&quot;math inline&quot;&gt;\((\log R_0, \log k)&amp;#39;\)&lt;/span&gt; from the asymptotic normal distribution. For each such sample the above Monte Carlo procedure is executed allowing us to determine point-wise confidence intervals for the probability by the percentile method.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-08-04-outbreakEnd/Y_UNCERTAINTY-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;h1 id=&quot;discussion&quot;&gt;Discussion&lt;/h1&gt;
&lt;p&gt;The present note introduced the statistical model based approach of &lt;span class=&quot;citation&quot; data-cites=&quot;nishiura_etal2016&quot;&gt;Nishiura, Miyamatsu, and Mizumoto (2016)&lt;/span&gt; for declaring the end of a person-to-person transmitted disease outbreak such as MERS-Cov, Ebola, etc. If the considered outbreak has a different mode of transmission, e.g. foodborne or originates from a point-source, then different formulas apply, see e.g. &lt;span class=&quot;citation&quot; data-cites=&quot;brookmeyer_you2006&quot;&gt;Brookmeyer and You (2006)&lt;/span&gt;. Interestingly enough, there appears to be some methodological overlap between declaring the end of an outbreak and declaring a software product to be free of errors.&lt;/p&gt;
&lt;p&gt;To summarise: The results of the &lt;span class=&quot;citation&quot; data-cites=&quot;nishiura_etal2016&quot;&gt;Nishiura, Miyamatsu, and Mizumoto (2016)&lt;/span&gt; paper could - with some fiddling to guesstimate the data - be approximately reproduced. A hierarchical model with simulation based inference was able to produce similar results. Availability of the full data in electronic form would have been helpful. Altoghether, it was fun to implement the method and hope is that the avaibility of the present analysis and R code might be helpful to someone at some point. You are certainly invited to &lt;strong&gt;reprofy&lt;/strong&gt; the present analysis.&lt;/p&gt;
&lt;center&gt;
&lt;embed src=&quot;https://openclipart.org/image/300px/svg_to_png/169987/copy.png&amp;amp;disposition=attachment&quot; /&gt;
&lt;/center&gt;
&lt;p&gt;
&lt;h3 id=&quot;acknowledgements&quot;&gt;Acknowledgements&lt;/h3&gt;
&lt;p&gt;I thank Hiroshi Nishiura for answering questions about their paper.&lt;/p&gt;
&lt;h1 id=&quot;references&quot; class=&quot;unnumbered&quot;&gt;References&lt;/h1&gt;
&lt;div id=&quot;refs&quot; class=&quot;references&quot;&gt;
&lt;div id=&quot;ref-brookmeyer_you2006&quot;&gt;
&lt;p&gt;Brookmeyer, R., and X. You. 2006. “A hypothesis test for the end of a common source outbreak.” &lt;em&gt;Biometrics&lt;/em&gt; 62 (1): 61–65. doi:&lt;a href=&quot;https://doi.org/10.1111/j.1541-0420.2005.00421.x&quot;&gt;10.1111/j.1541-0420.2005.00421.x&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-nishiura_etal2016&quot;&gt;
&lt;p&gt;Nishiura, H., Y. Miyamatsu, and K. Mizumoto. 2016. “Objective Determination of End of MERS Outbreak, South Korea, 2015.” &lt;em&gt;Emerging Infect. Dis.&lt;/em&gt; 22 (1): 146–48. doi:&lt;a href=&quot;https://doi.org/10.3201/eid2201.151383&quot;&gt;10.3201/eid2201.151383&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-nishiura_etal2015&quot;&gt;
&lt;p&gt;Nishiura, H., Y. Miyamatsu, G. Chowell, and M. Saitoh. 2015. “Assessing the risk of observing multiple generations of Middle East respiratory syndrome (MERS) cases given an imported case.” &lt;em&gt;Euro Surveill.&lt;/em&gt; 20 (27). doi:&lt;a href=&quot;https://doi.org/10.2807/1560-7917.ES2015.20.27.21181 &quot;&gt;10.2807/1560-7917.ES2015.20.27.21181&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-svensson2007&quot;&gt;
&lt;p&gt;Svensson, Å. 2007. “A note on generation times in epidemic models.” &lt;em&gt;Math Biosci&lt;/em&gt; 208 (1): 300–311. doi:&lt;a href=&quot;https://doi.org/10.1016/j.mbs.2006.10.010&quot;&gt;10.1016/j.mbs.2006.10.010&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
        <pubDate>Thu, 04 Aug 2016 00:00:00 +0200</pubDate>
        <link>http://staff.math.su.se/hoehle/blog/2016/08/04/outbreakEnd.html</link>
        <guid isPermaLink="true">http://staff.math.su.se/hoehle/blog/2016/08/04/outbreakEnd.html</guid>
        
        <category>rstats</category>
        
        <category>infectious disease epidemiology</category>
        
        <category>open data</category>
        
        <category>MERS</category>
        
        
      </item>
    
      <item>
        <title>Casting Call for MERS-CoV in Korea, 2015</title>
        <description>&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;We perform an adjustment for observed-but-not-yet-reported cases (aka. nowcasting) for the epidemic curve of the Middle East respiratory syndrome coronavirus (MERS-CoV) outbreak in Korea, 2015. The analysis is based on the publically available WHO data and aims at illustrating how one could do real-time public health surveillance during critical outbreaks.&lt;/p&gt;
&lt;p&gt;&lt;br&gt; &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width:0&quot; src=&quot;https://i.creativecommons.org/l/by-sa/4.0/88x31.png&quot;/&gt;&lt;/a&gt; This work is licensed under a &lt;a rel=&quot;license&quot;
href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt;. The markdown+Rknitr source code of this blog is available under a &lt;a href=&quot;https://www.gnu.org/licenses/gpl-3.0.html&quot;&gt;GNU General Public License (GPL v3)&lt;/a&gt; license from &lt;a href=&quot;https://github.com/hoehleatsu/hoehleatsu.github.io&quot;&gt;&lt;img src=&quot;/hoehle/blog/images/GitHub-Mark-32px.png&quot; alt=&quot;github&quot; /&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Short-range (0-6h) forecasts in the world of meteorology are also called &lt;strong&gt;nowcasts&lt;/strong&gt;. The term has also found its way into real-time infectious disease monitoring where one of its uses has been to adjust the currently available epidemic curve during an outbreak for structural and reporting delays.&lt;/p&gt;
&lt;p&gt;Whereas the original work in &lt;span class=&quot;citation&quot; data-cites=&quot;hoehle_anderheiden2014&quot;&gt;Höhle and an der Heiden (2014)&lt;/span&gt; was motivated by the large STEC O104:H4 outbreak in Germany 2011, one of our secondary motivations was to develop a tool the quantitative epidemiologist could use during similar high-profiled outbreaks (instead of having to re-invent the wheel during times of maximal stress). After my talk at the &lt;a href=&quot;https://biometricconference.org/showcases/biometrics-showcase/&quot;&gt;IBC2016 conference&lt;/a&gt; (&lt;a href=&quot;http://staff.math.su.se/hoehle/talks/IBC2016-Hoehle.pdf&quot;&gt;slides of the talk&lt;/a&gt;) one of the questions from the audience was how much impact the work had in terms of being useful for other outbreaks. Besides an analysis of an Adenovirus outbreak and a recent analysis of an O157 outbreak, I was a little short on a convincing answer. In addition, when trying to make a quick analysis for the O157 outbreak with the currently available code in the &lt;code&gt;surveillance&lt;/code&gt; package it became obvious that the nowcasting functionality in the package currently is a little rough and certainly in need of a user-friendliness polishing.&lt;/p&gt;
&lt;p&gt;So this little blog-note serves three purposes:&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;Illustrate how you can nowcasts with R, if you ever have to.&lt;/li&gt;
&lt;li&gt;Act as literate programming document for facilitating some code improvements of the &lt;code&gt;nowcast&lt;/code&gt; function while providing a vignette supported story.&lt;/li&gt;
&lt;li&gt;Perform an analysis of the WHO open-data on the MERS-CoV outbreak in Korea in 2015.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The structure of this blog entry is as follows. We first discuss and visualize the WHO data on the MERS-CoV outbreak. The findings from the descriptive data analysis are then used to set up nowcasts adjusting the observed epidemic curve during the outbreak for reporting delays between onset of symptoms in cases and the date the case report arrived at the WHO. Finally, we illustrate how to visualize a sequence of nowcasts during an outbreak using an animation.&lt;/p&gt;
&lt;h1 id=&quot;data&quot;&gt;Data&lt;/h1&gt;
&lt;p&gt;The data basis for our analysis is the WHO data on the &lt;a href=&quot;http://www.who.int/csr/don/21-july-2015-mers-korea/en/&quot;&gt;MERS-Cov outbreak in Korea&lt;/a&gt;, which occured during May-July 2015. Of interest will be the delay (here measured in days) between the time point on which a case has the onset of its MERS symptoms and the day the WHO learns about this case. In other words we put ourself in the role of an epidemiologist working at the WHO and who during the outbreak has to report on how the outbreak is evolving in Korea.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Load library to read excel files
&lt;span class=&quot;kw&quot;&gt;library&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;openxlsx&amp;quot;&lt;/span&gt;)

##Obtain file from link found at (if it doesn&amp;#39;t already exist)
##http://www.who.int/csr/don/21-july-2015-mers-korea/en/
if (!&lt;span class=&quot;kw&quot;&gt;file.exists&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;../downloads/MERS-CoV-cases-rok-21Jul15.xlsx&amp;quot;&lt;/span&gt;)) {
  &lt;span class=&quot;kw&quot;&gt;download.file&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;url=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;http://www.who.int/entity/csr/disease/coronavirus_infections/MERS-CoV-cases-rok-21Jul15.xlsx?ua=1&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;destfile=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;../downloads/MERS-CoV-cases-rok-21Jul15.xlsx&amp;quot;&lt;/span&gt;)
}

##Read data
linelist &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;read.xlsx&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;../downloads/MERS-CoV-cases-rok-21Jul15.xlsx&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;startRow=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;4&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;detectDates=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;)

##Base R style - IMHO easier to understand than the dplyr way to do the same
for (dateCol in &lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;Date.of.notification.to.WHO&amp;quot;&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;Date.of.symptoms.onset&amp;quot;&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;Date.of.first.hospitalization&amp;quot;&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;Date.of.laboratory.confirmation&amp;quot;&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;Date.of.outcome&amp;quot;&lt;/span&gt;)) {
  linelist[,dateCol] &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;as.Date&lt;/span&gt;(linelist[,dateCol],&lt;span class=&quot;dt&quot;&gt;format=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;%d/%m/%Y&amp;quot;&lt;/span&gt;)
}

##Make a delay column
linelist$delay &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;with&lt;/span&gt;(linelist,Date.of.notification.to.WHO -&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;Date.of.symptoms.onset)

&lt;span class=&quot;kw&quot;&gt;head&lt;/span&gt;(linelist,&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##   Case.no. Date.of.notification.to.WHO Age Sex Health.care.worker Comorbidities
## 1        1                  2015-05-20  68   M                 No          &amp;lt;NA&amp;gt;
## 2        2                  2015-05-22  63   F                 No          &amp;lt;NA&amp;gt;
## 3        3                  2015-05-22  76   M                 No          &amp;lt;NA&amp;gt;
##   Date.of.symptoms.onset Date.of.first.hospitalization Date.of.laboratory.confirmation
## 1             2015-05-11                    2015-05-15                      2015-05-20
## 2             2015-05-19                          &amp;lt;NA&amp;gt;                      2015-05-20
## 3             2015-05-20                          &amp;lt;NA&amp;gt;                      2015-05-20
##     Status Date.of.outcome  delay
## 1    Alive            &amp;lt;NA&amp;gt; 9 days
## 2    Alive            &amp;lt;NA&amp;gt; 3 days
## 3 Deceased      2015-06-04 2 days&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As the outbreak is already over, it is easy to visualize the epidemic curve in retrospect. We do so for the date of symptom onset.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Show the epidemic curve as it occurs at the end of the outbreak
##using simple call to ggplot
ggplot2::&lt;span class=&quot;kw&quot;&gt;ggplot&lt;/span&gt;( linelist, &lt;span class=&quot;kw&quot;&gt;aes&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;x=&lt;/span&gt;Date.of.symptoms.onset)) +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;geom_histogram&lt;/span&gt;() +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;xlab&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;Date of onset of symptoms&amp;quot;&lt;/span&gt;) +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;ylab&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;Number of cases&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-07-19-nowCast/EPICURVE-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;Furthermore, we can look at the delay distribution as it looks at the end of the outbreak. We shall later look in more detail at this distribution, but for now the plot gives an idea about the range of the delay: in most cases the delay is between 1-14 days, actually 97.1% of the observations have a lag smaller or equal to &lt;span class=&quot;math inline&quot;&gt;\(D=14\)&lt;/span&gt;. As a consequence, we shall use &lt;span class=&quot;math inline&quot;&gt;\(D=14\)&lt;/span&gt; as the maximum relevant lag to adjust for.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;ggplot&lt;/span&gt;( linelist, &lt;span class=&quot;kw&quot;&gt;aes&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;x=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;as.integer&lt;/span&gt;(delay),&lt;span class=&quot;dt&quot;&gt;y=&lt;/span&gt;..prop..)) +
&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;stat_count&lt;/span&gt;() +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;scale_y_continuous&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;labels =&lt;/span&gt; scales::percent) +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;xlab&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;Delay (days)&amp;quot;&lt;/span&gt;) +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;ylab&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-07-19-nowCast/unnamed-chunk-3-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;Instead of using &lt;code&gt;ggplot&lt;/code&gt; to show the epidemic curve, this can also be done directly from the surveillance package using the function &lt;code&gt;linelist2sts&lt;/code&gt;. This function takes a &lt;code&gt;data.frame&lt;/code&gt; representing a linelist and converts this into an object of class &lt;code&gt;sts&lt;/code&gt; (surveillance time series) used by the package. This then allows the use of all the plotting functionality of such objects as described in &lt;span class=&quot;citation&quot; data-cites=&quot;salmon_etal2016a&quot;&gt;Salmon, Schumacher, and Höhle (2016)&lt;/span&gt;. Note: For the nowcasting code of this blog entry to work, the newest development version of the package, i.e. version 1.12.2 available from Rforge using&lt;/p&gt;
&lt;p&gt;
&lt;center&gt;
&lt;code&gt;install.packages(&amp;quot;surveillance&amp;quot;,repos=&amp;quot;http://r-forge.r-project.org&amp;quot;)&lt;/code&gt;
&lt;/center&gt;
&lt;p&gt;
&lt;p&gt;is needed. The code then looks as follows:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Load surveillance pkg.
&lt;span class=&quot;kw&quot;&gt;library&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;surveillance&amp;quot;&lt;/span&gt;)

##Range of the symptom onset date variable
so_range &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;range&lt;/span&gt;(linelist$Date.of.symptoms.onset,&lt;span class=&quot;dt&quot;&gt;na.rm=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;)

##Create an sts time series from the linelist, which contains daily counts.
sts &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;linelist2sts&lt;/span&gt;(linelist, &lt;span class=&quot;dt&quot;&gt;dateCol=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;Date.of.symptoms.onset&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;aggregate.by=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;1 day&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;dRange=&lt;/span&gt;so_range)

##Show the resulting time series using the plot functionality for sts objects.
&lt;span class=&quot;kw&quot;&gt;plot&lt;/span&gt;(sts,&lt;span class=&quot;dt&quot;&gt;legend.opts=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;NULL&lt;/span&gt;,
     &lt;span class=&quot;dt&quot;&gt;xaxis.tickFreq=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;%d&amp;quot;&lt;/span&gt;=atChange,&lt;span class=&quot;st&quot;&gt;&amp;quot;%m&amp;quot;&lt;/span&gt;=atChange),
     &lt;span class=&quot;dt&quot;&gt;xaxis.labelFreq=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;%d&amp;quot;&lt;/span&gt;=at2ndChange),&lt;span class=&quot;dt&quot;&gt;xaxis.labelFormat=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;%d-%b&amp;quot;&lt;/span&gt;,
     &lt;span class=&quot;dt&quot;&gt;xlab=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;Time (days)&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;lty=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;),&lt;span class=&quot;dt&quot;&gt;lwd=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;),
     &lt;span class=&quot;dt&quot;&gt;ylab=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;No. symptom onsets&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-07-19-nowCast/EPICURVE-SURVEILLANCE-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;h2 id=&quot;nowcasting&quot;&gt;Nowcasting&lt;/h2&gt;
&lt;p&gt;We now move on to the nowcasts.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##State which date to nowcast
now &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;as.Date&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;2015-06-12&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Say (in a mathematical sense) we move back time to 2015-06-12. In the notation of &lt;span class=&quot;citation&quot; data-cites=&quot;hoehle_anderheiden2014&quot;&gt;Höhle and an der Heiden (2014)&lt;/span&gt; this means &lt;span class=&quot;math inline&quot;&gt;\(T=2015-06-12\)&lt;/span&gt;. We want to illustrate what the WHO could see at this point and, on the basis on how the available reports, estimate the delay distribution and adjust the observed cases accordingly. We shall here only use the right-truncation delay adjusted procedure operating on the generalized Dirichlet distribution. Since the nowcasts for the time points very close to now are very volatile (i.e. have very large credibility regions), it&#39;s opportune to not display these casts as they can be very hard to communicate. Also note that the selected date for &lt;code&gt;now&lt;/code&gt; is selected such that enough cases are available to give a sufficiently reliable estimate for the delay distribution.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Nowcasts are displayed up to time (now - safePredictLag)
safePredictLag &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;
nowcastDates &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;seq&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;from =&lt;/span&gt; so_range[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;], &lt;span class=&quot;dt&quot;&gt;to =&lt;/span&gt; now -&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;safePredictLag, &lt;span class=&quot;dt&quot;&gt;by =&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We now perform right-truncation adjusted Bayesian nowcasting using the generalized Dirichlet distribution. An important choice is here the prior for the expected number of cases per day, i.e. &lt;span class=&quot;math inline&quot;&gt;\(\lambda_t\)&lt;/span&gt; in the notation of &lt;span class=&quot;citation&quot; data-cites=&quot;hoehle_anderheiden2014&quot;&gt;Höhle and an der Heiden (2014)&lt;/span&gt;. In the conjugate case this is specified by assuming an iid. Gamma-distribution for &lt;span class=&quot;math inline&quot;&gt;\(\lambda_t\)&lt;/span&gt;, which is specified through prior mean and prior variance of the Gamma distribution. We here select here an empirical Bayes inspired approach and estimate these parameters from the currently available data. However, note: These data are by definition of the problem incomplete. As a dirty fix we therefore just inflate the prior variance by a factor - as future work this needs to be improved upon by following a proper marginal likelihood approach.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;nc.control &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(
  &lt;span class=&quot;dt&quot;&gt;N.tInf.prior =&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;structure&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;poisgamma&amp;quot;&lt;/span&gt;,
                           &lt;span class=&quot;dt&quot;&gt;mean.lambda =&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;mean&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;observed&lt;/span&gt;(sts)),
                           &lt;span class=&quot;dt&quot;&gt;var.lambda =&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;5&lt;/span&gt;*&lt;span class=&quot;kw&quot;&gt;var&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;observed&lt;/span&gt;(sts))
                           ),
  ##compute predictive distribution as wel, which is needed for some of the
  ##animations.
  &lt;span class=&quot;dt&quot;&gt;predPMF =&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;,
  &lt;span class=&quot;dt&quot;&gt;dRange =&lt;/span&gt; so_range)

## Now run the nowcast (NA dates are removed from the dataset).
nc &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;nowcast&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;now =&lt;/span&gt; now, &lt;span class=&quot;dt&quot;&gt;when =&lt;/span&gt; nowcastDates, &lt;span class=&quot;dt&quot;&gt;data =&lt;/span&gt; linelist,
              &lt;span class=&quot;dt&quot;&gt;dEventCol =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;Date.of.symptoms.onset&amp;quot;&lt;/span&gt;,
              &lt;span class=&quot;dt&quot;&gt;dReportCol =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;Date.of.notification.to.WHO&amp;quot;&lt;/span&gt;,
              &lt;span class=&quot;dt&quot;&gt;method =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;bayes.trunc&amp;quot;&lt;/span&gt;, &lt;span class=&quot;co&quot;&gt;#use the conjugate generalized dirichlet&lt;/span&gt;
              &lt;span class=&quot;dt&quot;&gt;aggregate.by =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;1 day&amp;quot;&lt;/span&gt;,
              &lt;span class=&quot;dt&quot;&gt;D =&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;14&lt;/span&gt;, &lt;span class=&quot;co&quot;&gt;#adjust cases up to 2 weeks back.&lt;/span&gt;
              &lt;span class=&quot;dt&quot;&gt;control =&lt;/span&gt; nc.control)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## Removed 13 records due to NA dates.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The resulting object is of class &lt;code&gt;stsNC&lt;/code&gt;, which is just a class inheriting from the &lt;code&gt;sts&lt;/code&gt; class. Hence, all the usual plotting functions apply to it. In addition, a plot of an &lt;code&gt;stsNC&lt;/code&gt; object as shown below, contains the median of the pointwise predictive distribution (thick blue line) as well as equi-tailed 95% credibility regions (dashed orange lines).&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;plot&lt;/span&gt;(nc, &lt;span class=&quot;dt&quot;&gt;legend.opts=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;NULL&lt;/span&gt;,
     &lt;span class=&quot;dt&quot;&gt;xaxis.tickFreq=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;%d&amp;quot;&lt;/span&gt;=atChange,&lt;span class=&quot;st&quot;&gt;&amp;quot;%m&amp;quot;&lt;/span&gt;=atChange),
     &lt;span class=&quot;dt&quot;&gt;xaxis.labelFreq=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;%d&amp;quot;&lt;/span&gt;=at2ndChange),&lt;span class=&quot;dt&quot;&gt;xaxis.labelFormat=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;%d-%b&amp;quot;&lt;/span&gt;,
     &lt;span class=&quot;dt&quot;&gt;xlab=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;Time (days)&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;lty=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;),&lt;span class=&quot;dt&quot;&gt;lwd=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;),
     &lt;span class=&quot;dt&quot;&gt;ylab=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;No. symptom onsets&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;ylim=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;kw&quot;&gt;max&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;observed&lt;/span&gt;(nc),&lt;span class=&quot;kw&quot;&gt;upperbound&lt;/span&gt;(nc),&lt;span class=&quot;kw&quot;&gt;predint&lt;/span&gt;(nc),&lt;span class=&quot;dt&quot;&gt;na.rm=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;)))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-07-19-nowCast/NOWCASTPLOT-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;Finally, we can for &lt;code&gt;stsNC&lt;/code&gt; objects show a simple non-parametric estimate of the delay distribution as a function of time using a window-smoothed approach with window width &lt;span class=&quot;math inline&quot;&gt;\(2w+1\)&lt;/span&gt;, see &lt;span class=&quot;citation&quot; data-cites=&quot;hoehle_anderheiden2014&quot;&gt;Höhle and an der Heiden (2014)&lt;/span&gt; for details.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;plot&lt;/span&gt;(nc, &lt;span class=&quot;dt&quot;&gt;type=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;delay&amp;quot;&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;dates=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;seq&lt;/span&gt;(so_range[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;],now,&lt;span class=&quot;dt&quot;&gt;by=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;1 day&amp;quot;&lt;/span&gt;),&lt;span class=&quot;dt&quot;&gt;w=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-07-19-nowCast/NOWCASTDELAY-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;The figure shows for each time point &lt;span class=&quot;math inline&quot;&gt;\(t\)&lt;/span&gt; the median as well as the 10% and 90% quantile of the empirical distribution of delays within the window of &lt;span class=&quot;math inline&quot;&gt;\(t-w,\ldots,t+w\)&lt;/span&gt;. Note: This simple estimate ignores the right- truncation, hence, within the period of &lt;code&gt;(now-D):now&lt;/code&gt; there will be a bias of these estimates towards shorter delays. This biased period is illustrated in the figure by the light-gray shaded area. Furthermore, the median of the model based estimate for the delay distribution is shown for the period of &lt;code&gt;(now-m:now)&lt;/code&gt;. From the figure one has the suspicion that the delay decreased a bit over time, but the decrease totally at the end could also be due to right-truncation. However, assuming a &lt;strong&gt;time-invariant delay distribution&lt;/strong&gt; for the entire outbreak would probably give unsatisfactory results. Hence, we shall for each time point use only a moving window consisting of all observations occuring within the period &lt;code&gt;(now-m):now&lt;/code&gt;. We select &lt;span class=&quot;math inline&quot;&gt;\(m=14\)&lt;/span&gt; for estimating the delay distribution.&lt;/p&gt;
&lt;h2 id=&quot;showing-a-sequence-of-nowcasts&quot;&gt;Showing a sequence of nowcasts&lt;/h2&gt;
&lt;p&gt;Once a couple of nowcasts have been performed it can also be helpful to visualize the sequence of nowcasts using an animation. This is easily done by first generating a list of nowcast results followed by a call to &lt;code&gt;surveillance::animate_nowcasts&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Nowcast all time points (except for the first three weeks). This might take a while.
nowcasts &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;()
animRange &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;seq&lt;/span&gt;(so_range[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;]+&lt;span class=&quot;dv&quot;&gt;21&lt;/span&gt;,so_range[&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;],&lt;span class=&quot;dt&quot;&gt;by=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;1 day&amp;quot;&lt;/span&gt;)

##Do nowcasts for the rage of dates
for (i in &lt;span class=&quot;kw&quot;&gt;seq_len&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;length&lt;/span&gt;(animRange))) {
  today &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;animRange[i]
  &lt;span class=&quot;kw&quot;&gt;print&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;as.character&lt;/span&gt;(today))

  nowcastDates &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;seq&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;from =&lt;/span&gt; so_range[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;], &lt;span class=&quot;dt&quot;&gt;to =&lt;/span&gt; today -&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;safePredictLag, &lt;span class=&quot;dt&quot;&gt;by =&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)

  nowcasts[[&lt;span class=&quot;kw&quot;&gt;as.character&lt;/span&gt;(today)]] &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;nowcast&lt;/span&gt;(
    &lt;span class=&quot;dt&quot;&gt;now =&lt;/span&gt; today, &lt;span class=&quot;dt&quot;&gt;when =&lt;/span&gt; nowcastDates, &lt;span class=&quot;dt&quot;&gt;data =&lt;/span&gt; linelist,
    &lt;span class=&quot;dt&quot;&gt;dEventCol =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;Date.of.symptoms.onset&amp;quot;&lt;/span&gt;,
    &lt;span class=&quot;dt&quot;&gt;dReportCol =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;Date.of.notification.to.WHO&amp;quot;&lt;/span&gt;,
    &lt;span class=&quot;dt&quot;&gt;method =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;bayes.trunc&amp;quot;&lt;/span&gt;,
    &lt;span class=&quot;dt&quot;&gt;aggregate.by =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;1 day&amp;quot;&lt;/span&gt;,
    &lt;span class=&quot;dt&quot;&gt;D =&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;14&lt;/span&gt;,
    &lt;span class=&quot;dt&quot;&gt;m =&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;14&lt;/span&gt;, ##moving window of 14+1 days for estimation
    &lt;span class=&quot;dt&quot;&gt;control =&lt;/span&gt; nc.control)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We will use the &lt;code&gt;animation&lt;/code&gt; package to wrap the call to &lt;code&gt;animate_nowcasts&lt;/code&gt; in order to generate an animated GIF. Better control over the obtained animation can be obtained using the &lt;code&gt;animation::saveHTML&lt;/code&gt; function. If one wants to include the animation into a Power-Point presentation, I recommend the use of Flash animations (&lt;code&gt;animation::saveSWF&lt;/code&gt;). Note that the animation package requires &lt;a href=&quot;http://www.imagemagick.org/script/index.php&quot;&gt;ImageMagick&lt;/a&gt; to be installed on your system.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;animation::&lt;span class=&quot;kw&quot;&gt;saveGIF&lt;/span&gt;( {
  &lt;span class=&quot;kw&quot;&gt;par&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;mar=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;fl&quot;&gt;5.5&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;4&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;) +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.1&lt;/span&gt;) ; ##add extra space at the bottom and remove at top
  &lt;span class=&quot;kw&quot;&gt;animate_nowcasts&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;nowcasts =&lt;/span&gt; nowcasts,
                   &lt;span class=&quot;dt&quot;&gt;linelist_truth =&lt;/span&gt; linelist,
                   &lt;span class=&quot;dt&quot;&gt;method =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;bayes.trunc&amp;quot;&lt;/span&gt;, &lt;span class=&quot;co&quot;&gt;#nowcast method to use (has to be in the casts)&lt;/span&gt;
                   &lt;span class=&quot;dt&quot;&gt;control =&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;sys.sleep=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;dRange=&lt;/span&gt;nc.control$dRange,&lt;span class=&quot;dt&quot;&gt;anim.dRange=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;range&lt;/span&gt;(animRange),&lt;span class=&quot;dt&quot;&gt;ylim=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;40&lt;/span&gt;))) },
  &lt;span class=&quot;dt&quot;&gt;movie.name=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;animate-nowcasts.gif&amp;quot;&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;ani.width=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;800&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;ani.height=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;500&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-07-19-nowCast/animate-nowcasts.gif&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;As a final comparison we can also obtain an animation of how the delay distribution changes with time. From the animation we notice that the delay appears to steadily decrease, which is a typical behavior for high-profiled outbreaks. However, this also seriously questions the assumption of a &lt;strong&gt;time-invariant delay distribution&lt;/strong&gt;. Instead, one could use a window-limited estimation approach or one could try to model the delay distribution using a discrete time survival model as done in &lt;span class=&quot;citation&quot; data-cites=&quot;hoehle_anderheiden2014&quot;&gt;Höhle and an der Heiden (2014)&lt;/span&gt;.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;animation::&lt;span class=&quot;kw&quot;&gt;saveGIF&lt;/span&gt;(
  for (i in &lt;span class=&quot;kw&quot;&gt;seq_len&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;length&lt;/span&gt;(nowcasts))) {
    &lt;span class=&quot;kw&quot;&gt;plot&lt;/span&gt;(nowcasts[[i]], &lt;span class=&quot;dt&quot;&gt;w=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;type=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;delay&amp;quot;&lt;/span&gt;)
  },
  &lt;span class=&quot;dt&quot;&gt;movie.name=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;animate-delays.gif&amp;quot;&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;ani.width=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;800&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;ani.height=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;500&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-07-19-nowCast/animate-delays.gif&quot; /&gt;
&lt;/figure&gt;
&lt;h1 id=&quot;discussion&quot;&gt;Discussion&lt;/h1&gt;
&lt;p&gt;The adjustment of occurred-but-not-yet-reported-events applies to many other application areas besides &lt;strong&gt;real-time public health monitoring&lt;/strong&gt;. For example, direct links to claims reserve modelling in actuarial sciences exist, but many other areas of application, where delays play a role, appear of interest. For the methodological details of the nowcasting procedures see &lt;span class=&quot;citation&quot; data-cites=&quot;hoehle_anderheiden2014&quot;&gt;Höhle and an der Heiden (2014)&lt;/span&gt;, which is available as open access document. The present blog entry focused on getting methods operational using R.&lt;/p&gt;
&lt;h1 id=&quot;references&quot; class=&quot;unnumbered&quot;&gt;References&lt;/h1&gt;
&lt;div id=&quot;refs&quot; class=&quot;references&quot;&gt;
&lt;div id=&quot;ref-hoehle_anderheiden2014&quot;&gt;
&lt;p&gt;Höhle, M., and M. an der Heiden. 2014. “Bayesian Nowcasting During the STEC O104:H4 Outbreak in Germany, 2011.” &lt;em&gt;Biometrics&lt;/em&gt; 70 (4): 993–1002. doi:&lt;a href=&quot;https://doi.org/10.1111/biom.12194&quot;&gt;10.1111/biom.12194&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-salmon_etal2016a&quot;&gt;
&lt;p&gt;Salmon, M., D. Schumacher, and M. Höhle. 2016. “Monitoring Count Time Series in R: Aberration Detection in Public Health Surveillance.” &lt;em&gt;Journal of Statistical Software&lt;/em&gt; 70 (10). doi:&lt;a href=&quot;https://doi.org/10.18637/jss.v070.i10&quot;&gt;10.18637/jss.v070.i10&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
        <pubDate>Tue, 19 Jul 2016 00:00:00 +0200</pubDate>
        <link>http://staff.math.su.se/hoehle/blog/2016/07/19/nowCast.html</link>
        <guid isPermaLink="true">http://staff.math.su.se/hoehle/blog/2016/07/19/nowCast.html</guid>
        
        <category>math</category>
        
        <category>rstats</category>
        
        <category>surveillance</category>
        
        <category>open data</category>
        
        <category>MERS</category>
        
        
      </item>
    
  </channel>
</rss>
