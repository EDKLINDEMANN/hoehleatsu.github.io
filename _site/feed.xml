<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Theory meets practice...</title>
    <description>A blog about statistics in theory and practice. Not always serious, not always flawless, but definitely a statistically flavoured bean.
</description>
    <link>http://staff.math.su.se/hoehle/blog/</link>
    <atom:link href="http://staff.math.su.se/hoehle/blog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Tue, 19 Jul 2016 00:59:48 +0200</pubDate>
    <lastBuildDate>Tue, 19 Jul 2016 00:59:48 +0200</lastBuildDate>
    <generator>Jekyll v3.1.6</generator>
    
      <item>
        <title>Casting Call for MERS-CoV in Korea, 2015</title>
        <description>&lt;p&gt;&lt;br&gt; &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width:0&quot; src=&quot;https://i.creativecommons.org/l/by-sa/4.0/88x31.png&quot;/&gt;&lt;/a&gt; This work is licensed under a &lt;a rel=&quot;license&quot;
href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt;. The markdown+Rknitr source code of this blog is available under a &lt;a href=&quot;https://www.gnu.org/licenses/gpl-3.0.html&quot;&gt;GNU General Public License (GPL v3)&lt;/a&gt; license from &lt;a href=&quot;https://github.com/hoehleatsu/hoehleatsu.github.io&quot;&gt;&lt;img src=&quot;/hoehle/blog/images/GitHub-Mark-32px.png&quot; alt=&quot;github&quot; /&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;We perform an adjustment for observed-but-not-yet-reported cases (aka. nowcasting) for the epidemic curve of the Middle East respiratory syndrome coronavirus (MERS-CoV) outbreak in Korea, 2015. The analysis is based on the publically available WHO data and aims at illustrating how one could do real-time public health surveillance during critical outbreaks.&lt;/p&gt;
&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Short-range (0-6h) forecasts in the world of meteorology are also called &lt;strong&gt;nowcasts&lt;/strong&gt;. The term has also found its way into real-time infectious disease monitoring where one of its uses has been to adjust the currently available epidemic curve during an outbreak for structural and reporting delays.&lt;/p&gt;
&lt;p&gt;Whereas the original work in &lt;span class=&quot;citation&quot; data-cites=&quot;hoehle_anderheiden2014&quot;&gt;HÃ¶hle and an der Heiden (2014)&lt;/span&gt; was motivated by the large STEC O104:H4 outbreak in Germany 2011, one of our secondary motivations was to develop a tool the quantitative epidemiologist could use during similar high-profiled outbreaks (instead of having to re-invent the wheel during times of maximal stress). After my talk at the &lt;a href=&quot;https://biometricconference.org/showcases/biometrics-showcase/&quot;&gt;IBC2016 conference&lt;/a&gt; (&lt;a href=&quot;http://staff.math.su.se/hoehle/talks/IBC2016-Hoehle.pdf&quot;&gt;slides of the talk&lt;/a&gt;) one of the questions from the audience was how much impact the work had in terms of being useful for other outbreaks. Besides an analysis of an Adenovirus outbreak and a recent analysis of an O157 outbreak, I was a little short on a convincing answer. In addition, when trying to make a quick analysis for the O157 outbreak with the currently available code in the &lt;code&gt;surveillance&lt;/code&gt; package it became obvious that the nowcasting functionality in the package currently is a little rough and certainly in need of a user-friendliness polishing.&lt;/p&gt;
&lt;p&gt;So this little blog-note serves three purposes:&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;Illustrate how you can nowcasts with R, if you ever have to.&lt;/li&gt;
&lt;li&gt;Act as literate programming document for facilitating some code improvements of the &lt;code&gt;nowcast&lt;/code&gt; function while providing a vignette supported story.&lt;/li&gt;
&lt;li&gt;Perform an analysis of the WHO open-data on the MERS-CoV outbreak in Korea in 2015.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The structure of this blog entry is as follows. We first discuss and visualize the WHO data on the MERS-CoV outbreak. The findings from the descriptive data analysis are then used to set up nowcasts adjusting the observed epidemic curve during the outbreak for reporting delays between onset of symptoms in cases and the date the case report arrived at the WHO. Finally, we illustrate how to visualize a sequence of nowcasts during an outbreak using an animation.&lt;/p&gt;
&lt;h1 id=&quot;data&quot;&gt;Data&lt;/h1&gt;
&lt;p&gt;The data basis for our analysis is the WHO data on the &lt;a href=&quot;http://www.who.int/csr/don/21-july-2015-mers-korea/en/&quot;&gt;MERS-Cov outbreak in Korea&lt;/a&gt;, which occured during May-July 2015. Of interest will be the delay between the time point (here measured in days) on which a case has the onset of its MERS symptoms and the day the WHO learns about this case. In other words we put ourself in the role of an epidemiologist working at the WHO and who during the outbreak has to report on how the outbreak is evolving in Korea.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Library to read excel files
&lt;span class=&quot;kw&quot;&gt;library&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;openxlsx&amp;quot;&lt;/span&gt;)

##Obtain file from link found at (if it doesn&amp;#39;t already exist)
##http://www.who.int/csr/don/21-july-2015-mers-korea/en/
if (!&lt;span class=&quot;kw&quot;&gt;file.exists&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;../downloads/MERS-CoV-cases-rok-21Jul15.xlsx&amp;quot;&lt;/span&gt;)) {
  &lt;span class=&quot;kw&quot;&gt;download.file&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;url=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;http://www.who.int/entity/csr/disease/coronavirus_infections/MERS-CoV-cases-rok-21Jul15.xlsx?ua=1&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;destfile=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;../downloads/MERS-CoV-cases-rok-21Jul15.xlsx&amp;quot;&lt;/span&gt;)
}

##Read data
linelist &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;read.xlsx&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;../downloads/MERS-CoV-cases-rok-21Jul15.xlsx&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;startRow=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;4&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;detectDates=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;)

##Base R style - IMHO easier to understand
for (dateCol in &lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;Date.of.notification.to.WHO&amp;quot;&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;Date.of.symptoms.onset&amp;quot;&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;Date.of.first.hospitalization&amp;quot;&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;Date.of.laboratory.confirmation&amp;quot;&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;Date.of.outcome&amp;quot;&lt;/span&gt;)) {
  linelist[,dateCol] &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;as.Date&lt;/span&gt;(linelist[,dateCol],&lt;span class=&quot;dt&quot;&gt;format=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;%d/%m/%Y&amp;quot;&lt;/span&gt;)
}

##Make a delay column
linelist$delay &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;with&lt;/span&gt;(linelist,Date.of.notification.to.WHO -&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;Date.of.symptoms.onset)

&lt;span class=&quot;kw&quot;&gt;head&lt;/span&gt;(linelist,&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##   Case.no. Date.of.notification.to.WHO Age Sex Health.care.worker Comorbidities
## 1        1                  2015-05-20  68   M                 No          &amp;lt;NA&amp;gt;
## 2        2                  2015-05-22  63   F                 No          &amp;lt;NA&amp;gt;
## 3        3                  2015-05-22  76   M                 No          &amp;lt;NA&amp;gt;
##   Date.of.symptoms.onset Date.of.first.hospitalization Date.of.laboratory.confirmation
## 1             2015-05-11                    2015-05-15                      2015-05-20
## 2             2015-05-19                          &amp;lt;NA&amp;gt;                      2015-05-20
## 3             2015-05-20                          &amp;lt;NA&amp;gt;                      2015-05-20
##     Status Date.of.outcome  delay
## 1    Alive            &amp;lt;NA&amp;gt; 9 days
## 2    Alive            &amp;lt;NA&amp;gt; 3 days
## 3 Deceased      2015-06-04 2 days&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As the outbreak is already over, it is easy to visualize the epidemic curve in retrospect. We do so for the date of symptom onset.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Show the epidemic curve as it occurs at the end of the outbreak
##using simple call to ggplot
ggplot2::&lt;span class=&quot;kw&quot;&gt;ggplot&lt;/span&gt;( linelist, &lt;span class=&quot;kw&quot;&gt;aes&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;x=&lt;/span&gt;Date.of.symptoms.onset)) +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;geom_histogram&lt;/span&gt;() +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;xlab&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;Date of onset of symptoms&amp;quot;&lt;/span&gt;) +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;ylab&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;Number of cases&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-07-19-nowCast/EPICURVE-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;Furthermore, we can look at the delay distribution as it looks at the end of the outbreak. We shall later look in more detail at this distribution, but for now the plot gives an idea about the range of the delay: in most cases the delay is between 1-14 days, actually 97.1% of the observations have a lag smaller or equal to &lt;span class=&quot;math inline&quot;&gt;\(D=14\)&lt;/span&gt;. As a consequence, we shall use &lt;span class=&quot;math inline&quot;&gt;\(D=14\)&lt;/span&gt; as the maximum relevant lag to adjust for.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;ggplot&lt;/span&gt;( linelist, &lt;span class=&quot;kw&quot;&gt;aes&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;x=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;as.integer&lt;/span&gt;(delay),&lt;span class=&quot;dt&quot;&gt;y=&lt;/span&gt;..prop..)) +
&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;stat_count&lt;/span&gt;() +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;scale_y_continuous&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;labels =&lt;/span&gt; scales::percent) +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;xlab&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;Delay (days)&amp;quot;&lt;/span&gt;) +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;ylab&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-07-19-nowCast/unnamed-chunk-3-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;Instead of using &lt;code&gt;ggplot&lt;/code&gt; to show the epidemic curve, this can also be done directly from the surveillance package using the function &lt;code&gt;linelist2sts&lt;/code&gt;. This function takes a &lt;code&gt;data.frame&lt;/code&gt; representing a linelist and converts this into an object of class &lt;code&gt;sts&lt;/code&gt; (surveillance time series) used by the package. This then allows the use of all the plotting functionality of such objects as described in &lt;span class=&quot;citation&quot; data-cites=&quot;salmon_etal2016a&quot;&gt;Salmon, Schumacher, and HÃ¶hle (2016)&lt;/span&gt;. Note: For the nowcasting code of this blog entry to work, the newest development version of the package, i.e. version 1.12.2 available from Rforge using&lt;/p&gt;
&lt;p&gt;
&lt;center&gt;
&lt;code&gt;install.packages(&amp;quot;surveillance&amp;quot;,repos=&amp;quot;http://r-forge.r-project.org&amp;quot;)&lt;/code&gt;
&lt;/center&gt;
&lt;p&gt;
&lt;p&gt;is needed. The code then looks as follows:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Load surveillance pkg. 
&lt;span class=&quot;kw&quot;&gt;library&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;surveillance&amp;quot;&lt;/span&gt;)

##Range of the symptom onset date variable
so_range &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;range&lt;/span&gt;(linelist$Date.of.symptoms.onset,&lt;span class=&quot;dt&quot;&gt;na.rm=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;)

##Create an sts time series from the linelist, which contains daily counts.
sts &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;linelist2sts&lt;/span&gt;(linelist, &lt;span class=&quot;dt&quot;&gt;dateCol=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;Date.of.symptoms.onset&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;aggregate.by=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;1 day&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;dRange=&lt;/span&gt;so_range)

##Show the resulting time series using the plot functionality for sts objects.
&lt;span class=&quot;kw&quot;&gt;plot&lt;/span&gt;(sts,&lt;span class=&quot;dt&quot;&gt;legend.opts=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;NULL&lt;/span&gt;,
     &lt;span class=&quot;dt&quot;&gt;xaxis.tickFreq=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;%d&amp;quot;&lt;/span&gt;=atChange,&lt;span class=&quot;st&quot;&gt;&amp;quot;%m&amp;quot;&lt;/span&gt;=atChange),
     &lt;span class=&quot;dt&quot;&gt;xaxis.labelFreq=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;%d&amp;quot;&lt;/span&gt;=at2ndChange),&lt;span class=&quot;dt&quot;&gt;xaxis.labelFormat=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;%d-%b&amp;quot;&lt;/span&gt;,
     &lt;span class=&quot;dt&quot;&gt;xlab=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;Time (days)&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;lty=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;),&lt;span class=&quot;dt&quot;&gt;lwd=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;),
     &lt;span class=&quot;dt&quot;&gt;ylab=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;No. symptom onsets&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-07-19-nowCast/EPICURVE-SURVEILLANCE-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;h2 id=&quot;nowcasting&quot;&gt;Nowcasting&lt;/h2&gt;
&lt;p&gt;We now move on to the nowcasts.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##State which date to nowcast
now &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;as.Date&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;2015-06-12&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Say (in a mathematical sense) we move back time to 2015-06-12. In the notation of &lt;span class=&quot;citation&quot; data-cites=&quot;hoehle_anderheiden2014&quot;&gt;HÃ¶hle and an der Heiden (2014)&lt;/span&gt; this means &lt;span class=&quot;math inline&quot;&gt;\(T=2015-06-12\)&lt;/span&gt;. We want to illustrate what the WHO could see at this point and, on the basis on how the available reports, estimate the delay distribution and adjust the observed cases accordingly. We shall here only use the right-truncation delay adjusted procedure operating on the generalized Dirichlet distribution. Since the nowcasts for the time points very close to now are very volatile (i.e. have very large credibility regions), it&#39;s opportune to not display these casts as they can be very hard to communicate. Also note that the selected date for &lt;code&gt;now&lt;/code&gt; is selected such that enough cases are available to give a sufficiently reliable estimate for the delay distribution.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Nowcasts are displayed up to time (now - safePredictLag)
safePredictLag &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;
nowcastDates &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;seq&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;from =&lt;/span&gt; so_range[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;], &lt;span class=&quot;dt&quot;&gt;to =&lt;/span&gt; now -&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;safePredictLag, &lt;span class=&quot;dt&quot;&gt;by =&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We now perform right-truncation adjusted Bayesian nowcasting using the generalized Dirichlet distribution. An important choice is here the prior for the expected number of cases per day, i.e. &lt;span class=&quot;math inline&quot;&gt;\(\lambda_t\)&lt;/span&gt; in the notation of &lt;span class=&quot;citation&quot; data-cites=&quot;hoehle_anderheiden2014&quot;&gt;HÃ¶hle and an der Heiden (2014)&lt;/span&gt;. In the conjugate case this is specified by assuming an iid. Gamma-distribution for &lt;span class=&quot;math inline&quot;&gt;\(\lambda_t\)&lt;/span&gt;, which is specified through prior mean and prior variance of the Gamma distribution. We here select here an empirical Bayes inspired approach and estimate these parameters from the currently available data. However, note: These data are by definition of the problem incomplete. As a dirty fix we therefore just inflate the prior variance by a factor - as future work this needs to be improved upon by following a proper marginal likelihood approach.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;nc.control &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(
  &lt;span class=&quot;dt&quot;&gt;N.tInf.prior =&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;structure&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;poisgamma&amp;quot;&lt;/span&gt;,
                           &lt;span class=&quot;dt&quot;&gt;mean.lambda =&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;mean&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;observed&lt;/span&gt;(sts)),
                           &lt;span class=&quot;dt&quot;&gt;var.lambda =&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;5&lt;/span&gt;*&lt;span class=&quot;kw&quot;&gt;var&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;observed&lt;/span&gt;(sts))
                           ),
  ##compute predictive distribution as wel, which is needed for some of the
  ##animations.
  &lt;span class=&quot;dt&quot;&gt;predPMF =&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;,
  &lt;span class=&quot;dt&quot;&gt;dRange =&lt;/span&gt; so_range)

## Now run the nowcast (NA dates are removed from the dataset).
nc &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;nowcast&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;now =&lt;/span&gt; now, &lt;span class=&quot;dt&quot;&gt;when =&lt;/span&gt; nowcastDates, &lt;span class=&quot;dt&quot;&gt;data =&lt;/span&gt; linelist,
              &lt;span class=&quot;dt&quot;&gt;dEventCol =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;Date.of.symptoms.onset&amp;quot;&lt;/span&gt;,
              &lt;span class=&quot;dt&quot;&gt;dReportCol =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;Date.of.notification.to.WHO&amp;quot;&lt;/span&gt;,
              &lt;span class=&quot;dt&quot;&gt;method =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;bayes.trunc&amp;quot;&lt;/span&gt;, &lt;span class=&quot;co&quot;&gt;#use the conjugate generalized dirichlet&lt;/span&gt;
              &lt;span class=&quot;dt&quot;&gt;aggregate.by =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;1 day&amp;quot;&lt;/span&gt;,
              &lt;span class=&quot;dt&quot;&gt;D =&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;14&lt;/span&gt;, &lt;span class=&quot;co&quot;&gt;#adjust cases up to 2 weeks back.&lt;/span&gt;
              &lt;span class=&quot;dt&quot;&gt;control =&lt;/span&gt; nc.control)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## Removed 13 records due to NA dates.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The resulting object is of class &lt;code&gt;stsNC&lt;/code&gt;, which is just a class inheriting from the &lt;code&gt;sts&lt;/code&gt; class. Hence, all the usual plotting functions apply to it. In addition, a plot of an &lt;code&gt;stsNC&lt;/code&gt; object as shown below, contains the median of the pointwise predictive distribution (thick blue line) as well as equi-tailed 95% credibility regions (dashed orange lines).&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;plot&lt;/span&gt;(nc, &lt;span class=&quot;dt&quot;&gt;legend.opts=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;NULL&lt;/span&gt;,
     &lt;span class=&quot;dt&quot;&gt;xaxis.tickFreq=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;%d&amp;quot;&lt;/span&gt;=atChange,&lt;span class=&quot;st&quot;&gt;&amp;quot;%m&amp;quot;&lt;/span&gt;=atChange),
     &lt;span class=&quot;dt&quot;&gt;xaxis.labelFreq=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;%d&amp;quot;&lt;/span&gt;=at2ndChange),&lt;span class=&quot;dt&quot;&gt;xaxis.labelFormat=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;%d-%b&amp;quot;&lt;/span&gt;,
     &lt;span class=&quot;dt&quot;&gt;xlab=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;Time (days)&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;lty=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;),&lt;span class=&quot;dt&quot;&gt;lwd=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;),
     &lt;span class=&quot;dt&quot;&gt;ylab=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;No. symptom onsets&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;ylim=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;kw&quot;&gt;max&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;observed&lt;/span&gt;(nc),&lt;span class=&quot;kw&quot;&gt;upperbound&lt;/span&gt;(nc),&lt;span class=&quot;kw&quot;&gt;predint&lt;/span&gt;(nc),&lt;span class=&quot;dt&quot;&gt;na.rm=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;)))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-07-19-nowCast/NOWCASTPLOT-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;Finally, we can for &lt;code&gt;stsNC&lt;/code&gt; objects show a simple non-parametric estimate of the delay distribution as a function of time using a window-smoothed approach with window width &lt;span class=&quot;math inline&quot;&gt;\(2w+1\)&lt;/span&gt;, see &lt;span class=&quot;citation&quot; data-cites=&quot;hoehle_anderheiden2014&quot;&gt;HÃ¶hle and an der Heiden (2014)&lt;/span&gt; for details.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;plot&lt;/span&gt;(nc, &lt;span class=&quot;dt&quot;&gt;type=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;delay&amp;quot;&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;dates=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;seq&lt;/span&gt;(so_range[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;],now,&lt;span class=&quot;dt&quot;&gt;by=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;1 day&amp;quot;&lt;/span&gt;),&lt;span class=&quot;dt&quot;&gt;w=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-07-19-nowCast/NOWCASTDELAY-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;The figure shows for each time point &lt;span class=&quot;math inline&quot;&gt;\(t\)&lt;/span&gt; the median as well as the 10% and 90% quantile of the empirical distribution of delays within the window of &lt;span class=&quot;math inline&quot;&gt;\(t-w,\ldots,t+w\)&lt;/span&gt;. Note: This simple estimate ignores the right- truncation, hence, within the period of &lt;code&gt;(now-D):now&lt;/code&gt; there will be a bias of these estimates towards shorter delays. This biased period is illustrated in the figure by the light-gray shaded area. Furthermore, the median of the model based estimate for the delay distribution is shown for the period of &lt;code&gt;(now-m:now)&lt;/code&gt;. From the figure one has the suspicion that the delay decreased a bit over time, but the decrease totally at the end could also be due to right-truncation. However, assuming a &lt;strong&gt;time-invariant delay distribution&lt;/strong&gt; for the entire outbreak would probably give unsatisfactory results. Hence, we shall for each time point use only a moving window consisting of all observations occuring within the period &lt;code&gt;(now-m):now&lt;/code&gt;. We select &lt;span class=&quot;math inline&quot;&gt;\(m=14\)&lt;/span&gt; for estimating the delay distribution.&lt;/p&gt;
&lt;h2 id=&quot;showing-a-sequence-of-nowcasts&quot;&gt;Showing a sequence of nowcasts&lt;/h2&gt;
&lt;p&gt;Once a couple of nowcasts have been performed it can also be helpful to visualize the sequence of nowcasts using an animation. This is easily done by first generating a list of nowcast results followed by a call to &lt;code&gt;surveillance::animate_nowcasts&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Nowcast all time points (except for the first three weeks). This might take a while.
nowcasts &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;()
animRange &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;seq&lt;/span&gt;(so_range[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;]+&lt;span class=&quot;dv&quot;&gt;21&lt;/span&gt;,so_range[&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;],&lt;span class=&quot;dt&quot;&gt;by=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;1 day&amp;quot;&lt;/span&gt;)

##Do nowcasts for the rage of dates
for (i in &lt;span class=&quot;kw&quot;&gt;seq_len&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;length&lt;/span&gt;(animRange))) {
  today &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;animRange[i]
  &lt;span class=&quot;kw&quot;&gt;print&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;as.character&lt;/span&gt;(today))

  nowcastDates &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;seq&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;from =&lt;/span&gt; so_range[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;], &lt;span class=&quot;dt&quot;&gt;to =&lt;/span&gt; today -&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;safePredictLag, &lt;span class=&quot;dt&quot;&gt;by =&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)

  nowcasts[[&lt;span class=&quot;kw&quot;&gt;as.character&lt;/span&gt;(today)]] &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;nowcast&lt;/span&gt;(
    &lt;span class=&quot;dt&quot;&gt;now =&lt;/span&gt; today, &lt;span class=&quot;dt&quot;&gt;when =&lt;/span&gt; nowcastDates, &lt;span class=&quot;dt&quot;&gt;data =&lt;/span&gt; linelist,
    &lt;span class=&quot;dt&quot;&gt;dEventCol =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;Date.of.symptoms.onset&amp;quot;&lt;/span&gt;,
    &lt;span class=&quot;dt&quot;&gt;dReportCol =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;Date.of.notification.to.WHO&amp;quot;&lt;/span&gt;,
    &lt;span class=&quot;dt&quot;&gt;method =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;bayes.trunc&amp;quot;&lt;/span&gt;,
    &lt;span class=&quot;dt&quot;&gt;aggregate.by =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;1 day&amp;quot;&lt;/span&gt;,
    &lt;span class=&quot;dt&quot;&gt;D =&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;14&lt;/span&gt;,
    &lt;span class=&quot;dt&quot;&gt;m =&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;14&lt;/span&gt;, ##moving window of 14+1 days for estimation
    &lt;span class=&quot;dt&quot;&gt;control =&lt;/span&gt; nc.control)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We will use the &lt;code&gt;animation&lt;/code&gt; package to wrap the call to &lt;code&gt;animate_nowcasts&lt;/code&gt; in order to generate an animated GIF. Better control over the obtained animation can be obtained using the &lt;code&gt;animation::saveHTML&lt;/code&gt; function. If one wants to include the animation into a Power-Point presentation, I recommend the use of Flash animations (&lt;code&gt;animation::saveSWF&lt;/code&gt;). Note that the animation package requires &lt;a href=&quot;http://www.imagemagick.org/script/index.php&quot;&gt;ImageMagick&lt;/a&gt; to be installed on your system.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;animation::&lt;span class=&quot;kw&quot;&gt;saveGIF&lt;/span&gt;( {
  &lt;span class=&quot;kw&quot;&gt;par&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;mar=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;fl&quot;&gt;5.5&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;4&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;) +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.1&lt;/span&gt;) ; ##add extra space at the bottom and remove at top
  &lt;span class=&quot;kw&quot;&gt;animate_nowcasts&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;nowcasts =&lt;/span&gt; nowcasts,
                   &lt;span class=&quot;dt&quot;&gt;linelist_truth =&lt;/span&gt; linelist,
                   &lt;span class=&quot;dt&quot;&gt;method =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;bayes.trunc&amp;quot;&lt;/span&gt;, &lt;span class=&quot;co&quot;&gt;#nowcast method to use (has to be in the casts)&lt;/span&gt;
                   &lt;span class=&quot;dt&quot;&gt;control =&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;sys.sleep=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;dRange=&lt;/span&gt;nc.control$dRange,&lt;span class=&quot;dt&quot;&gt;anim.dRange=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;range&lt;/span&gt;(animRange),&lt;span class=&quot;dt&quot;&gt;ylim=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;40&lt;/span&gt;))) },
  &lt;span class=&quot;dt&quot;&gt;movie.name=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;animate-nowcasts.gif&amp;quot;&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;ani.width=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;800&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;ani.height=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;500&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-07-19-nowCast/animate-nowcasts.gif&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;As a final comparison we can also obtain an animation of how the delay distribution changes with time. From the animation we notice that the delay appears to steadily decrease, which is a typical behavior for high-profiled outbreaks. However, this also seriously questions the assumption of a &lt;strong&gt;time-invariant delay distribution&lt;/strong&gt;. Instead, one could use a window-limited estimation approach or one could try to model the delay distribution using a discrete time survival model as done in &lt;span class=&quot;citation&quot; data-cites=&quot;hoehle_anderheiden2014&quot;&gt;HÃ¶hle and an der Heiden (2014)&lt;/span&gt;.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;animation::&lt;span class=&quot;kw&quot;&gt;saveGIF&lt;/span&gt;(
  for (i in &lt;span class=&quot;kw&quot;&gt;seq_len&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;length&lt;/span&gt;(nowcasts))) {
    &lt;span class=&quot;kw&quot;&gt;plot&lt;/span&gt;(nowcasts[[i]], &lt;span class=&quot;dt&quot;&gt;w=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;type=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;delay&amp;quot;&lt;/span&gt;)
  },
  &lt;span class=&quot;dt&quot;&gt;movie.name=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;animate-delays.gif&amp;quot;&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;ani.width=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;800&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;ani.height=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;500&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-07-19-nowCast/animate-delays.gif&quot; /&gt;
&lt;/figure&gt;
&lt;h1 id=&quot;discussion&quot;&gt;Discussion&lt;/h1&gt;
&lt;p&gt;The adjustment of occurred-but-not-yet-reported-events applies to many other application areas besides &lt;strong&gt;real-time public health monitoring&lt;/strong&gt;. For example, direct links to claims reserve modelling in actuarial sciences exist, but many other areas of application, where delays play a role, appear of interest. For the methodological details of the nowcasting procedures see &lt;span class=&quot;citation&quot; data-cites=&quot;hoehle_anderheiden2014&quot;&gt;HÃ¶hle and an der Heiden (2014)&lt;/span&gt;, which is available as open access document. The present blog entry focused on getting methods operational using R.&lt;/p&gt;
&lt;h1 id=&quot;references&quot; class=&quot;unnumbered&quot;&gt;References&lt;/h1&gt;
&lt;div id=&quot;refs&quot; class=&quot;references&quot;&gt;
&lt;div id=&quot;ref-hoehle_anderheiden2014&quot;&gt;
&lt;p&gt;HÃ¶hle, M., and M. an der Heiden. 2014. âBayesian Nowcasting During the STEC O104:H4 Outbreak in Germany, 2011.â &lt;em&gt;Biometrics&lt;/em&gt; 70 (4): 993â1002. doi:&lt;a href=&quot;https://doi.org/10.1111/biom.12194&quot;&gt;10.1111/biom.12194&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-salmon_etal2016a&quot;&gt;
&lt;p&gt;Salmon, M., D. Schumacher, and M. HÃ¶hle. 2016. âMonitoring Count Time Series in R: Aberration Detection in Public Health Surveillance.â &lt;em&gt;Journal of Statistical Software&lt;/em&gt; 70 (10). doi:&lt;a href=&quot;https://doi.org/10.18637/jss.v070.i10&quot;&gt;10.18637/jss.v070.i10&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
        <pubDate>Tue, 19 Jul 2016 00:00:00 +0200</pubDate>
        <link>http://staff.math.su.se/hoehle/blog/2016/07/19/nowCast.html</link>
        <guid isPermaLink="true">http://staff.math.su.se/hoehle/blog/2016/07/19/nowCast.html</guid>
        
        <category>math</category>
        
        <category>rstats</category>
        
        <category>surveillance</category>
        
        <category>open data</category>
        
        <category>MERS</category>
        
        
      </item>
    
      <item>
        <title>Princes Disguised in Uniforms</title>
        <description>&lt;p&gt;&lt;br&gt; &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width:0&quot; src=&quot;https://i.creativecommons.org/l/by-sa/4.0/88x31.png&quot;/&gt;&lt;/a&gt; This work is licensed under a &lt;a rel=&quot;license&quot;
href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt;. The markdown+Rknitr source code of this blog is available under a &lt;a href=&quot;https://www.gnu.org/licenses/gpl-3.0.html&quot;&gt;GNU General Public License (GPL v3)&lt;/a&gt; license from &lt;a href=&quot;https://github.com/hoehleatsu/hoehleatsu.github.io&quot;&gt;&lt;img src=&quot;/hoehle/blog/images/GitHub-Mark-32px.png&quot; alt=&quot;github&quot; /&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;We revisit the &lt;strong&gt;secretary problem&lt;/strong&gt; as a mathematical fairy tale: Princes wooing a princess sequentially arrive each having a qualification score originating from a known parametric distribution with all parameters known, e.g., the standard uniform distribution or the normal distribution with known mean and variance. For this so called &lt;strong&gt;full information game&lt;/strong&gt; the question of interest is: How does the optimal strategy look, which maximizes the expected score of the selected candidate? As a further twist: How does the strategy change, if we sequentially have to estimate the parameters of the distribution alongside? The later variant is called the &lt;strong&gt;partial information game&lt;/strong&gt; and is nicely addressed using sequential Bayesian updating.&lt;/p&gt;
&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;In the last blog post &lt;a href=&quot;../12/%20optimalChoice.html&quot;&gt;&lt;em&gt;Optimal Choice - Mathematical Advice for Real Life&lt;/em&gt;&lt;/a&gt; our interest was in determining a strategy to select the overall best candidate from a sequence of &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; candidates (e.g. princes, job candidates, houses, bids or tinder profiles) arriving sequentially. It was shown that the optimal strategy is to screen a number of candidates &lt;span class=&quot;math inline&quot;&gt;\(r-1\)&lt;/span&gt; in order to form a baseline and then, starting from the &lt;span class=&quot;math inline&quot;&gt;\(r\)&lt;/span&gt;&#39;th candidate, select the first candidate better than the baseline. If no candidate was chosen before the &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt;&#39;th candidate this last candidate has to be selected no matter what. The natural phenomena of getting &lt;em&gt;desperate towards the end&lt;/em&gt; was observed, if the objective of finding &lt;em&gt;the&lt;/em&gt; best is changed to maximizing the expected rank of the selected candidate.&lt;/p&gt;
&lt;p&gt;In this blog post we study the situation, where additional information about the absolute score of the candidates (instead of just their relative ranks) is available. In particular we assume that the candidate scores are known to originate from a known &lt;strong&gt;underlying distribution&lt;/strong&gt;, e.g. the uniform or the standard normal. This means that not only the underlying parametric family of the scores are known, but also the parameters of the distribution. In what follows we use the work of &lt;span class=&quot;citation&quot; data-cites=&quot;guttman1960&quot;&gt;Guttman (1960)&lt;/span&gt; to describe the problem in mathematical notation and discuss solution strategies. Then we move on to the work of &lt;span class=&quot;citation&quot; data-cites=&quot;stewart1978&quot;&gt;Stewart (1978)&lt;/span&gt; in order to investigate how the strategy changes, if we also have to simultaneously estimate the parameters of the distribution alongside. &lt;a href=&quot;https://www.r-project.org/&quot;&gt;&lt;strong&gt;R code&lt;/strong&gt;&lt;/a&gt; implementing the optimal strategies is provided for both situations in order to enable prudent decision support for real-life problems.&lt;/p&gt;
&lt;h1 id=&quot;methods&quot;&gt;Methods&lt;/h1&gt;
&lt;p&gt;Let the &lt;strong&gt;score&lt;/strong&gt; of a candidate be represented by a random variable &lt;span class=&quot;math inline&quot;&gt;\(X\)&lt;/span&gt; with continuous probability density function &lt;span class=&quot;math inline&quot;&gt;\(f\)&lt;/span&gt; having support on &lt;span class=&quot;math inline&quot;&gt;\((a,b)\)&lt;/span&gt;, where &lt;span class=&quot;math inline&quot;&gt;\(a&amp;lt;b\)&lt;/span&gt;. Note that &lt;span class=&quot;math inline&quot;&gt;\(a\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(b\)&lt;/span&gt; are allowed to be &lt;span class=&quot;math inline&quot;&gt;\(\pm \infty\)&lt;/span&gt;, respectively. Let &lt;span class=&quot;math inline&quot;&gt;\(F\)&lt;/span&gt; be the corresponding cumulative distribution of the score. Furthermore, let &lt;span class=&quot;math inline&quot;&gt;\(\mu=E(X)=\int_{a}^b x \cdot f(x) dx\)&lt;/span&gt; be the expectation of &lt;span class=&quot;math inline&quot;&gt;\(X\)&lt;/span&gt;. In what follows we will assume that the distribution is such that the expectation exists. Assuming a total of &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; candidates, we ascertain that their abilities/scores are independently and identically sampled from this distribution, i.e.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
X_1,\ldots,X_n \stackrel{\text{iid}}{\sim} F.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; candidates arrive sequentially and for each candidate one has to decide whether to select this candidate or to keep looking at further candidates. Once a candidate is rejected there is no opportunity to regret this choice later.&lt;/p&gt;
&lt;p&gt;Now we denote by &lt;span class=&quot;math inline&quot;&gt;\(E_{n}\)&lt;/span&gt; the expected score of the chosen candidate when one has to choose among &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; candidates according to some pre-described strategy. It is immediately obvious that &lt;span class=&quot;math inline&quot;&gt;\(E_1=\mu\)&lt;/span&gt;. If there are &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; candidates we would like to find the optimal stopping rule maximizing &lt;span class=&quot;math inline&quot;&gt;\(E_n\)&lt;/span&gt;. The standard stopping rule based on the expectation implies that we would already stop at the first candidate, if the observed value &lt;span class=&quot;math inline&quot;&gt;\(x\)&lt;/span&gt; is such that &lt;span class=&quot;math inline&quot;&gt;\(x &amp;gt; E_{n-1}\)&lt;/span&gt;. As a consequence,&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
\begin{align*}
E_{n+1} &amp;amp;= P(X &amp;gt; E_n) \cdot E(X\&amp;gt;|\&amp;gt;X \geq E_n)  +
P(X \leq E_n) \cdot E_n \\
%&amp;amp;= \int_{E_n}^b x \cdot f(x) dx + E_n \int_{a}^{E_n} f(x) dx \\
&amp;amp;= \int_{E_n}^b x \cdot f(x) dx + E_n \cdot (1-F(E_n)).
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;A function to perform these computations in R handling either general densities using numeric integration or analytic derivations would be:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;######################################################################
##Compute E vector using either numerical integration, a function for
##the computation of E[n+1] or using the analytic solution of
##\int_{E_n}^b x df(x) dx.
##
## Parameters:
##  n - number of candidates
##  df - density function of the score distribution (i.e. f)
##  pf - cumulative density function of the score distribution (i.e. F)
##  intE_fun - function g(E_n) = \int_{E_n}^b x*f(x)dx (if available)
##  Enp1_fun - function h(n,E_n) directly computing E_{n+1} from E_{n}
##
## Returns a vector of length (n+1) containing (E_0,...,E_n)&amp;#39;.
######################################################################
compute_E &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(n,df,pf,&lt;span class=&quot;dt&quot;&gt;intE_fun=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;NULL&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;Enp1_fun=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;NULL&lt;/span&gt;,...) {
  E &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;rep&lt;/span&gt;(&lt;span class=&quot;ot&quot;&gt;NA&lt;/span&gt;,n&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;)
  E[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;] &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;
  target &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(x) x*&lt;span class=&quot;kw&quot;&gt;df&lt;/span&gt;(x,...)

  for (n in &lt;span class=&quot;kw&quot;&gt;seq_len&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;length&lt;/span&gt;(E)-&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)) {
    if (&lt;span class=&quot;kw&quot;&gt;is.null&lt;/span&gt;(Enp1_fun)) {
      if (&lt;span class=&quot;kw&quot;&gt;is.null&lt;/span&gt;(intE_fun)) {
        E[n&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;] &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;integrate&lt;/span&gt;(target,E[n],&lt;span class=&quot;ot&quot;&gt;Inf&lt;/span&gt;)$value +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;E[n] *&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;pf&lt;/span&gt;(E[n],...)
      } else {
        E[n&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;] &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;intE_fun&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;En=&lt;/span&gt;E[n]) +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;E[n] *&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;pf&lt;/span&gt;(E[n],...)
      }
    } else {
      E[n&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;] &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;Enp1_fun&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;n,&lt;span class=&quot;dt&quot;&gt;En=&lt;/span&gt;E[n],...)
    }
  }
  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt;(E)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Altogether, the optimal stopping time is thus&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
T_{\text{stop}} = \min_{1\leq i \leq n} \left\{x_i &amp;gt; E_{n-i}\right\}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The sequential comparisons can be given in the same strategy vector format as for the &lt;a href=&quot;../12/optimalChoice.html&quot;&gt;secretary problem post&lt;/a&gt;, i.e. one selects the candidate &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt; if &lt;span class=&quot;math inline&quot;&gt;\(x_i&amp;gt;s_i\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;######################################################################
## Strategy of full information variant of the secretary problem
##
## Parameters:
##  n - number of candidates
######################################################################

strategy_fip &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(n,df,pf,&lt;span class=&quot;dt&quot;&gt;intE_fun=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;NULL&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;Enp1_fun=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;NULL&lt;/span&gt;,...) {
  E &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;compute_E&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;n,&lt;span class=&quot;dt&quot;&gt;df=&lt;/span&gt;df,&lt;span class=&quot;dt&quot;&gt;pf=&lt;/span&gt;pf,&lt;span class=&quot;dt&quot;&gt;intE_fun=&lt;/span&gt;intE_fun,&lt;span class=&quot;dt&quot;&gt;Enp1_fun=&lt;/span&gt;Enp1_fun,...)
  s &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;E[(n&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;:n)+&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;]
  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt;(s)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id=&quot;example-u01&quot;&gt;Example: U(0,1)&lt;/h4&gt;
&lt;p&gt;Example: In the case of &lt;span class=&quot;math inline&quot;&gt;\(X\sim U(0,1)\)&lt;/span&gt; we can analytically compute &lt;span class=&quot;math display&quot;&gt;\[
E_{n+1}=\frac{1}{2}(1-E_n^2) + E_n^2 =\frac{1}{2}(1+E_n^2).
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Given this setup, an R implementation of the strategy with, say, &lt;span class=&quot;math inline&quot;&gt;\(n=11\)&lt;/span&gt; looks as follows.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;strategy_unif &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(n) {
  &lt;span class=&quot;kw&quot;&gt;strategy_fip&lt;/span&gt;(n,&lt;span class=&quot;dt&quot;&gt;Enp1_fun=&lt;/span&gt;function(n,En) {&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;/&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;*(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;+En^&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;)})
}
(s_unif &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;strategy_unif&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;11&lt;/span&gt;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 0.861 0.850 0.836 0.820 0.800 0.775 0.742 0.695 0.625 0.500 0.000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can thus compare the computed expectations by simulation:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;## Simulate selection from n candidates if following the strategy s.
simulate &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(n,s) {
  x &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;runif&lt;/span&gt;(n)
  select_idx &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;which.max&lt;/span&gt;(x &amp;gt;&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;s)
  &lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;score=&lt;/span&gt;x[select_idx],&lt;span class=&quot;dt&quot;&gt;select_idx=&lt;/span&gt;select_idx,&lt;span class=&quot;dt&quot;&gt;isOverallBest=&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;rank&lt;/span&gt;(x)[select_idx] ==&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;n))
}

## Small simulation study to get expected score of the selected candidate
res &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;replicate&lt;/span&gt;(&lt;span class=&quot;fl&quot;&gt;1e5&lt;/span&gt;,&lt;span class=&quot;kw&quot;&gt;simulate&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;length&lt;/span&gt;(s_unif),&lt;span class=&quot;dt&quot;&gt;s=&lt;/span&gt;s_unif))
&lt;span class=&quot;kw&quot;&gt;apply&lt;/span&gt;(res,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,mean)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##         score    select_idx isOverallBest 
##         0.871         4.960         0.530&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;tail&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;compute_E&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;11&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;Enp1_fun=&lt;/span&gt;function(n,En) {&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;/&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;*(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;+En^&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;)}),&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.871&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As always, an animation says more than 1000 words and a few equations:&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-06-19-princesAsUniforms/animation.gif&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;Finally, we can see how the expected score develops with increasing &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt;.&lt;/p&gt;
&lt;center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&quot;header&quot;&gt;
&lt;th style=&quot;text-align: left;&quot;&gt;&lt;/th&gt;
&lt;th style=&quot;text-align: right;&quot;&gt;10&lt;/th&gt;
&lt;th style=&quot;text-align: right;&quot;&gt;100&lt;/th&gt;
&lt;th style=&quot;text-align: right;&quot;&gt;1000&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;score&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.862&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.981&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.998&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;select_idx&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;4.589&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;34.943&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;333.724&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;isOverallBest&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.544&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.426&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.409&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/center&gt;
&lt;p&gt;&lt;span class=&quot;citation&quot; data-cites=&quot;gilbert_mosteller1966&quot;&gt;Gilbert and Mosteller (1966)&lt;/span&gt; provide an approximation for the expectation:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;E_optE &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(n) { &lt;span class=&quot;dv&quot;&gt;1-2&lt;/span&gt;/(n+&lt;span class=&quot;kw&quot;&gt;log&lt;/span&gt;(n&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;)+&lt;span class=&quot;fl&quot;&gt;1.767&lt;/span&gt;) }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;which we can compare the &lt;code&gt;score&lt;/code&gt;column of the above simulation results:&lt;/p&gt;
&lt;center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&quot;header&quot;&gt;
&lt;th style=&quot;text-align: right;&quot;&gt;10&lt;/th&gt;
&lt;th style=&quot;text-align: right;&quot;&gt;100&lt;/th&gt;
&lt;th style=&quot;text-align: right;&quot;&gt;1000&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.859&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.981&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.998&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/center&gt;
&lt;p&gt;Altogether, this shows a pretty good agreement between the approximation and simulation results.&lt;/p&gt;
&lt;h4 id=&quot;example-n01&quot;&gt;Example N(0,1)&lt;/h4&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;## Compare results for the normal distribution (with and without
## analytic solution for 1st integral of the E[n+1] formula
&lt;span class=&quot;kw&quot;&gt;strategy_fip&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;11&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;df=&lt;/span&gt;dnorm,&lt;span class=&quot;dt&quot;&gt;pf=&lt;/span&gt;pnorm)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 1.324 1.276 1.223 1.162 1.092 1.011 0.913 0.790 0.630 0.399 0.000&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;(s_norm &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;strategy_fip&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;11&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;df=&lt;/span&gt;dnorm,&lt;span class=&quot;dt&quot;&gt;pf=&lt;/span&gt;pnorm,&lt;span class=&quot;dt&quot;&gt;intE_fun=&lt;/span&gt;function(En,...) {
  &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;/&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;*&lt;span class=&quot;kw&quot;&gt;sqrt&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;)*&lt;span class=&quot;kw&quot;&gt;exp&lt;/span&gt;(-&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;/&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;*En^&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;)/&lt;span class=&quot;kw&quot;&gt;sqrt&lt;/span&gt;(pi)
}))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 1.324 1.276 1.223 1.162 1.092 1.011 0.913 0.790 0.630 0.399 0.000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that by transforming the observations by the CDF &lt;span class=&quot;math inline&quot;&gt;\(F\)&lt;/span&gt;, i.e. &lt;span class=&quot;math inline&quot;&gt;\(Y_i=F(X_i)\)&lt;/span&gt; we for any continuous distribution obtain &lt;span class=&quot;math inline&quot;&gt;\(Y_i \stackrel{\text{iid}}{\sim} U(0,1)\)&lt;/span&gt;. Hence, the result of comparing the &lt;span class=&quot;math inline&quot;&gt;\(X_i\)&lt;/span&gt; against &lt;code&gt;s_norm&lt;/code&gt; is the same as comparing &lt;span class=&quot;math inline&quot;&gt;\(F(X_i)\)&lt;/span&gt; against &lt;code&gt;s_unif&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;set.seed&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)
x &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;rnorm&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;11&lt;/span&gt;) ; y &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;pnorm&lt;/span&gt;(x)
&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;which.max&lt;/span&gt;(x &amp;gt;&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;s_norm), &lt;span class=&quot;kw&quot;&gt;which.max&lt;/span&gt;(y &amp;gt;&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;s_unif))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## [1] 4 4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is thus not necessary to derive the optimal strategy for each possible continuous distribution. Instead one can transform the score to the uniform score as illustrated above and then use the corresponding strategy for the uniform to determine the stopping time.&lt;/p&gt;
&lt;h1 id=&quot;the-partial-information-game&quot;&gt;The Partial Information Game&lt;/h1&gt;
&lt;p&gt;To summarise the previous section&#39;s findings: knowing the candidate&#39;s score distribution means that no training sample is needed to form a baseline. Hence, in the full information game, one immediately is &lt;em&gt;ready for action&lt;/em&gt;: if a candidate with an excellent score is met early you do not hesitate! However, in a real word applications the parameters of the parametric distribution are likely to be unknown. This is known as the &lt;strong&gt;partial information game&lt;/strong&gt; and here statistical inference actually for the first time plays a role, because one needs to learn about the parameters of the distribution while candidates arrive and while simultaneously deciding to select the current candidate or keep looking.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;citation&quot; data-cites=&quot;stewart1978&quot;&gt;Stewart (1978)&lt;/span&gt; discusses a Bayesian approach to sequential learning the upper and lower limits of the underlying but unknown &lt;span class=&quot;math inline&quot;&gt;\(U(\alpha,\beta)\)&lt;/span&gt; distribution. Inspired by &lt;span class=&quot;citation&quot; data-cites=&quot;degroot1970&quot;&gt;DeGroot (1970)&lt;/span&gt;, a conjugate bilateral bivariate Pareto distribution on &lt;span class=&quot;math inline&quot;&gt;\((\alpha,\beta)\)&lt;/span&gt; is used. In what follows we describe this approach and the resulting selection strategy.&lt;/p&gt;
&lt;p&gt;We will assume a bilateral bivariate Pareto distribution as joint prior distribution for &lt;span class=&quot;math inline&quot;&gt;\(\alpha\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(\beta\)&lt;/span&gt;, i.e. the hierarchical Bayesian model is&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
\begin{align*}
(\alpha,\beta)                                &amp;amp; \sim \text{bPar}(k,l,u) \\
X_i \&amp;gt;|\&amp;gt; \alpha,\beta &amp;amp; \stackrel{\text{iid}}{\sim}   U(\alpha,\beta), &amp;amp; i=1,\ldots,n,
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where the density of the &lt;span class=&quot;math inline&quot;&gt;\(\text{bPar}(k,l,u)\)&lt;/span&gt; distribution is &lt;span class=&quot;math display&quot;&gt;\[
f(\alpha,\beta) = \frac{k(k+1)(u-l)^k}{(\beta-\alpha)^{k+2}} \cdot
I(\alpha&amp;lt;l \text{ and } \beta &amp;gt; u).
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Here, &lt;span class=&quot;math inline&quot;&gt;\(k&amp;gt;0\)&lt;/span&gt; is a shape parameter and &lt;span class=&quot;math inline&quot;&gt;\(I(\&amp;gt;)\)&lt;/span&gt; denotes the indicator function. In other words, the parameter &lt;span class=&quot;math inline&quot;&gt;\(l\)&lt;/span&gt; is an upper bound for the lower limit of the uniform (i.e. &lt;span class=&quot;math inline&quot;&gt;\(\alpha\)&lt;/span&gt;), and the parameter &lt;span class=&quot;math inline&quot;&gt;\(u\)&lt;/span&gt; is a lower limit for the upper limit of the uniform (i.e. &lt;span class=&quot;math inline&quot;&gt;\(\beta\)&lt;/span&gt;). We can think of &lt;span class=&quot;math inline&quot;&gt;\((-\infty,l)\)&lt;/span&gt; as our prior interval for the worst possible candidate applying and &lt;span class=&quot;math inline&quot;&gt;\((u,\infty)\)&lt;/span&gt; as our prior interval for the best possible candidate. The shape parameter &lt;span class=&quot;math inline&quot;&gt;\(k\)&lt;/span&gt; denotes how concentrated the prior density is near the limits &lt;span class=&quot;math inline&quot;&gt;\(l\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(u\)&lt;/span&gt;, respectively.&lt;/p&gt;
&lt;p&gt;In the example: the princess may think entitlements and the cool future title (king) ensures that the worst possible prince up for wooing her would at least be a five. Similarly, the lower bound on the upper limit means that the princess initially thinks that due to her stingy dad (the current king) the best overall applicant might, in worst case, just be about a seven. Finally, the parameter &lt;span class=&quot;math inline&quot;&gt;\(k\)&lt;/span&gt; quantifies the strength in her prior belief - the higher &lt;span class=&quot;math inline&quot;&gt;\(k\)&lt;/span&gt; the closer the true limits are to the values of &lt;span class=&quot;math inline&quot;&gt;\(l\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(u\)&lt;/span&gt;. Since the princess is unsure how well her prior is suited, she assumes a low value of &lt;span class=&quot;math inline&quot;&gt;\(k\)&lt;/span&gt;, say, &lt;span class=&quot;math inline&quot;&gt;\(k=0.1\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;#################################################
&lt;span class=&quot;co&quot;&gt;# Joint bilateral Pareto prior&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# Parameters:&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#  theta - vector length two containing (alpha,beta)&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#  k     - parameter&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#  l     - upper bound for alpha (i.e. an upper bound for the true lower bound)&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#  u     - lower for beta (i.e. a lower bound for the true upper bound)&lt;/span&gt;
################################################

f_pareto &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(theta,k,l,u) {
  if (&lt;span class=&quot;kw&quot;&gt;is.matrix&lt;/span&gt;(theta)) {
    alpha &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;theta[,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;] ; beta &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;theta[,&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;]
  } else {
    alpha &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;theta[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;]  ; beta &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;theta[&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;]
  }

  &lt;span class=&quot;co&quot;&gt;#Compute PDF&lt;/span&gt;
 &lt;span class=&quot;kw&quot;&gt;ifelse&lt;/span&gt;(alpha &amp;lt;&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;l &amp;amp;&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;beta &amp;gt;&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;u,
        k*(k&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;)*(u -&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;l)^k /&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;(beta-alpha)^(k&lt;span class=&quot;dv&quot;&gt;+2&lt;/span&gt;), &lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We illustrate the prior setting consisting of &lt;span class=&quot;math inline&quot;&gt;\(l=5\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(u=7\)&lt;/span&gt; and the two values &lt;span class=&quot;math inline&quot;&gt;\(k=0.1\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(k=1\)&lt;/span&gt;:&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-06-19-princesAsUniforms/PARETO_PDF-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;And the marginal density for two slices of the above joint density is:&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-06-19-princesAsUniforms/PDF_PARETO_MARGINAL-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;An important feature of this bivariate Pareto prior is that it is the conjugate prior to uniform sampling &lt;span class=&quot;citation&quot; data-cites=&quot;degroot1970&quot;&gt;(DeGroot 1970)&lt;/span&gt;. In other words, if &lt;span class=&quot;math inline&quot;&gt;\((\alpha,\beta) \sim \text{bPar}(k,l_0,u_0)\)&lt;/span&gt; and observations &lt;span class=&quot;math inline&quot;&gt;\(X_1,\ldots,X_i \stackrel{\text{iid}}{\sim} U(\alpha,\beta)\)&lt;/span&gt; become available, then the posterior distribution of interest is&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
(\alpha,\beta)&amp;#39; \&amp;gt;|\&amp;gt; X_1,\ldots,X_i \sim \text{bPar}(k+i,l_i,u_i),
\]&lt;/span&gt; where &lt;span class=&quot;math display&quot;&gt;\[
\begin{align*}
l_i &amp;amp;= \min(l_0,x_1,\ldots,x_i), \\
u_i &amp;amp;= \max(u_0,x_1,\ldots,x_i).
\end{align*}
\]&lt;/span&gt; In other words, the posterior depends only on &lt;span class=&quot;math inline&quot;&gt;\(l_i\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(u_i\)&lt;/span&gt; and not the individual &lt;span class=&quot;math inline&quot;&gt;\(x_i\)&lt;/span&gt;&#39;s. Let &lt;span class=&quot;math inline&quot;&gt;\(\gamma_i\)&lt;/span&gt; be the obtained score, if we at stage &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt; select the &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt;&#39;th candidate. Furthermore, using the same expectation definition as in the previous section, let &lt;span class=&quot;math inline&quot;&gt;\(E_i\)&lt;/span&gt; be the expected score obtained by following a particular strategy from the &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt;&#39;th candidate to the &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt;&#39;th candidate.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
\begin{align*}
\gamma_n &amp;amp;= x_n \\
E_i      &amp;amp;= E(\gamma_i | x_1,\ldots, x_{i-1}), &amp;amp; i \leq n, \\
\gamma_i &amp;amp;= \max(x_i, E_{i+1}),                  &amp;amp; i &amp;lt; n.
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;citation&quot; data-cites=&quot;stewart1978&quot;&gt;Stewart (1978)&lt;/span&gt; then shows that the optimal strategy is found by the following approach, which we here for simplicity shall program directly in R:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;## Small helper function to convert between index 0 and R&amp;#39;s index 1 storing
idx &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(i) i&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;

## Compute delta vector, which is a helper-vector in the solution of Stewart (1978)
compute_delta &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(n, k) {
  &lt;span class=&quot;co&quot;&gt;#Define delta&amp;#39;s&lt;/span&gt;
  delta &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;rep&lt;/span&gt;(&lt;span class=&quot;ot&quot;&gt;NA&lt;/span&gt;,n&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;)
  delta[&lt;span class=&quot;kw&quot;&gt;idx&lt;/span&gt;(n&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;)] =&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;/&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;

  for (i in &lt;span class=&quot;kw&quot;&gt;rev&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;seq_len&lt;/span&gt;(n&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;))) {
    if (delta[&lt;span class=&quot;kw&quot;&gt;idx&lt;/span&gt;(i)]&amp;gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;) {
      delta[&lt;span class=&quot;kw&quot;&gt;idx&lt;/span&gt;(i&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;)] &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;delta[&lt;span class=&quot;kw&quot;&gt;idx&lt;/span&gt;(i)]
    } else {
      delta[&lt;span class=&quot;kw&quot;&gt;idx&lt;/span&gt;(i&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;)] &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;/&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;*(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;+(k+i&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;)/(k+i&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;)*delta[&lt;span class=&quot;kw&quot;&gt;idx&lt;/span&gt;(i)]^&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;) +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;(k+i&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;)*delta[&lt;span class=&quot;kw&quot;&gt;idx&lt;/span&gt;(i)]/(k+i&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;)/(k+i&lt;span class=&quot;dv&quot;&gt;-2&lt;/span&gt;)
    }
  }

  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt;(delta)
}

###############################################################
## Bayesian sequential learning for a sequence of scores using the
## procedure described in Stewart (1978)
##
## Parameters:
##  x - vector of candidate scores (scores are only revealed sequentially)
##  prior - list containing prior values for k, l and u
###############################################################

strategy_pig &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(x, prior) {
  &lt;span class=&quot;co&quot;&gt;#Extract and precompute&lt;/span&gt;
  n &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;length&lt;/span&gt;(x)
  delta &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;compute_delta&lt;/span&gt;(n,&lt;span class=&quot;dt&quot;&gt;k=&lt;/span&gt;prior$k)

  &lt;span class=&quot;co&quot;&gt;#Generate data_frame to work on&lt;/span&gt;
  seq &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;data_frame&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;i=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;kw&quot;&gt;seq_len&lt;/span&gt;(n&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;)),&lt;span class=&quot;dt&quot;&gt;x=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;ot&quot;&gt;NA&lt;/span&gt;,x,&lt;span class=&quot;ot&quot;&gt;NA&lt;/span&gt;), &lt;span class=&quot;dt&quot;&gt;delta=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(delta,&lt;span class=&quot;ot&quot;&gt;NA&lt;/span&gt;))

  &lt;span class=&quot;co&quot;&gt;#Sequential updating of l and u from the data&lt;/span&gt;
  l &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;cummin&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(prior$l,x))
  u &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;cummax&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(prior$u,x))
  seq &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;seq %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;mutate&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;l=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(l,l[n]),&lt;span class=&quot;dt&quot;&gt;u=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(u,u[n]),&lt;span class=&quot;dt&quot;&gt;im1div2=&lt;/span&gt;i&lt;span class=&quot;fl&quot;&gt;-0.5&lt;/span&gt;)

  ##Compute expectation
  seq &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;seq %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;mutate&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;E=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;lag&lt;/span&gt;(delta)*&lt;span class=&quot;kw&quot;&gt;lag&lt;/span&gt;(u) +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;-&lt;span class=&quot;kw&quot;&gt;lag&lt;/span&gt;(delta))*&lt;span class=&quot;kw&quot;&gt;lag&lt;/span&gt;(l))
  ##Decision boundary
  seq &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;seq %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;mutate&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;threshold=&lt;/span&gt;delta*u +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;-delta)*l, &lt;span class=&quot;dt&quot;&gt;rank=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;rank&lt;/span&gt;(x),&lt;span class=&quot;dt&quot;&gt;isOverallBest=&lt;/span&gt;(rank ==&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;n))

  &lt;span class=&quot;co&quot;&gt;#Ensure that last candidate is always taken&lt;/span&gt;
  seq[n&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;:&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;threshold&amp;quot;&lt;/span&gt;] &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;min&lt;/span&gt;(x)

  ##Find r_1 and return there characteristics
  r1 &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;seq %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;filter&lt;/span&gt;(delta &amp;lt;=&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt; &amp;amp;&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;i &amp;lt;&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;n &amp;amp;&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;i &amp;gt;&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;max&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;-prior$k)) %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;slice&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;) %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt;(i) %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;as.numeric
  select &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;seq %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;filter&lt;/span&gt;(i &amp;gt;=&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;r1) %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;filter&lt;/span&gt;(x &amp;gt;=&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;threshold) %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;slice&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)
  
  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;seq=&lt;/span&gt;seq,&lt;span class=&quot;dt&quot;&gt;select=&lt;/span&gt;select))
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We now simulate a particular scenario consisting of 11 princes wooing a princess and apply the optimal selection strategy applying the princess&#39; prior:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Prior info
prior &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;k=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.1&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;l=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;5&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;u=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;7&lt;/span&gt;)

##Reverse engineering a happy end! :-)
&lt;span class=&quot;co&quot;&gt;# which(sapply(1:100, function(i) {&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#   set.seed(i); x &amp;lt;- runif(n=11,0,10)&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#   s &amp;lt;- strategy_pig(x, prior=prior)&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#   as.numeric(s$select[,&amp;quot;isOverallBest&amp;quot;])&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# })==1)&lt;/span&gt;

##Sample princes from an uniform with unknown limits -- here X_i \sim U(0,10)
&lt;span class=&quot;kw&quot;&gt;set.seed&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;8&lt;/span&gt;)
x &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;runif&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;11&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;)
s &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;strategy_pig&lt;/span&gt;(x, &lt;span class=&quot;dt&quot;&gt;prior=&lt;/span&gt;prior)
s$select&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## Source: local data frame [1 x 10]
## 
##       i     x delta     l     u im1div2     E threshold  rank isOverallBest
##   (dbl) (dbl) (dbl) (dbl) (dbl)   (dbl) (dbl)     (dbl) (dbl)         (lgl)
## 1     8  9.32 0.745  2.08  9.32     7.5  6.88      7.47    11          TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;figure&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-06-19-princesAsUniforms/animation-pig.gif&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;The animation provides interesting insights: Firstly, the upper bound on the lower limit is updated along the way, because some seriously unfit candidates dare to woo. Secondly, the decision boundary is initially slightly above our lower bound on the upper limit. However, the first candidate (candidate no. 3) above this prior bound is not accepted, since it is still early in the sequence and thus little is known about the support of the uniform, i.e. the range of candidates applying. Hence, the princess hopes to get an even better candidate. However, as time passes by and no such candidate appears, the limit is slowly adjusted downwards. Luckily, the 8&#39;th candidate not only brings a score better than imagined (and is thus selected), he also (seen through the omnipotent eyes of somebody knowing all the candidates) actually is the best prince among &lt;strong&gt;all&lt;/strong&gt; the candidates, i.e. &lt;code&gt;isOverallBest=TRUE&lt;/code&gt;. In other words: our mathematical fairy tale even has a happy end!&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-06-19-princesAsUniforms/Fairytale-Fantasy-Castle-Landscape-300px.png&quot; title=&quot;Source: https://openclipart.org/detail/231006/fairytale-fantasy-castle-landscape&quot; /&gt;
&lt;/center&gt;
&lt;h1 id=&quot;discussion&quot;&gt;Discussion&lt;/h1&gt;
&lt;p&gt;The full information game provides a good baseline to see the difference between having no information but the rank of candidates and knowing the distribution of the candidate&#39;s score. More references and variants of the secretary problem can be found in &lt;span class=&quot;citation&quot; data-cites=&quot;freeman1983&quot;&gt;Freeman (1983)&lt;/span&gt;.&lt;/p&gt;
&lt;h1 id=&quot;references&quot; class=&quot;unnumbered&quot;&gt;References&lt;/h1&gt;
&lt;div id=&quot;refs&quot; class=&quot;references&quot;&gt;
&lt;div id=&quot;ref-degroot1970&quot;&gt;
&lt;p&gt;DeGroot, Morris. 1970. &lt;em&gt;Optimal Statistical Decisions&lt;/em&gt;. McGraw-Hill. New York.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-freeman1983&quot;&gt;
&lt;p&gt;Freeman, P. R. 1983. âThe Secretary Problem and Its Extensions: A Review.â &lt;em&gt;International Statistical Review / Revue Internationale de Statistique&lt;/em&gt; 51 (2): 189â206. &lt;a href=&quot;http://www.jstor.org/stable/1402748&quot; class=&quot;uri&quot;&gt;http://www.jstor.org/stable/1402748&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-gilbert_mosteller1966&quot;&gt;
&lt;p&gt;Gilbert, J. P., and F. Mosteller. 1966. âRecognizing the Maximum of a Sequence.â &lt;em&gt;Journal of the American Statistical Association&lt;/em&gt; 61 (313): 35â73. &lt;a href=&quot;http://www.jstor.org/stable/2283044&quot; class=&quot;uri&quot;&gt;http://www.jstor.org/stable/2283044&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-guttman1960&quot;&gt;
&lt;p&gt;Guttman, I. 1960. âOn a Problem of L. Moser.â &lt;em&gt;Canadian Mathematical Bulletin&lt;/em&gt; 3: 35â39.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-stewart1978&quot;&gt;
&lt;p&gt;Stewart, T. J. 1978. âOptimal Selection from a Random Sequence with Learning of the Underlying Distribution.â &lt;em&gt;Journal of the American Statistical Association&lt;/em&gt; 73 (364): 775â80. &lt;a href=&quot;http://www.jstor.org/stable/2286279&quot; class=&quot;uri&quot;&gt;http://www.jstor.org/stable/2286279&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
        <pubDate>Sun, 19 Jun 2016 00:00:00 +0200</pubDate>
        <link>http://staff.math.su.se/hoehle/blog/2016/06/19/princesAsUniforms.html</link>
        <guid isPermaLink="true">http://staff.math.su.se/hoehle/blog/2016/06/19/princesAsUniforms.html</guid>
        
        <category>math</category>
        
        <category>rstats</category>
        
        <category>secretary problem</category>
        
        <category>stopping rule</category>
        
        
      </item>
    
      <item>
        <title>Optimal Choice - Mathematical Advice for Real Life</title>
        <description>&lt;p&gt;&lt;br&gt; &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width:0&quot; src=&quot;https://i.creativecommons.org/l/by-sa/4.0/88x31.png&quot;/&gt;&lt;/a&gt; This work is licensed under a &lt;a rel=&quot;license&quot;
href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt;. The markdown+Rknitr source code of this blog is available under a &lt;a href=&quot;https://www.gnu.org/licenses/gpl-3.0.html&quot;&gt;GNU General Public License (GPL v3)&lt;/a&gt; license from &lt;a href=&quot;https://github.com/hoehleatsu/hoehleatsu.github.io&quot;&gt;&lt;img src=&quot;/hoehle/blog/images/GitHub-Mark-32px.png&quot; alt=&quot;github&quot; /&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;We discuss how to choose the optimal candidate from a rankable sequence of candidates arriving one by one. The candidates could for example be job applicants, princes, tinder profiles or flats. This &lt;strong&gt;choice problem&lt;/strong&gt; is casted into the context of sequential decision making and is solved using optimal stopping theory. Two R functions are provided to compute optimal selection strategies in two specific instances of the problem. Altogether, the mathematical inclined decision maker is given valuable open-source tools to support prudent real life decision making.&lt;/p&gt;
&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Life is full of choices. The prudent &lt;a href=&quot;https://en.wikipedia.org/wiki/Decision-making&quot;&gt;decision maker&lt;/a&gt; likes to rationally balance alternatives, assess uncertain outcomes, gather additional information and - when ready - pick the best action. A mathematical approach to such decision making under uncertainty is based on maximizing an adequate utility function subject to the identified stochasticity, e.g., by maximizing expected utility. The ultimate statistical guides to such &lt;a href=&quot;https://en.wikipedia.org/wiki/Optimal_decision&quot;&gt;optimal decision making&lt;/a&gt; are the books by &lt;span class=&quot;citation&quot; data-cites=&quot;degroot1970&quot;&gt;DeGroot (1970)&lt;/span&gt; and &lt;span class=&quot;citation&quot; data-cites=&quot;berger1985&quot;&gt;Berger (1985)&lt;/span&gt;. &lt;a href=&quot;https://en.wikipedia.org/wiki/Influence_diagram&quot;&gt;Influence diagrams&lt;/a&gt; are compact representations of decision problems embedded within the graphical modelling toolset of Bayesian networks, see e.g. &lt;span class=&quot;citation&quot; data-cites=&quot;jensen_nielsen2007&quot;&gt;Jensen and Nielsen (2007)&lt;/span&gt;.&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-06-12-optimalChoice/indecisive-silhouette-300px-scaled.png&quot; title=&quot;Source: https://openclipart.org/detail/171299/indecisive-silhouettesvg&quot; /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;In this note we consider the very simple -- but entertaining -- sequential decision problem known as the optimal choice, secretary, marriage, dowry or game of googol problem &lt;span class=&quot;citation&quot; data-cites=&quot;ferguson1989&quot;&gt;(Ferguson 1989)&lt;/span&gt;. Scientific publishing about the &lt;a href=&quot;https://en.wikipedia.org/wiki/Secretary_problem&quot;&gt;&lt;strong&gt;optimal choice problem&lt;/strong&gt;&lt;/a&gt; dates back to the 1950&#39;s and 1960&#39;s, but accounts of variations of the problem date back as far as &lt;a href=&quot;https://en.wikipedia.org/wiki/Johannes_Kepler#Second_marriage&quot;&gt;1613&lt;/a&gt;. To illustrate the problem we use the process of finding a real estate property in an overheated housing market as example. Of course, the human resource manager, wooed princess, &lt;a href=&quot;http://www.npr.org/sections/krulwich/2014/05/15/312537965/how-to-marry-the-right-girl-a-mathematical-solution&quot;&gt;Johannes Kepler&lt;/a&gt;, tinder hustler as well as the mathematical enthusiast (subsets might overlap) should easily be able to adapt terminology to their needs.&lt;/p&gt;
&lt;h2 id=&quot;the-optimal-choice-problem&quot;&gt;The optimal choice problem&lt;/h2&gt;
&lt;p&gt;The rules of the game are as follows:&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;You want to choose exactly one property (say, buy a &lt;strong&gt;flat&lt;/strong&gt;) within a given period of time&lt;/li&gt;
&lt;li&gt;The number of candidate flats available on the market and inspectable in the given time period is assumed to be known. We shall denote this number by &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;The flats are assumed to be rankable from best (rank 1) to worst (rank &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt;) without ties.&lt;/li&gt;
&lt;li&gt;The flats can only be inspected sequentially and in some random order.&lt;/li&gt;
&lt;li&gt;After seeing a flat one has to decide whether to pick this flat or not.&lt;/li&gt;
&lt;li&gt;Once a flat is rejected, this choice is permanent and cannot be re-called.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Your objective is to find the &lt;em&gt;best candidate&lt;/em&gt; among the &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; flats. Less will not work for you, i.e. you have no interest in the 2nd best candidate or any other worse candidate. Furthermore, the decision you have to make at each decision time is to either select the current candidate flat or reject it and inspect futher candidate flats. Which flat to pick thus at each time point is based only on the flat&#39;s relative rank within the set of flats seen up to now. Our goal is to find a strategy s.t. we end up with the best flat, i.e. rank 1, among all of the &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; flats. Note that simply looking at all candidates and then picking the best one will not work due to rules 5 and 6.&lt;/p&gt;
&lt;h2 id=&quot;mathematical-notation&quot;&gt;Mathematical notation&lt;/h2&gt;
&lt;p&gt;Following &lt;span class=&quot;citation&quot; data-cites=&quot;chow_etal1964&quot;&gt;Chow et al. (1964)&lt;/span&gt; we introduce the following mathematical notation: Let &lt;span class=&quot;math inline&quot;&gt;\(x_1,\ldots, x_n\)&lt;/span&gt; be a permutation of the integers between 1 and &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt;. At the time we are considering the &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt;&#39;th candidate in our ordered sequence we have seen the candidates &lt;span class=&quot;math inline&quot;&gt;\(1,\ldots,i\)&lt;/span&gt;. Let &lt;span class=&quot;math inline&quot;&gt;\(y_i\)&lt;/span&gt;, &lt;span class=&quot;math inline&quot;&gt;\(y_i \in \{1,\ldots,i\}\)&lt;/span&gt;, denote the rank of the &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt;&#39;th candidate among these &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt; candidates We call this the &lt;strong&gt;relative rank&lt;/strong&gt; at time &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt; of the &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt;&#39;th candidate. Note that the relative rank can be 1 even though a candidates&#39; &lt;strong&gt;overall rank&lt;/strong&gt; is not 1. This is a consequence of the overall rank being only partially revealed by knowing more of the candidates.&lt;/p&gt;
&lt;p&gt;A code example illustrates the concept:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;co&quot;&gt;#Generate a sequence of ranks between 1 and n&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;set.seed&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;123&lt;/span&gt;)
n &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;10L ; x &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;sample&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;:n,&lt;span class=&quot;dt&quot;&gt;replace=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;FALSE&lt;/span&gt;)

&lt;span class=&quot;co&quot;&gt;#Function to compute sequential relative ranks, where smallest is best&lt;/span&gt;
relrank &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(x) {
  output &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;rep&lt;/span&gt;(&lt;span class=&quot;ot&quot;&gt;NA&lt;/span&gt;,&lt;span class=&quot;kw&quot;&gt;length&lt;/span&gt;(x))
  &lt;span class=&quot;co&quot;&gt;# take vector and find relative ranks, if sequentially disclosed&lt;/span&gt;
  for (i in &lt;span class=&quot;kw&quot;&gt;seq_len&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;length&lt;/span&gt;(x))) {
    output[i] &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;sum&lt;/span&gt;(x[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;:i] &amp;lt;=&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;x[i])
  }
  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt;(output)
}

&lt;span class=&quot;kw&quot;&gt;rbind&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;x=&lt;/span&gt;x, &lt;span class=&quot;dt&quot;&gt;y=&lt;/span&gt;y&amp;lt;-&lt;span class=&quot;kw&quot;&gt;relrank&lt;/span&gt;(x))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##   [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
## x    3    8    4    7    6    1   10    9    2     5
## y    1    2    2    3    3    1    7    7    2     5&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;finding-the-best&quot;&gt;Finding the best&lt;/h2&gt;
&lt;p&gt;It is possible to show &lt;span class=&quot;citation&quot; data-cites=&quot;gilbert_mosteller1966&quot;&gt;(Gilbert and Mosteller 1966)&lt;/span&gt; that the optimal selection policy is to follow the rather intuitive procedure:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Consider the first &lt;span class=&quot;math inline&quot;&gt;\(r-1\)&lt;/span&gt; candidates without picking any of them (=&amp;quot;training sample&amp;quot;).&lt;/li&gt;
&lt;li&gt;Then select the first candidate, which is better than the best among the training sample.&lt;/li&gt;
&lt;li&gt;If no candidate has been selected by the time &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; and, hence, the last candidate is reached, one is forced to select this candidate.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Mathematically expressed the optimal stopping time is thus&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
\min_{i \in \{r,\ldots,n\}}\{y_i = 1 \text{ or } i = n\}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The question is what &lt;span class=&quot;math inline&quot;&gt;\(r\)&lt;/span&gt; to choose? &lt;span class=&quot;citation&quot; data-cites=&quot;ferguson1989&quot;&gt;Ferguson (1989)&lt;/span&gt; in equation 2.1 shows that the probability &lt;span class=&quot;math inline&quot;&gt;\(\phi_n(r)\)&lt;/span&gt; of finding the overall best rank using a value of &lt;span class=&quot;math inline&quot;&gt;\(r\)&lt;/span&gt; in the above strategy is&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
\phi_n(r) = \frac{r-1}{n} \sum_{j=r}^n \frac{1}{j-1}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;It is obvious that &lt;span class=&quot;math inline&quot;&gt;\(\phi_n(1)=1/n\)&lt;/span&gt;. The remaining probabilities can easily be computed with R:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;co&quot;&gt;#Compute probability of finding max after screening the r-1 first out of n and then&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#picking the first, which is better than the best in the training sample.&lt;/span&gt;
phi &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(r,n) {
  if (r==&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;) &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;/n)
  j &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;r:n
  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt;((&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;/n)*(r&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;)*&lt;span class=&quot;kw&quot;&gt;sum&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;/(j&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;)))
}

&lt;span class=&quot;co&quot;&gt;#Compute probabilities for all i in {1,...,n}&lt;/span&gt;
df &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;data.frame&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;i=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;:n)
df &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;df %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;rowwise&lt;/span&gt;() %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;mutate&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;phi=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;phi&lt;/span&gt;(i,n)) %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;ungroup&lt;/span&gt;()
r &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;df %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;filter&lt;/span&gt;(phi==&lt;span class=&quot;kw&quot;&gt;max&lt;/span&gt;(phi))  %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt;(i)  %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;unlist&lt;/span&gt;() %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;as.numeric&lt;/span&gt;()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We can illustrate &lt;span class=&quot;math inline&quot;&gt;\(\phi_n(r)\)&lt;/span&gt; as a function of &lt;span class=&quot;math inline&quot;&gt;\(r\)&lt;/span&gt;:&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-06-12-optimalChoice/PHIPLOT-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;We thus select the &lt;span class=&quot;math inline&quot;&gt;\(r\)&lt;/span&gt;, which gives the highest value of &lt;span class=&quot;math inline&quot;&gt;\(\phi_n(r)\)&lt;/span&gt;. In the example with &lt;span class=&quot;math inline&quot;&gt;\(n=10\)&lt;/span&gt; we therefore look at &lt;span class=&quot;math inline&quot;&gt;\(r-1=3\)&lt;/span&gt; candidates in order to get a &lt;em&gt;baseline&lt;/em&gt; and then take the first candidate, which is better than this baseline. In the example:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;(pickIdx &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;which.max&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;relrank&lt;/span&gt;(x)[r:n] ==&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt; |&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;(r:n ==&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;n)))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;x[pickIdx +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;(r&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;)]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the example we thus actually manage to select the best candidate! However, this is not always guaranteed: for example, if the best overall candidate is among the training sample (4/10 chance for this to happen) we would end up with the last candidate flat no matter how good or bad it is. As stated above: the probability that the above decision strategy will pick the best candidate is &lt;span class=&quot;math inline&quot;&gt;\(\phi_{10}(4)=0.40\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;In order to compare the decision strategy with later formulations we denote by &lt;span class=&quot;math inline&quot;&gt;\(\mathbf{s}=(s_1,\ldots,s_n)\)&lt;/span&gt; a strategy which at time &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt; selects candidate &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt;, if &lt;span class=&quot;math inline&quot;&gt;\(y_i \leq s_i\)&lt;/span&gt;. In other words, the above strategy for &lt;span class=&quot;math inline&quot;&gt;\(n=10\)&lt;/span&gt; is:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;s &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;rep&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;,r&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;),&lt;span class=&quot;kw&quot;&gt;rep&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,n-(r&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;)-&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;),n)
s&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  0  0  0  1  1  1  1  1  1 10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And the selected candidate can easily found as&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;which.max&lt;/span&gt;(y &amp;lt;=&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;s)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## [1] 6&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For small &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; the optimal &lt;span class=&quot;math inline&quot;&gt;\(r\)&lt;/span&gt; and corresponding probability of success can easily be computed numerically. However, for large &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; the numerical precision as well as the computations become more tedious and hence interest is in finding a general asymptotic approximation as &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; grows large: One can show that as &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; gets large the optimal procedure is always to screen the first &lt;span class=&quot;math inline&quot;&gt;\(1/e\)&lt;/span&gt; = 37% and then select the first candidate better than the training sample &lt;span class=&quot;citation&quot; data-cites=&quot;gilbert_mosteller1966&quot;&gt;(Gilbert and Mosteller 1966)&lt;/span&gt;. The asymptotic probability of success, i.e. finding the overall best candidate, when following the such a procedure is also about &lt;span class=&quot;math inline&quot;&gt;\(1/e\)&lt;/span&gt;=37% &lt;span class=&quot;citation&quot; data-cites=&quot;gilbert_mosteller1966&quot;&gt;(Gilbert and Mosteller 1966)&lt;/span&gt;. Below we show a small table illustrating the precision of the asymptotic approximation.&lt;/p&gt;
&lt;center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&quot;header&quot;&gt;
&lt;th style=&quot;text-align: right;&quot;&gt;&lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt;&lt;/th&gt;
&lt;th style=&quot;text-align: right;&quot;&gt;&lt;span class=&quot;math inline&quot;&gt;\(r-1\)&lt;/span&gt;&lt;/th&gt;
&lt;th style=&quot;text-align: right;&quot;&gt;&lt;span class=&quot;math inline&quot;&gt;\((r-1)/n\)&lt;/span&gt; (%)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;10&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;4&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;40.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;100&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;38&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;38.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;1000&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;369&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;36.9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;10000&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;3680&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;36.8&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/center&gt;
&lt;p&gt;We summarise our above findings for how to find the best candidate in the following function:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;strategy_best &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(n) {
  r &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;find_r&lt;/span&gt;(n)
  s &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;rep&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;,r&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;),&lt;span class=&quot;kw&quot;&gt;rep&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,n-(r&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;)-&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;),n)
  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt;(s)
}

(s &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;strategy_best&lt;/span&gt;(n))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  0  0  0  1  1  1  1  1  1 10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;...and sometimes one animation says more than a lot of text and equations:&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-06-12-optimalChoice/animation-select.gif&quot; /&gt;
&lt;/figure&gt;
&lt;h2 id=&quot;maximizing-the-expected-rank&quot;&gt;Maximizing the expected rank&lt;/h2&gt;
&lt;p&gt;As attractive as it may sound, finding the overall best candidate appears a pedant&#39;s criterion. In reality, you would typically settle with a lesser rank, as long as you know the candidate is good and it&#39;s yours to keep. Hence, finding a &lt;a href=&quot;https://en.wikipedia.org/wiki/Satisficing&quot;&gt;satisficing&lt;/a&gt; strategy to minimize, e.g., the expected rank appears a more prudent objective for the risk adverse decision maker. This problem was addressed by &lt;span class=&quot;citation&quot; data-cites=&quot;chow_etal1964&quot;&gt;Chow et al. (1964)&lt;/span&gt;, we shall follow their treatment in what follows.&lt;/p&gt;
&lt;p&gt;In their paper they show that the relative ranks &lt;span class=&quot;math inline&quot;&gt;\(y_1,\ldots,y_n\)&lt;/span&gt; are independent and the probability mass function of the &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt;&#39;s relative rank is &lt;span class=&quot;math inline&quot;&gt;\(P(y_i=j)=1/i\)&lt;/span&gt;, &lt;span class=&quot;math inline&quot;&gt;\(j=1,\ldots,i\)&lt;/span&gt;. Furthermore, the sequence of relative ranks has the Markov property and, hence,&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
P(x_i=k|y_1=j_1,\ldots,y_{i-1}=j_{i-1},y_i=j) = P(x_i=k|y_i=j) =
\frac{\binom{k-1}{j-1} \binom{n-k}{i-j}}{\binom{n}{i}}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;From this one computes&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
E(x_i|y_i=j) = \sum_{k=1}^n k\cdot P(x_i=k|y_i=j) = \frac{n+1}{i+1} j.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Define &lt;span class=&quot;math inline&quot;&gt;\(c_i=c_i(n)\)&lt;/span&gt; to be the minimal possible expected overall rank selected if we limit us to strategies of the following type: use the first &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt; candidates to generate a baseline and then, starting from &lt;span class=&quot;math inline&quot;&gt;\(i+1\)&lt;/span&gt;, select the first candidate better than the baseline. &lt;span class=&quot;citation&quot; data-cites=&quot;chow_etal1964&quot;&gt;Chow et al. (1964)&lt;/span&gt; shows that &lt;span class=&quot;math inline&quot;&gt;\(c_i\)&lt;/span&gt; can be computed by backwards recursion: Beginning with&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
c_{n-1} = E\left(\frac{n+1}{n+1}y_n\right) = \frac{1}{n} \sum_{j=1}^n
j = \frac{n+1}{2},
\]&lt;/span&gt; and then for &lt;span class=&quot;math inline&quot;&gt;\(i=n-1,n-2,\ldots,1\)&lt;/span&gt; letting &lt;span class=&quot;math display&quot;&gt;\[
s_i     = \left[ \frac{i+1}{n+1} c_i\right] \\
c_{i-1} = \frac{1}{i} \left[ \frac{n+1}{i+1} \cdot \frac{s_i(s_i+1)}{2}+ (i-s_i)c_i \right],
\]&lt;/span&gt; where &lt;span class=&quot;math inline&quot;&gt;\([x]\)&lt;/span&gt; denotes the largest integer smaller or equal to &lt;span class=&quot;math inline&quot;&gt;\(x\)&lt;/span&gt;, i.e. &lt;code&gt;floor(x)&lt;/code&gt;. Because at each decision time &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt; we choose between either picking the current candidate or proceeding to the next candidate, we can evaluate the two options according to their expected payoff:&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;if we decide to wait deciding for at least another round the expected payoff is &lt;span class=&quot;math inline&quot;&gt;\(c_i\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;If we selected the current candidate, which has relative rank &lt;span class=&quot;math inline&quot;&gt;\(y_i=j\)&lt;/span&gt; our expected payoff is &lt;span class=&quot;math inline&quot;&gt;\(E(x_i|y_i=j)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Our optimal stopping time is thus&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
\min_{i\in \{1,\ldots,n\}} \{ E(x_i|y_i=j) \geq c_{i} \&amp;gt; \text{or} \&amp;gt; i=n \}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Implicitly, the above computed sequence of &lt;span class=&quot;math inline&quot;&gt;\(s_i\)&lt;/span&gt;&#39;s actually contains the resulting decision strategy &lt;span class=&quot;citation&quot; data-cites=&quot;chow_etal1964&quot;&gt;(Chow et al. 1964)&lt;/span&gt;. We transfer the procedure into R code as follows:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;co&quot;&gt;# Function to find a strategy minimizing expected rank as done by Chow et al. (1964).&lt;/span&gt;
strategy_erank &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(n) {
  c &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;s &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;rep&lt;/span&gt;(&lt;span class=&quot;ot&quot;&gt;NA&lt;/span&gt;,n)
  idx &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(i) {i&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;}
  c[&lt;span class=&quot;kw&quot;&gt;idx&lt;/span&gt;(n&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;)] &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;(n&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;)/&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;
  s[&lt;span class=&quot;kw&quot;&gt;idx&lt;/span&gt;(n)] &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;n

  for (i in (n&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;):&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;) {
    s[&lt;span class=&quot;kw&quot;&gt;idx&lt;/span&gt;(i)]   &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;floor&lt;/span&gt;( (i&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;)/(n&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;)*c[&lt;span class=&quot;kw&quot;&gt;idx&lt;/span&gt;(i)])
    c[&lt;span class=&quot;kw&quot;&gt;idx&lt;/span&gt;(i)-&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;] &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;/i *&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;( (n&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;)/(i&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;)*s[&lt;span class=&quot;kw&quot;&gt;idx&lt;/span&gt;(i)]*(s[&lt;span class=&quot;kw&quot;&gt;idx&lt;/span&gt;(i)]+&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)/&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt; +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;(i-s[&lt;span class=&quot;kw&quot;&gt;idx&lt;/span&gt;(i)])*c[&lt;span class=&quot;kw&quot;&gt;idx&lt;/span&gt;(i)])
  }

  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;s=&lt;/span&gt;s,&lt;span class=&quot;dt&quot;&gt;c=&lt;/span&gt;c))
}

&lt;span class=&quot;kw&quot;&gt;print&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;strategy_erank&lt;/span&gt;(n),&lt;span class=&quot;dt&quot;&gt;digits=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;4&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## $s
##  [1] NA  0  0  0  1  1  2  2  3  5 10
## 
## $c
##  [1] 2.558 2.558 2.558 2.558 2.677 2.888 3.154 3.590 4.278 5.500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that in the above, the first element of the vectors &lt;code&gt;s&lt;/code&gt; and &lt;code&gt;c&lt;/code&gt; is the element 0. Hence, &lt;span class=&quot;math inline&quot;&gt;\(s_1\)&lt;/span&gt; is located at position two of the vector. It is interesting to observe that for the example one forms a baseline for the same amount of time, but after a while becomes more &lt;strong&gt;desperate&lt;/strong&gt; and accepts candidates who are not optimal.&lt;/p&gt;
&lt;p&gt;Finally, it is interesting to compare the two strategies for any &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; we like, e.g. &lt;span class=&quot;math inline&quot;&gt;\(n=15\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;(two_s &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;rbind&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;best=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;strategy_best&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;15&lt;/span&gt;), &lt;span class=&quot;dt&quot;&gt;erank=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;strategy_erank&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;15&lt;/span&gt;)$s[-&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;]))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] [,15]
## best     0    0    0    0    0    1    1    1    1     1     1     1     1     1    15
## erank    0    0    0    0    1    1    1    1    2     2     3     4     5     7    15&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again, for the expected minimizing rank strategy our training sample is slightly smaller than for the selecting the best strategy. Furthermore, we again adapt our relative-rank criterion as one becomes more desperate towards the end. Finally, we illustrate the two strategies on the &lt;span class=&quot;math inline&quot;&gt;\(n=15\)&lt;/span&gt; sequence with ranks &lt;span class=&quot;math inline&quot;&gt;\(x\)&lt;/span&gt; (and resulting relative ranks &lt;span class=&quot;math inline&quot;&gt;\(y\)&lt;/span&gt;):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##   [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] [,15]
## x    8    5    6    9    1    3   10   12   14    15     4    13    11     2     7
## y    1    1    2    4    1    2    7    8    9    10     3    10     9     2     7&lt;/code&gt;&lt;/pre&gt;
&lt;figure&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-06-12-optimalChoice/animation-select2.gif&quot; /&gt;
&lt;/figure&gt;
&lt;h1 id=&quot;monte-carlo-simulation&quot;&gt;Monte Carlo simulation&lt;/h1&gt;
&lt;p&gt;Using Monte Carlo integration we can for a given &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; compute the expected rank obtained by each of the strategies.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;simulate &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(s,n) {
  x &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;sample&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;seq_len&lt;/span&gt;(n),&lt;span class=&quot;dt&quot;&gt;size=&lt;/span&gt;n,&lt;span class=&quot;dt&quot;&gt;replace=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;FALSE&lt;/span&gt;)
  y &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;relrank&lt;/span&gt;(x)
  idxSelect &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;which.max&lt;/span&gt;(y &amp;lt;=&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;s)
  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;rank=&lt;/span&gt;x[idxSelect],&lt;span class=&quot;dt&quot;&gt;idx=&lt;/span&gt;idxSelect,&lt;span class=&quot;dt&quot;&gt;isBest=&lt;/span&gt;(x[idxSelect]==&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)))
}

strategies &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;s_best=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;strategy_best&lt;/span&gt;(n), &lt;span class=&quot;dt&quot;&gt;s_erank=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;strategy_erank&lt;/span&gt;(n)$s[-&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;])
res &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;lapply&lt;/span&gt;(strategies, function(s) &lt;span class=&quot;kw&quot;&gt;replicate&lt;/span&gt;(&lt;span class=&quot;fl&quot;&gt;1e5&lt;/span&gt;, &lt;span class=&quot;kw&quot;&gt;simulate&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;s=&lt;/span&gt;s,&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;n)))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;(sim &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;rbind&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;best=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;apply&lt;/span&gt;(res[[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;]], &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,mean), &lt;span class=&quot;dt&quot;&gt;erank=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;apply&lt;/span&gt;(res[[&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;]],&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,mean)))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##          rank     idx  isBest
## best  3.02481 6.98755 0.39855
## erank 2.55563 6.27949 0.33177&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From the results it becomes clear that the expected rank optimizing strategy on average takes a little less time before selecting a candidate. Furthermore, the obtained expected rank is somewhat better than for the overall best decision strategy. We can also compare the Monte Carlo estimate &lt;code&gt;sim[&amp;quot;erank&amp;quot;,&amp;quot;rank&amp;quot;]&lt;/code&gt;=2.556 against the theoretical value of &lt;span class=&quot;math inline&quot;&gt;\(c_0\)&lt;/span&gt;=2.558.&lt;/p&gt;
&lt;h1 id=&quot;discussion&quot;&gt;Discussion&lt;/h1&gt;
&lt;p&gt;Is the blog title &lt;em&gt;Mathematical advice for real life&lt;/em&gt; an &lt;strong&gt;oxymoron&lt;/strong&gt;? Certainly not! Assumptions 1-6 clearly state the abstraction. You may not agree with these assumptions, but given that framework, the two functions &lt;code&gt;strategy_best&lt;/code&gt;and &lt;code&gt;strategy_erank&lt;/code&gt; give practical advice for a certain class of decisions. The methods are also clearly superior to &lt;a href=&quot;https://www.youtube.com/watch?v=BVIjqd8DBGw&quot;&gt;Sheldon Cooper&#39;s dice strategy&lt;/a&gt;. Furthermore, assumptions 1-6 have been improved upon in a multitude of ways &lt;span class=&quot;citation&quot; data-cites=&quot;freeman1983&quot;&gt;(Freeman 1983)&lt;/span&gt;. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;unknown &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; or random &lt;span class=&quot;math inline&quot;&gt;\(n\sim\operatorname{Po}(\lambda)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;the opportunity to return to previous candidates, but with a probability &lt;span class=&quot;math inline&quot;&gt;\(p\)&lt;/span&gt; of being rejected&lt;/li&gt;
&lt;li&gt;Candidate score originating from a known underlying distribution, e.g. the uniform or the normal&lt;/li&gt;
&lt;li&gt;Candidate score originating from an &lt;span class=&quot;math inline&quot;&gt;\(U(a,b)\)&lt;/span&gt; uniform with unknown &lt;span class=&quot;math inline&quot;&gt;\(a&amp;lt;b\)&lt;/span&gt;, but with a conjugate and sequentially updated bivariate Pareto prior on &lt;span class=&quot;math inline&quot;&gt;\((a,b)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Altogether, such methods provide decision support: One can evaluate a potential decision and compare results with other ways of reaching the decision. &lt;span class=&quot;citation&quot; data-cites=&quot;frey_eichenberger1996&quot;&gt;Frey and Eichenberger (1996)&lt;/span&gt; discuss that for marriage decisions investigations show that individuals decide rather quickly marrying the first reasonably serious partner. Where does this misalignment between theory and practice originate from? Some of it appears to be consequences of additional effects not addressed by the model, e.g., little marginal gain of searching longer, &lt;em&gt;lemon effects&lt;/em&gt;, satisficing, endowment effects, etc... &lt;strong&gt;Life is complicated&lt;/strong&gt;. Finding a satisficing complexity representation is non-trivial - even for mathematicians. :-)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-06-12-optimalChoice/unnamed-chunk-16-1.png&quot; style=&quot;display: block; margin: auto;&quot; /&gt;&lt;/p&gt;
&lt;h1 id=&quot;references&quot; class=&quot;unnumbered&quot;&gt;References&lt;/h1&gt;
&lt;div id=&quot;refs&quot; class=&quot;references&quot;&gt;
&lt;div id=&quot;ref-berger1985&quot;&gt;
&lt;p&gt;Berger, J. O. 1985. &lt;em&gt;Statistical Decision Theory and Bayesian Analysis : With 23 Illustrations&lt;/em&gt;. 2nd ed. Springer Series in Statistics. New York, Berlin, Heidelberg: Springer.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-chow_etal1964&quot;&gt;
&lt;p&gt;Chow, Y. S., S. Moriguti, H. Robbins, and S. M. Samuels. 1964. âOptimal Selection Based on Relative Rank (the âSecretary Problemâ).â &lt;em&gt;Israel Journal of Mathematics&lt;/em&gt; 2 (2): 81â90. doi:&lt;a href=&quot;https://doi.org/10.1007/BF02759948&quot;&gt;10.1007/BF02759948&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-degroot1970&quot;&gt;
&lt;p&gt;DeGroot, Morris. 1970. &lt;em&gt;Optimal Statistical Decisions&lt;/em&gt;. McGraw-Hill. New York.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-ferguson1989&quot;&gt;
&lt;p&gt;Ferguson, T. S. 1989. âWho Solved the Secretary Problem?â &lt;em&gt;Statist. Sci.&lt;/em&gt; 4 (3). The Institute of Mathematical Statistics: 282â89. doi:&lt;a href=&quot;https://doi.org/10.1214/ss/1177012493&quot;&gt;10.1214/ss/1177012493&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-freeman1983&quot;&gt;
&lt;p&gt;Freeman, P. R. 1983. âThe Secretary Problem and Its Extensions: A Review.â &lt;em&gt;International Statistical Review / Revue Internationale de Statistique&lt;/em&gt; 51 (2): 189â206. &lt;a href=&quot;http://www.jstor.org/stable/1402748&quot; class=&quot;uri&quot;&gt;http://www.jstor.org/stable/1402748&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-frey_eichenberger1996&quot;&gt;
&lt;p&gt;Frey, B. S., and R. Eichenberger. 1996. âMarriage Paradoxes.â &lt;em&gt;Rationality and Society&lt;/em&gt; 8 (2): 187â206.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-gilbert_mosteller1966&quot;&gt;
&lt;p&gt;Gilbert, J. P., and F. Mosteller. 1966. âRecognizing the Maximum of a Sequence.â &lt;em&gt;Journal of the American Statistical Association&lt;/em&gt; 61 (313): 35â73. &lt;a href=&quot;http://www.jstor.org/stable/2283044&quot; class=&quot;uri&quot;&gt;http://www.jstor.org/stable/2283044&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-jensen_nielsen2007&quot;&gt;
&lt;p&gt;Jensen, F. V., and T. D. Nielsen. 2007. &lt;em&gt;Bayesian Networks and Decision Graphs&lt;/em&gt;. 2nd ed. Springer Verlag.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
        <pubDate>Sun, 12 Jun 2016 00:00:00 +0200</pubDate>
        <link>http://staff.math.su.se/hoehle/blog/2016/06/12/optimalChoice.html</link>
        <guid isPermaLink="true">http://staff.math.su.se/hoehle/blog/2016/06/12/optimalChoice.html</guid>
        
        <category>datascience</category>
        
        <category>rstats</category>
        
        <category>debugging</category>
        
        
      </item>
    
      <item>
        <title>Right or Wrong? - Validate Numbers Like a Boss</title>
        <description>&lt;p&gt;&lt;br&gt; &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width:0&quot; src=&quot;https://i.creativecommons.org/l/by-sa/4.0/88x31.png&quot;/&gt;&lt;/a&gt; This work is licensed under a &lt;a rel=&quot;license&quot;
href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt;. The markdown+Rknitr source code of this blog is available under a &lt;a href=&quot;https://www.gnu.org/licenses/gpl-3.0.html&quot;&gt;GNU General Public License (GPL v3)&lt;/a&gt; license from &lt;a href=&quot;https://github.com/hoehleatsu/hoehleatsu.github.io&quot;&gt;&lt;img src=&quot;/hoehle/blog/images/GitHub-Mark-32px.png&quot; alt=&quot;github&quot; /&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;How does a statistician ensure that an analysis that comprises of outputting &lt;span class=&quot;math inline&quot;&gt;\(N\)&lt;/span&gt; results is correct? Can this be done without manually checking each of the results? Some statistical approaches for this task of &lt;strong&gt;proof-calculation&lt;/strong&gt; are described - e.g. capture-recapture estimation and sequential decision making.&lt;/p&gt;
&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;One activity the public associates with &lt;strong&gt;statistics&lt;/strong&gt; is the generation of large tables containing a multitude of numbers on a phenomena of interest. Below an example containing the summary of &lt;a href=&quot;https://www.ons.gov.uk/employmentandlabourmarket/peopleinwork/employmentandemployeetypes/bulletins/uklabourmarket/april2016&quot;&gt;UK labour market statistics&lt;/a&gt; for the 3 months to February 2016 from the Office for National Statistics:&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-05-22-proofCalculation/unemployment-apr2016.png&quot; title=&quot;Source: https://www.ons.gov.uk/employmentandlabourmarket/peopleinwork/employmentandemployeetypes/bulletins/uklabourmarket/april2016&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;Another example is The German Federal Governmentâs &lt;a href=&quot;http://www.bmas.de/DE/Service/Medien/Publikationen/a334-4-armuts-reichtumsbericht-2013.html&quot;&gt;4th Report on Poverty and Wealth&lt;/a&gt;. The report consists of a total of 549 pages with the pure table appendix fun starting on p. 518 including, e.g., age-adjusted ORs obtained from logistic regression modelling (p.523).&lt;/p&gt;
&lt;p&gt;Even though dynamic &amp;amp; web-based reporting coupled with graphical &amp;amp; interactive visualizations have developed to a point making such tables obsolete, this does not change the fact that the results still need to be &lt;strong&gt;correct&lt;/strong&gt;. As a consequence, the results need to be validated to ensure their correctness, occasionally even beyond any doubt! In what follow we will use the term &lt;strong&gt;result&lt;/strong&gt; to describe an output element of the statistical analysis. In most cases results are numbers, but we shall use the term number and result interchangeably. However, results could also denote higher level output elements, e.g., complete tables, a specific line in a graph or the complete output of a particular query.&lt;/p&gt;
&lt;p&gt;Surprisingly, statistics students are taught very little about addressing such a task using what we do best: statistics. We teach about the median, censoring &amp;amp; truncation, complex modelling and computer intensive inference methods. Maybe we even tell them about &lt;code&gt;knitr&lt;/code&gt; as way to get the same results twice (a minimum requirement to ensure correctness). However, spraying out numbers (even from the most beautiful model) is &lt;strong&gt;not cool&lt;/strong&gt; if the initial data-munging went wrong or if your quotient is obtained by dividing with the wrong denominator.&lt;/p&gt;
&lt;p&gt;The on-going discussion of &lt;strong&gt;reproducible research&lt;/strong&gt; aims at the core of this problem: How to ensure that your analysis re-producible and correct? As modern statistics becomes more and more programming oriented it appears natural to seek inspiration from the discipline of &lt;strong&gt;software testing&lt;/strong&gt;. Another entertaining source of inspiration is the concept of optimal &lt;strong&gt;proofreading&lt;/strong&gt;. This dates back to the 1970-1980s, where the problem is formulated as the search for an optimal stopping rules for the process of checking a text consisting of &lt;span class=&quot;math inline&quot;&gt;\(M\)&lt;/span&gt; words - see for example Yang et al. (1982). Periodically, the software development community re-visits these works - see for example Hayes (2010). Singpurwalla and Wilson (1999) give a thorough exposition of treating uncertainty in the context of software engineering by interfacing between statistics and software engineering.&lt;/p&gt;
&lt;h1 id=&quot;proofcalculation&quot;&gt;Proofcalculation&lt;/h1&gt;
&lt;p&gt;The scientific method of choice to address validity is &lt;strong&gt;peer review&lt;/strong&gt;. This can go as far as having the reviewer implement the analysis as a completely separate and independent process in order to check that results agree. Reporting the results of clinical trials have such independent implementations as part of the protocol. Such a co-pilot approach fits nicely to the fact that real-life statistical analysis rarely is a one-person activity anymore. In practice, there might neither be a need nor the resources to rebuild entire analyses, but critical parts need to be &lt;strong&gt;double-checked&lt;/strong&gt;. Pair programming is one technique from the agile programming world to accomodate this. However, single programmers coding independently and then compare results appears a better way to quality-control critical code &amp;amp; analysis segments.&lt;/p&gt;
&lt;p&gt;Formalizing the validation task into mathematical notation, let&#39;s assume the report of interest consists of a total of &lt;span class=&quot;math inline&quot;&gt;\(N\)&lt;/span&gt; numbers. These numbers have a hierarchical structure, e.g., they relate to various parts of the analysis or are part of individual tables. Error search is performed along this hierarchical structure. Good proofcalculation strategies follow the principles of software testing - for example it may be worthwhile to remember &lt;strong&gt;Pareto&#39;s law&lt;/strong&gt;: 80 percent of the error are found in 20 percent of the modules to test. In other words: keep looking for errors at places where you already found some. Further hints on a well structured debugging process can be found in Zeller (2009) where the quote on Pareto&#39;s law is also from.&lt;/p&gt;
&lt;p&gt;One crucial question is what exactly we mean by an &lt;strong&gt;error&lt;/strong&gt;? A result can be wrong, because of a bug in the code line computing it. Strictly speaking &lt;strong&gt;wrong&lt;/strong&gt; is just the (mathematical) black-and-white version of the complex phenomena describing a misalignment between what is perceived and what is desired by somebody. A more in-depth debate of what&#39;s &lt;em&gt;wrong&lt;/em&gt; is beyond the scope of this note, but certainly there are situations when a result is agreeably wrong, e.g., due to erroneous counting of the number of distinct elements in the denominator set. More complicated cases could be the use of a wrong regression model compared to what was described in the methodology section, e.g., use of an extra unintended covariate. Even worse are problems in the data-prepossessing step resulting in a wrong data foundation and, hence, invalidating a large part of the results. Altogether, a result be wrong in more than one way and one error can invalidate several results: the &lt;span class=&quot;math inline&quot;&gt;\(M\)&lt;/span&gt; results are just the final output - what matters is what happens along your &lt;strong&gt;analysis pipeline&lt;/strong&gt;. Detecting a wrong result is thus merely a symptom of a flawed pipeline. This also means that fixing the bug causing a number to be wrong does not necessarily ensure that the number is correct afterwards.&lt;/p&gt;
&lt;p&gt;We summarise the above discussion by making the following simplifying abstractions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The number of results which is wrong is a function of the number of errors &lt;span class=&quot;math inline&quot;&gt;\(M\)&lt;/span&gt;. One error invalidates at least one result, but it can invalidate several jointly and errors can overlap thus invalidating the same number.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;We deliberately keep the definition of an error vague, but mean a mechanism which causes a result to be wrong. The simplest form of a result is a number. The simplest error is a number which is wrong.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The hierarchical structure of the numbers and the intertwined code generating them is ignored. Instead, we simply assume there are &lt;span class=&quot;math inline&quot;&gt;\(M\)&lt;/span&gt; errors and assume that these errors are independent of each other.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We shall now describe an estimation approach a decision theoretic approach for the problem.&lt;/p&gt;
&lt;h1 id=&quot;team-based-validation&quot;&gt;Team Based Validation&lt;/h1&gt;
&lt;p&gt;Consider the situation where a team of two statisticians together validate the same report. Say the team use a fixed amount of time (e.g. one day) trying to find as many errors in the numbers as possible. During the test period no errors are fixed - this happens only after the end of the period. Let&#39;s assume that during the test period the two statistician found &lt;span class=&quot;math inline&quot;&gt;\(n_1\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(n_2\)&lt;/span&gt; wrong numbers, respectively. Let &lt;span class=&quot;math inline&quot;&gt;\(0 \leq n_{12} \leq \min(n_1,n_2)\)&lt;/span&gt; be the number of wrong numbers which were found by both statisticians.&lt;/p&gt;
&lt;p&gt;The data in alternative representation: Denote by &lt;span class=&quot;math inline&quot;&gt;\(f_i, i=1,2\)&lt;/span&gt; the number of wrong numbers found by &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt; of the testers, i.e.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
\begin{aligned}
f_1 &amp;amp;=(n_1-n_{12})+(n_2-n_{12})\\
f_2 &amp;amp;= n_{12}.
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;These are the wrong numbers found by only one of the testers and by both testers, respectively. Let &lt;span class=&quot;math inline&quot;&gt;\(S=f_1+f_2=n_1+n_2-n_{12}\)&lt;/span&gt; be the total number of erroneous numbers found in the test phase. Assuming that we in the subsequent debugging phase are able to remove all these &lt;span class=&quot;math inline&quot;&gt;\(S\)&lt;/span&gt; errors, we are interested in estimating the number of remaining errors, i.e. &lt;span class=&quot;math inline&quot;&gt;\(f_0\)&lt;/span&gt; or, alternatively, the total number of errors &lt;span class=&quot;math inline&quot;&gt;\(M=S+f_0\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Assume that after the first day of proofcalculation the two statisticians obtain the following results:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;testP &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;data.frame&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;t&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;9&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;12&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;6&lt;/span&gt;)))
&lt;span class=&quot;kw&quot;&gt;colnames&lt;/span&gt;(testP) &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;01&amp;quot;&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;10&amp;quot;&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;11&amp;quot;&lt;/span&gt;)
testP&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##   01 10 11
## 1  9 12  6&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;i.e. &lt;span class=&quot;math inline&quot;&gt;\(n_1=9\)&lt;/span&gt;, &lt;span class=&quot;math inline&quot;&gt;\(n_2=12\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(n_{12}=6\)&lt;/span&gt;. The total number of errors found so far is &lt;span class=&quot;math inline&quot;&gt;\(S=27\)&lt;/span&gt;. In the above code we use index &lt;code&gt;01&lt;/code&gt;, &lt;code&gt;10&lt;/code&gt; and &lt;code&gt;11&lt;/code&gt; specifying the results in two binary variable bit-notation - this is necessary for the &lt;code&gt;CARE1&lt;/code&gt; package used in the next section.&lt;/p&gt;
&lt;h2 id=&quot;estimating-the-total-number-of-wrong-numbers&quot;&gt;Estimating the total number of wrong numbers&lt;/h2&gt;
&lt;p&gt;Estimating the total number of errors from the above data is a capture-recapture problem with two time points (=sampling occasions).&lt;/p&gt;
&lt;h3 id=&quot;lincoln-petersen-estimator&quot;&gt;Lincoln-Petersen estimator&lt;/h3&gt;
&lt;p&gt;Under the simple assumption that the two statisticians are equally good at finding errors and that the possible errors have the same probability to be found (unrealistic?) a simple capture-recapture estimate for the total number of errors is the so called &lt;a href=&quot;https://en.wikipedia.org/wiki/Mark_and_recapture#Lincoln.E2.80.93Petersen_estimator&quot;&gt;Lincoln-Petersen estimator&lt;/a&gt;):&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
\hat{M} = \frac{n_1 \cdot n_2}{n_{12}}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Note that this estimator puts no upper-bound on &lt;span class=&quot;math inline&quot;&gt;\(N\)&lt;/span&gt;. The estimator can be computed using, e.g., the &lt;a href=&quot;https://cran.r-project.org/web/packages/CARE1/index.html&quot;&gt;&lt;code&gt;CARE1&lt;/code&gt;&lt;/a&gt; package:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;(M.hat &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;CARE1::&lt;span class=&quot;kw&quot;&gt;estN.pair&lt;/span&gt;(testP))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##  Petersen   Chapman        se       cil       ciu 
## 45.000000 42.428571  9.151781 32.259669 72.257758&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In other words, the estimated total number of errors is 45. A 95% confidence interval (CI) for &lt;span class=&quot;math inline&quot;&gt;\(M\)&lt;/span&gt; is 32-72 - see the package documentation for details on the method for computing the (CI). To verify the computations one could alternatively compute the Lincoln-Petersen estimator manually:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;(Nhat &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;(testP[&lt;span class=&quot;st&quot;&gt;&amp;quot;01&amp;quot;&lt;/span&gt;]+testP[&lt;span class=&quot;st&quot;&gt;&amp;quot;11&amp;quot;&lt;/span&gt;]) *&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;(testP[&lt;span class=&quot;st&quot;&gt;&amp;quot;10&amp;quot;&lt;/span&gt;]+testP[&lt;span class=&quot;st&quot;&gt;&amp;quot;11&amp;quot;&lt;/span&gt;]) /&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;testP[&lt;span class=&quot;st&quot;&gt;&amp;quot;11&amp;quot;&lt;/span&gt;])&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##   01
## 1 45&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, an estimate on the number of errors left to find is &lt;span class=&quot;math inline&quot;&gt;\(\hat{M}-S=18.0\)&lt;/span&gt;.&lt;/p&gt;
&lt;h2 id=&quot;heterogeneous-sampling-probabilities&quot;&gt;Heterogeneous Sampling Probabilities&lt;/h2&gt;
&lt;p&gt;If one does not want to assume the equal catch-probabilities of the errors, a range of alternatives exists. One of them is the procedure by Chao (1984, 1987). Here, a non-parametric estimate of the total number of errors is given as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
\hat{M} = S + \frac{f_1^2}{2 f_2}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The above estimator is based on the assumption that the two statisticians are equally good at spotting errors, but unlike for the Petersen-Lincoln estimator, errors can have heterogeneous detection probabilities. No specific parametric model for the detection is although required. An R implementation of the estimator is readily available as part of the &lt;a href=&quot;https://cran.r-project.org/web/packages/SPECIES/index.html&quot;&gt;&lt;code&gt;SPECIES&lt;/code&gt;&lt;/a&gt; package. For this, data first need to be stored as a &lt;code&gt;data.frame&lt;/code&gt; containing &lt;span class=&quot;math inline&quot;&gt;\(f_1, f_2\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;testPaggr &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;data.frame&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;j=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;:&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;f_j=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;as.numeric&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;sum&lt;/span&gt;(testP[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;:&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;]),testP[&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;])))
testPaggr&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##   j f_j
## 1 1  21
## 2 2   6&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;(M_est &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;SPECIES::&lt;span class=&quot;kw&quot;&gt;chao1984&lt;/span&gt;(testPaggr, &lt;span class=&quot;dt&quot;&gt;conf=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.95&lt;/span&gt;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## $Nhat
## [1] 64
## 
## $SE
## [1] 22.78363
## 
## $CI
##      lb  ub
## [1,] 39 139&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this case the estimator for the total number of errors is &lt;span class=&quot;math inline&quot;&gt;\(\hat{M}\)&lt;/span&gt;=64 (95% CI: 39-139). Again see the package documentation for methodological details.&lt;/p&gt;
&lt;!-- ### Manual computation --&gt;
&lt;!-- Again, if the computation can of course also be done manually: --&gt;
&lt;!-- ```{r} --&gt;
&lt;!-- f &lt;- testPaggr$n_j --&gt;
&lt;!-- S &lt;- sum(f) --&gt;
&lt;!-- ceiling(S + f[1]^2/(2*f[2])) --&gt;
&lt;!-- ``` --&gt;
&lt;h1 id=&quot;knowing-when-to-stop&quot;&gt;Knowing when to Stop&lt;/h1&gt;
&lt;p&gt;Whereas the above estimates are nice to know, they give little guidance on how, after the first day of testing, to decide between the following two alternatives: continue validating numbers for another day or stop the testing process and ship the report. We address this sequential decision making problem by casting it into a decision theoretic framework. Following the work of Ferguson and Hardwick (1989): let&#39;s assume that each futher round of proofcalculation costs an amount of &lt;span class=&quot;math inline&quot;&gt;\(C_p&amp;gt;0\)&lt;/span&gt; units and that each error undetected after additional &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; rounds of proofcalculation costs &lt;span class=&quot;math inline&quot;&gt;\(c_n&amp;gt;0\)&lt;/span&gt; units. Treating the total number of wrong results &lt;span class=&quot;math inline&quot;&gt;\(M\)&lt;/span&gt; as a random variable and letting &lt;span class=&quot;math inline&quot;&gt;\(X_1,\ldots,X_n\)&lt;/span&gt;, be the number of wrong results found in each of the additional proofcalculation rounds &lt;span class=&quot;math inline&quot;&gt;\(1,\ldots,n\)&lt;/span&gt;, we know that &lt;span class=&quot;math inline&quot;&gt;\(X_i\in \mathbb{N}_0\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(\sum_{j=1}^n X_j \leq N\)&lt;/span&gt;. One then formulates the conditional expected loss after &lt;span class=&quot;math inline&quot;&gt;\(n, n=0, 1, 2, \ldots,\)&lt;/span&gt; additional rounds of proofcalculation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
Y_n = n C_p + c_n E(M_n|X_1,\ldots,X_n),
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&quot;math inline&quot;&gt;\(M_n = M -(\sum_{j=1}^n X_j)\)&lt;/span&gt;. If we further assume that in the &lt;span class=&quot;math inline&quot;&gt;\((n+1)\)&lt;/span&gt;&#39;th proofcalculation round errors are detected independently of each other with probability &lt;span class=&quot;math inline&quot;&gt;\(p_n, 0 \leq p_n \leq 1\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(p_n\)&lt;/span&gt; being a known number we obtain that&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
X_{n+1} \&amp;gt;|\&amp;gt; M, X_1,\ldots,X_n \sim \text{Bin}(M_n, p_n), \quad n=0,1,2,\ldots.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Under the further assumption that &lt;span class=&quot;math inline&quot;&gt;\(M\sim \text{Po}(\lambda)\)&lt;/span&gt; with &lt;span class=&quot;math inline&quot;&gt;\(\lambda&amp;gt;0\)&lt;/span&gt; being known, one can show that the loss function is independent of the observations (Ferguson and Hardwick, 1989), i.e.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
Y_n = n C_p + c_n \lambda \prod_{j=0}^{n-1} (1-p_j), \quad n=0,1,2,\ldots.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The above Poisson assumption seems to be an acceptable approximation if the total number of results &lt;span class=&quot;math inline&quot;&gt;\(M\)&lt;/span&gt; is large and the probability of a result being wrong is low. In this case the optimal stopping rule is given by:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
n_{\text{stop}} = \min_{n\geq 0} Y_n.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;One limitation of the above approach is that we have used a &lt;strong&gt;guesstimate&lt;/strong&gt; on how the detection probability &lt;span class=&quot;math inline&quot;&gt;\(p_n\)&lt;/span&gt; evolves over time. An extension would be to sequentially estimate this parameter from the obtained results. This goes along the lines of Dalal and Mallows (1988) which discuss when to stop testing your software - see the following &lt;a href=&quot;/hoehle/blog/2016/05/06/when2stop.html&quot;&gt;blog entry&lt;/a&gt; for a short statistical treatment of their approach.&lt;/p&gt;
&lt;h3 id=&quot;numerical-example&quot;&gt;Numerical example&lt;/h3&gt;
&lt;p&gt;We consider a setup where the costly errors have substantial ramifications and thus are easy to detect early on. As time passes on the errors become more difficult to detect. This is reflected by the subsequent choices of &lt;span class=&quot;math inline&quot;&gt;\(p_n\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(c_n\)&lt;/span&gt; - see below. Furthermore, the expected number of bugs is taken to be the non-homogeneous capture-recapture estimate of the remaining errors. This coupling of the two procedures is somewhat pragmatic: it does not include the first round of proofcalculation in the decision making as this is used to estimate &lt;span class=&quot;math inline&quot;&gt;\(\lambda\)&lt;/span&gt;. Furthermore, no estimation uncertainty in &lt;span class=&quot;math inline&quot;&gt;\(\lambda\)&lt;/span&gt; from this stage is transferred to the subsequent stages.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;co&quot;&gt;#Cost of one round of proofcalculation (say in number of working days)&lt;/span&gt;
Cp &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#Cost of finding errors after n round of proofcalculation&lt;/span&gt;
cn &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(n) &lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;*&lt;span class=&quot;fl&quot;&gt;0.9&lt;/span&gt;^(&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;*(n&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;))
&lt;span class=&quot;co&quot;&gt;#Expected number of errors&lt;/span&gt;
(lambda &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;M_est$Nhat -&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;sum&lt;/span&gt;(testP))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## [1] 37&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;co&quot;&gt;#Probabilty of detecting an error in round j+1&lt;/span&gt;
pj &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(j) {
  &lt;span class=&quot;fl&quot;&gt;0.8&lt;/span&gt;^(j&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;)
}
&lt;span class=&quot;co&quot;&gt;#Expected conditional loss as defined above&lt;/span&gt;
Yn &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;Vectorize&lt;/span&gt;(function(n) {
  n*Cp +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;cn&lt;/span&gt;(n) *&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;lambda *&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;prod&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;-&lt;span class=&quot;kw&quot;&gt;pj&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;:(n&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;)))
})

&lt;span class=&quot;co&quot;&gt;#Make a data.frame with the results.&lt;/span&gt;
df &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;data.frame&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;:&lt;span class=&quot;dv&quot;&gt;20&lt;/span&gt;) %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;mutate&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;Yn=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;Yn&lt;/span&gt;(n),&lt;span class=&quot;dt&quot;&gt;cn=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;cn&lt;/span&gt;(n),&lt;span class=&quot;dt&quot;&gt;pn=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;pj&lt;/span&gt;(n&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The above choice of parameters leads to the following functional forms:&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-05-22-proofCalculation/unnamed-chunk-7-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;The optimal strategy is thus found as:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;df %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;filter&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;rank&lt;/span&gt;(Yn) ==&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;) %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt;(n,Yn)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##   n       Yn
## 1 5 6.457426&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In other words, one should test after &lt;span class=&quot;math inline&quot;&gt;\(n_{\text{stop}}=5\)&lt;/span&gt; additional rounds.&lt;/p&gt;
&lt;h1 id=&quot;discussion&quot;&gt;Discussion&lt;/h1&gt;
&lt;p&gt;Is any of the above &lt;strong&gt;useful&lt;/strong&gt;? Well, I have not heard about such approaches being used seriously in software engineering. The presented methods narrow down a complex problem down using assumptions in order to make the problem mathematically tractable. You may not agree with the assumptions as, e.g., Bolton (2010) - yet, such assumptions are a good way to get started. The point is that statisticians appear to be very good at enlightening others about the &lt;strong&gt;virtues of statistics&lt;/strong&gt; (repeat your measurements, have a sampling plan, pantomimic acts visualizing the horror of p-values). However, when it comes to our own analyses, we are surprisingly statistics-illiterate at times.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-05-22-proofCalculation/look_for_the_pattern-300px.png&quot; title=&quot;Source: https://openclipart.org/detail/248382/dropping-numbers&quot; /&gt;
&lt;/figure&gt;
&lt;h1 id=&quot;literature&quot;&gt;Literature&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Bolton, M (2010). &lt;a href=&quot;http://www.developsense.com/blog/2010/07/another-silly-quantitative-model/&quot;&gt;Another Silly Quantitative Model&lt;/a&gt;, Blog post, July 2010.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Cook, JD (2010). &lt;a href=&quot;http://www.johndcook.com/blog/2010/07/13/lincoln-index/&quot;&gt;How many errors are left to find?&lt;/a&gt;, Blog post, July 2010.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Dalal, S. R. and C. L. Mallows. â&lt;a href=&quot;http://www.jstor.org/stable/2289319&quot;&gt;When Should One Stop Testing Software?&lt;/a&gt;â. Journal of the American Statistical Association (1988), 83(403):872â879.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Ferguson, TS and Hardwick JP (1989). &lt;a href=&quot;http://www.jstor.org/stable/3214037&quot;&gt;Stopping Rules For Proofreading&lt;/a&gt;, J. Appl. Prob. 26:304-313.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Hayes, B (2010). &lt;a href=&quot;http://bit-player.org/2010/the-thrill-of-the-chase&quot;&gt;The thrill of the chase&lt;/a&gt;, Blog post, July 2010.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Singpurwalla ND, Wilson SP (1999). &lt;a href=&quot;http://www.springer.com/us/book/9780387988238&quot;&gt;Statistical Methods in Software Engineering&lt;/a&gt;, Springer.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Yang MCK, Wackerly DD, Rosalsky A (1982). &lt;a href=&quot;http://www.jstor.org/stable/3213535&quot;&gt;Optimal Stopping Rules in Proofreading&lt;/a&gt;, Journal of Applied Probability 19(3), pp. 723-729&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Zeller, A (2009). &lt;a href=&quot;http://www.whyprogramsfail.com/&quot;&gt;Why programs fail&lt;/a&gt;, Elsevier, 2009, 423 pages.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&quot;refs&quot; class=&quot;references&quot;&gt;

&lt;/div&gt;
</description>
        <pubDate>Sun, 22 May 2016 00:00:00 +0200</pubDate>
        <link>http://staff.math.su.se/hoehle/blog/2016/05/22/proofCalculation.html</link>
        <guid isPermaLink="true">http://staff.math.su.se/hoehle/blog/2016/05/22/proofCalculation.html</guid>
        
        <category>datascience</category>
        
        <category>rstats</category>
        
        <category>debugging</category>
        
        
      </item>
    
      <item>
        <title>When Should One Stop Testing Software?</title>
        <description>&lt;p&gt;&lt;br&gt; &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width:0&quot; src=&quot;https://i.creativecommons.org/l/by-sa/4.0/88x31.png&quot;/&gt;&lt;/a&gt; This work is licensed under a &lt;a rel=&quot;license&quot;
href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt;. The markdown+Rknitr source code of this blog is available under a &lt;a href=&quot;https://www.gnu.org/licenses/gpl-3.0.html&quot;&gt;GNU General Public License (GPL v3)&lt;/a&gt; license from &lt;a href=&quot;https://github.com/hoehleatsu/hoehleatsu.github.io&quot;&gt;&lt;img src=&quot;/hoehle/blog/images/GitHub-Mark-32px.png&quot; alt=&quot;github&quot; /&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;
&lt;p&gt;This is a small note rediscovering a gem published by S. R. Dalal and C. L. Mallows on treating the test of software in a statistical context (Dalal and Mallows, 1988). In their paper they answer the question on how long to continue testing your software before shipping. The problem is translated into a sequential decision problem, where an optimal stopping rule has to be found minimizing expected loss. We sketch the main result of their paper and apply their stopping rule to an example using R code.&lt;/p&gt;
&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Imagine that a team of developers of a new R package needs to structure a test plan before the release of the package to CRAN. Let &lt;span class=&quot;math inline&quot;&gt;\(N\)&lt;/span&gt; be the (unknown) number of bugs in the package. The team starts their testing at time zero and subsequently find an increasing number of bugs as the test period passes by. The figure below shows such a testing process mimicking the example of Dalal and Mallows (1988) from the testing of a large software system at a telecommunications research company.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-05-06-when2stop/unnamed-chunk-1-1.png&quot; style=&quot;display: block; margin: auto;&quot; /&gt;&lt;/p&gt;
&lt;p&gt;We see that the number of bugs appears to level off. The question is now &lt;em&gt;how long should we continue testing before releasing&lt;/em&gt;? Dalal and Mallows (1988) give an intriguing statistical answer to this problem.&lt;/p&gt;
&lt;h1 id=&quot;methodology&quot;&gt;Methodology&lt;/h1&gt;
&lt;p&gt;In order to answer the above question the following notation and assumptions are introduced:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The total number of bugs is assumed to be Poisson distributed &lt;span class=&quot;math display&quot;&gt;\[N \sim \text{Po}(\lambda).\]&lt;/span&gt; However, practice shows that the number of bugs in different modules has more variation that given by the Poisson distribution. Hence, let &lt;span class=&quot;math inline&quot;&gt;\(\lambda \sim \text{Ga}(\alpha,\beta)\)&lt;/span&gt; and thus the marginal distribution of &lt;span class=&quot;math inline&quot;&gt;\(N\)&lt;/span&gt; is negative binomial.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The amount of time until discovery of each bug during the testing period is distributed according to the known distribution &lt;span class=&quot;math inline&quot;&gt;\(G\)&lt;/span&gt; with density &lt;span class=&quot;math inline&quot;&gt;\(g\)&lt;/span&gt;. Furthermore, it can be assumed that the discoveries times are independent of each other. Example : The simplest example is to assume that the discovery distribution is exponential, i.e. &lt;span class=&quot;math inline&quot;&gt;\(g(t)=\mu\exp(-\mu t)\)&lt;/span&gt;, where we measure time in number of person-days spent on the testing. Thus, &lt;span class=&quot;math inline&quot;&gt;\(1/\mu\)&lt;/span&gt; is the expected time until discovery of a bug.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Let &lt;span class=&quot;math inline&quot;&gt;\(K(t)\)&lt;/span&gt; be the total number of bugs found up to time &lt;span class=&quot;math inline&quot;&gt;\(t\)&lt;/span&gt;. In other words, if &lt;span class=&quot;math inline&quot;&gt;\(t_1,\ldots,t_N\)&lt;/span&gt; denote the discovery times of the &lt;span class=&quot;math inline&quot;&gt;\(N\)&lt;/span&gt; bugs then&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[K(t)=\sum_{i=1}^N I(t_i \leq t),\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;where &lt;span class=&quot;math inline&quot;&gt;\(I(\cdot)\)&lt;/span&gt; is the indicator function. However, note that at time point &lt;span class=&quot;math inline&quot;&gt;\(t\)&lt;/span&gt;, only bugs with a discovery time smaller or equal to &lt;span class=&quot;math inline&quot;&gt;\(t\)&lt;/span&gt; would already have been observed and, hence, would be known to exist (right-truncation). Thus, even though &lt;span class=&quot;math inline&quot;&gt;\(K(t)\)&lt;/span&gt; is proportional to the empirical cumulative distribution function of the discovery distribution &lt;span class=&quot;math inline&quot;&gt;\(\hat{G}(t)\)&lt;/span&gt;, the factor of proportionality is &lt;span class=&quot;math inline&quot;&gt;\(N\)&lt;/span&gt;, which is unknown at the time &lt;span class=&quot;math inline&quot;&gt;\(t\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Note: The paper actually showns that the Poisson-Gamma distribution assumption for &lt;span class=&quot;math inline&quot;&gt;\(N\)&lt;/span&gt; is not crucial. An asymptotic argument is given that as long as the process does not terminate quickly (i.e. the number of bugs is relatively large) the results hold for more general distributions of &lt;span class=&quot;math inline&quot;&gt;\(N\)&lt;/span&gt;. Hence, in the analysis that follows, the parameter &lt;span class=&quot;math inline&quot;&gt;\(\lambda\)&lt;/span&gt; is not needed as we only proceed with the asymptotic approach of the paper.&lt;/p&gt;
&lt;h3 id=&quot;loss-function&quot;&gt;Loss function&lt;/h3&gt;
&lt;p&gt;In order to make a decision about when to stop testing based on expected loss/gain we need two further assumptions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Let &lt;span class=&quot;math inline&quot;&gt;\(c\)&lt;/span&gt; be the net cost of fixing a bug &lt;em&gt;after&lt;/em&gt; release of the software instead of &lt;em&gt;before&lt;/em&gt; the release. Hence, &lt;span class=&quot;math inline&quot;&gt;\(c\)&lt;/span&gt; is the price of fixing a bug after release minus the price of fixing a bug before release. The practice of software development tells us that &lt;span class=&quot;math inline&quot;&gt;\(c&amp;gt;0\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Let &lt;span class=&quot;math inline&quot;&gt;\(f(t)\)&lt;/span&gt; be a known non-negative and monotone increasing function reflecting the cost of testing plus the opportunity cost of not releasing the software up to time &lt;span class=&quot;math inline&quot;&gt;\(t\)&lt;/span&gt;. Note that the cost of testing does not contain the costs of fixing bugs, once they are found. A simple example for &lt;span class=&quot;math inline&quot;&gt;\(f\)&lt;/span&gt; is the linear loss function, i.e. &lt;span class=&quot;math inline&quot;&gt;\(f(t) = f \cdot t\)&lt;/span&gt;, where &lt;span class=&quot;math inline&quot;&gt;\(f&amp;gt;0\)&lt;/span&gt; is a known constant.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The above assumptions in summary imply the analysis of the following loss function:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[L(t,K(t),N) = f(t) - c K(t) + b\cdot N.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;As time passes, one obtains information about the number of bugs found through &lt;span class=&quot;math inline&quot;&gt;\(K(t)\)&lt;/span&gt;. At each time point the following decision has to be made: stop testing &amp;amp; ship the package or continue to test. Seen in a statistical context this can be rephrased into formulating a stopping rule such that the above loss function is minimized.&lt;/p&gt;
&lt;h3 id=&quot;optimal-stopping-time&quot;&gt;Optimal Stopping Time&lt;/h3&gt;
&lt;p&gt;In the simple model with exponential discovery times having rate &lt;span class=&quot;math inline&quot;&gt;\(\mu\)&lt;/span&gt;, the stopping rule stated as equation (4.6) of Dalal and Mallows (1988) is to stop as soon as the number, &lt;span class=&quot;math inline&quot;&gt;\(k\)&lt;/span&gt;, of bugs found at time &lt;span class=&quot;math inline&quot;&gt;\(t\)&lt;/span&gt;, i.e. &lt;span class=&quot;math inline&quot;&gt;\(K(t)=k\)&lt;/span&gt;, is such that:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
\frac{f}{c}\cdot \frac{\exp(\mu t) -1}{\mu} \geq k.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;At this time point, the estimated number of bugs left is Poisson with mean &lt;span class=&quot;math inline&quot;&gt;\(f/(c\mu)\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##########################################################################
&lt;span class=&quot;co&quot;&gt;# Function describing the LHS of (4.6) in the Delal and Mallows article&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# Parameters:&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#  fdivc - the quotient f/c&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#  mu    - the value of mu, this typically needs to be estimated from data&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#  testProcess - a data_frame containing the decision time points and the&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#               observed number of events&lt;/span&gt;
##########################################################################
lhs &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(fdivc,mu,testProcess) {
  fdivc*(&lt;span class=&quot;kw&quot;&gt;exp&lt;/span&gt;(mu*testProcess$t)-&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)/mu
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In the above, the quantity &lt;span class=&quot;math inline&quot;&gt;\(c/f\)&lt;/span&gt; measures the amount saved by finding a bug (and hence fixing it before release) measured in units of testing days. As an example: if &lt;span class=&quot;math inline&quot;&gt;\(c/f=0.2 \Leftrightarrow f/c=5\)&lt;/span&gt; then the gain in detecting a bug before release corresponds to 0.2 testing days. Throughout the subsequent example we shall work with both &lt;span class=&quot;math inline&quot;&gt;\(c/f=0.2\)&lt;/span&gt; (ship early and fix later is acceptable) and &lt;span class=&quot;math inline&quot;&gt;\(c/f=1\)&lt;/span&gt; (high costs of fixing bugs afte r the release).&lt;/p&gt;
&lt;h1 id=&quot;example&quot;&gt;Example&lt;/h1&gt;
&lt;p&gt;Taking the testing data from the above figure, the first step consists of estimating &lt;span class=&quot;math inline&quot;&gt;\(\mu\)&lt;/span&gt; from the available data. It is important to realize that the available data are a right-truncated sample, because only errors with a discovery time smaller than the current observation time are observed. Furthermore, if only data on the daily number of bug discoveries are available, then the data are also interval censored. We set up the loglikelihood function accordingly.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;#######################################################
&lt;span class=&quot;co&quot;&gt;#Log-likelihood function to maximize, which handles the&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#right truncation and interval censoring.&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# Paramers:&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#  theta - \log(\mu).&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#  testProcess - data_frame containing the observed data&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#  tC - the right-censoring time.&lt;/span&gt;
########################################################
ll &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(theta, testProcess, &lt;span class=&quot;dt&quot;&gt;tC=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;max&lt;/span&gt;(testProcess$t)) {
  mu &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;exp&lt;/span&gt;(theta)
  &lt;span class=&quot;co&quot;&gt;#Daily number of *new* bug discoveries. .&lt;/span&gt;
  DeltaK &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;kw&quot;&gt;diff&lt;/span&gt;(testProcess$K))
  &lt;span class=&quot;co&quot;&gt;#CDF function taking the right-truncation into account&lt;/span&gt;
  CDF &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(x) &lt;span class=&quot;kw&quot;&gt;pexp&lt;/span&gt;(x,&lt;span class=&quot;dt&quot;&gt;rate=&lt;/span&gt;mu)/&lt;span class=&quot;kw&quot;&gt;pexp&lt;/span&gt;(tC,&lt;span class=&quot;dt&quot;&gt;rate=&lt;/span&gt;mu)
  &lt;span class=&quot;co&quot;&gt;#Log-likelihood is equivalent to multinomial sampling with p being a func of mu.&lt;/span&gt;
  p &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;CDF&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;:(&lt;span class=&quot;kw&quot;&gt;max&lt;/span&gt;(testProcess$t)+&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)) -&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;CDF&lt;/span&gt;(testProcess$t)
  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;sum&lt;/span&gt;(DeltaK *&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;log&lt;/span&gt;(p)))
}
&lt;span class=&quot;co&quot;&gt;#Find MLE&lt;/span&gt;
mle &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;optim&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;log&lt;/span&gt;(&lt;span class=&quot;fl&quot;&gt;0.01&lt;/span&gt;),ll, &lt;span class=&quot;dt&quot;&gt;testProcess=&lt;/span&gt;testProcess, &lt;span class=&quot;dt&quot;&gt;control=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;fnscale=&lt;/span&gt;-&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;),&lt;span class=&quot;dt&quot;&gt;method=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;BFGS&amp;quot;&lt;/span&gt;)
mu.hat &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;exp&lt;/span&gt;(mle$par)
&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;mu=&lt;/span&gt;mu, &lt;span class=&quot;dt&quot;&gt;mu.hat=&lt;/span&gt;mu.hat)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##         mu     mu.hat 
## 0.02000000 0.01916257&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that we in the above used all data obtained over the entire testing period. In practice, one would instead sequentially update the &lt;span class=&quot;math inline&quot;&gt;\(\mu\)&lt;/span&gt; estimate each day as the information arrives -- see the animated sequential procedure in the next section.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-05-06-when2stop/unnamed-chunk-4-1.png&quot; style=&quot;display: block; margin: auto;&quot; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Source: local data frame [1 x 5]
## 
##       t     K K_estimate     sol5     sol1
##   (int) (dbl)      (dbl)    (dbl)    (dbl)
## 1    82   989   990.8676 994.9211 198.9842&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The optimal stopping time in the example, in the case of &lt;span class=&quot;math inline&quot;&gt;\(f/c=5\)&lt;/span&gt;, is to stop the testing after 82 testing days. An estimate of the expected number of remaining bugs at this stopping time would be 260.9, which appears to agree quite well with the empirical data -- actually, they were simulated with &lt;span class=&quot;math inline&quot;&gt;\(N=1250\)&lt;/span&gt;.&lt;/p&gt;
&lt;h1 id=&quot;animation&quot;&gt;Animation&lt;/h1&gt;
&lt;p&gt;The animation belows shows the above computations in sequential fashion:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;At a given time &lt;span class=&quot;math inline&quot;&gt;\(t\)&lt;/span&gt; of the testing process, &lt;span class=&quot;math inline&quot;&gt;\(\hat{\mu}\)&lt;/span&gt; is determined from the curve of cumulative bugs found up to time &lt;span class=&quot;math inline&quot;&gt;\(t\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;This &lt;span class=&quot;math inline&quot;&gt;\(\hat{\mu}\)&lt;/span&gt; estimate is then use to determine the intersecting curves as described above.&lt;/li&gt;
&lt;li&gt;Once the &lt;span class=&quot;math inline&quot;&gt;\(K(t)\)&lt;/span&gt; curve and the curve for a given &lt;span class=&quot;math inline&quot;&gt;\(f/c\)&lt;/span&gt; ratio intersect, we would stop the testing.&lt;/li&gt;
&lt;/ul&gt;
&lt;figure&gt;
&lt;img src=&quot;/hoehle/blog/downloads/animation.gif&quot; /&gt;
&lt;/figure&gt;
&lt;h1 id=&quot;discussion&quot;&gt;Discussion&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Assuming that the time periods until discovery of the bugs are independently distributed appears convenient, butnot so realistic. The paper has a section about analysing the situation in case of different classes of bugs. However, fixing a bug often spawns new bugs. Hence, the bug-process could instead be more realistically modelled by a self-exiciting process such as the Hawkes&#39; process (Hawkes, 1971).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;For Open Source Software and in particular R packages, which nobody might ever use, is &lt;span class=&quot;math inline&quot;&gt;\(c\)&lt;/span&gt; really bigger than zero? Ship and fix might be a good way to test, if a package actually addresses any kind of need?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;How to extract the daily number of bugs found from your bug tracking ticket system?&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;literature&quot;&gt;Literature&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Dalal, S. R. and C. L. Mallows. â&lt;a href=&quot;http://www.jstor.org/stable/2289319&quot;&gt;When Should One Stop Testing Software?&lt;/a&gt;â. Journal of the American Statistical Association (1988), 83(403):872â879.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Hawkes, A. G. &amp;quot;&lt;a href=&quot;http://biomet.oxfordjournals.org/content/58/1/83.abstract&quot;&gt;Spectra of some self-exciting and mutually exciting point processes&lt;/a&gt;&amp;quot;. Biometrika (1971), 58(1):83-90.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&quot;refs&quot; class=&quot;references&quot;&gt;

&lt;/div&gt;
</description>
        <pubDate>Fri, 06 May 2016 00:00:00 +0200</pubDate>
        <link>http://staff.math.su.se/hoehle/blog/2016/05/06/when2stop.html</link>
        <guid isPermaLink="true">http://staff.math.su.se/hoehle/blog/2016/05/06/when2stop.html</guid>
        
        <category>datascience</category>
        
        <category>rstats</category>
        
        <category>debugging</category>
        
        
      </item>
    
  </channel>
</rss>
