<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Theory meets practice...</title>
    <description>A blog about statistics in theory and practice. Not always serious, not always flawless, but definitely a statistically flavoured bean.
</description>
    <link>http://staff.math.su.se/hoehle/blog/</link>
    <atom:link href="http://staff.math.su.se/hoehle/blog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sun, 25 Dec 2016 22:02:15 +0100</pubDate>
    <lastBuildDate>Sun, 25 Dec 2016 22:02:15 +0100</lastBuildDate>
    <generator>Jekyll v3.1.6</generator>
    
      <item>
        <title>suRprise! - Classifying Kinder Eggs by Boosting</title>
        <description>&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Carrying the Danish tradition of Juleforsøg to the realm of statistics, we use R to classify the figure content of Kinder Eggs using boosted regression trees for the egg&#39;s weight and possible rattling noises.&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-12-23-surprise/pics/figures.jpg&quot; /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br&gt; &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width:0&quot; src=&quot;https://i.creativecommons.org/l/by-sa/4.0/88x31.png&quot;/&gt;&lt;/a&gt; This work is licensed under a &lt;a rel=&quot;license&quot;
href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt;. The markdown+Rknitr source code of this blog is available under a &lt;a href=&quot;https://www.gnu.org/licenses/gpl-3.0.html&quot;&gt;GNU General Public License (GPL v3)&lt;/a&gt; license from &lt;a href=&quot;https://github.com/hoehleatsu/hoehleatsu.github.io&quot;&gt;&lt;img src=&quot;/hoehle/blog/images/GitHub-Mark-32px.png&quot; alt=&quot;github&quot; /&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;A &lt;strong&gt;juleforsøg&lt;/strong&gt; is the kind of &lt;a href=&quot;https://www.youtube.com/watch?v=sinQ06YzbJI8&quot;&gt;exploding experiment&lt;/a&gt; happening in the last physics or chemistry class before the Christmas vacation. Not seldomly the teacher, with a look of secrecy, initializes the class by locking the door mumbling something like &amp;quot;the headmaster better not see this...&amp;quot;. With Christmas approaching fast, here is an attempt to create a statistical juleforsøg concluding the &lt;em&gt;Theory meets practice&lt;/em&gt; 2016 posting season:&lt;/p&gt;
&lt;p&gt;The advertisement campaign of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Kinder_Surprise&quot;&gt;Kinder Surprise Eggs&lt;/a&gt; aka. &lt;a href=&quot;https://en.wikipedia.org/wiki/Kinder_Joy&quot;&gt;Kinder Joy&lt;/a&gt; claims that the content of every 7th egg is a figure (see &lt;a href=&quot;https://blog.kalaydo.de/blog/wp-content/uploads/2016/05/Biene-Maja.jpg&quot;&gt;example&lt;/a&gt;) - otherwise they contain toys or puzzles, which positively can be described as junk. Figures, in particular completed series, on the other hand, can achieve high &lt;a href=&quot;https://translate.google.com/translate?sl=de&amp;amp;tl=en&amp;amp;js=y&amp;amp;prev=_t&amp;amp;hl=en&amp;amp;ie=UTF-8&amp;amp;u=https%3A%2F%2Fwww.kalaydo.de%2Fblog%2Fwertvolle-ue-ei-figuren%2F&amp;amp;edit-text=&amp;amp;act=url&quot;&gt;trading values&lt;/a&gt;. The clear goal is thus to optimize your egg hunting strategy in order to maximize figure content.&lt;/p&gt;
&lt;h2 id=&quot;the-problem&quot;&gt;The problem&lt;/h2&gt;
&lt;p&gt;Your budget is limited, so the question is which egg to select when standing in the supermarket?&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-12-23-surprise/pics/inshopwithprice.jpg&quot; /&gt;
&lt;/center&gt;
&lt;p&gt;
&lt;p&gt;Photo: Price in SEK per egg in a Swedish supermarket.&lt;/p&gt;
&lt;h3 id=&quot;various-egg-selection-strategies&quot;&gt;Various egg selection strategies&lt;/h3&gt;
&lt;p&gt;It goes without saying that brute force purchasing strategies would be insane. Hence, a number of egg selection strategies can be observed in real life:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The no clue egg enthusiast: Selects an egg at random. With a certain probability (determined by the producer and the cleverness of the previous supermarked visitors) the egg contains a figure&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The egg junkie: knows a good &lt;a href=&quot;https://www.radiologycafe.com/blog/easter-egg-xray&quot;&gt;radiologist&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The egg nerd: using &lt;a href=&quot;https://translate.google.com/translate?sl=de&amp;amp;tl=en&amp;amp;js=y&amp;amp;prev=_t&amp;amp;hl=en&amp;amp;ie=UTF-8&amp;amp;u=http%3A%2F%2Fwww.eierwiki.de%2Findex.php%3Ftitle%3DTipps_%2526_Tricks_beim_Eierkauf&amp;amp;edit-text=&amp;amp;act=url&quot;&gt;scale, rattling noises and the barcode&lt;/a&gt; he/she quickly determines whether there is a figure in the egg&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We shall in this post be interested in &lt;strong&gt;the statistician&#39;s egg selection approach&lt;/strong&gt;: Egg classification based on weight and rattling noise using &#39;top-notch&#39; machine learning algorithms - in our case based on boosted classification trees.&lt;/p&gt;
&lt;h2 id=&quot;data-collection&quot;&gt;Data Collection&lt;/h2&gt;
&lt;p&gt;We collected n=79 eggs of which 43.0% were figures - the data are available under a GPL v3.0 license from &lt;a href=&quot;https://github.com/hoehleatsu/hoehleatsu.github.io/blob/master/figure/source/2016-12-23-surprise/surprise.txt&quot;&gt;github&lt;/a&gt;. For each egg, we determined its &lt;strong&gt;weight&lt;/strong&gt; as well as the sound it produced when being shaken. If the sounds could be characterized as &lt;strong&gt;rattling&lt;/strong&gt; (aka. clattering) this was indicative of the content consisting of many parts and, hence, unlikely to be a figure.&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-12-23-surprise/pics/weightandrattle.jpg&quot; /&gt;
&lt;/center&gt;
&lt;p&gt;
&lt;p&gt;Altogether, the first couple of rows of the dataset look as follows.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;head&lt;/span&gt;(surprise, &lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;5&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##   weight rattles_like_figure figure rattles rattles_fac figure_fac
## 1     32                   1      0       0          no         no
## 2     34                   0      1       1         yes        yes
## 3     34                   1      1       0          no        yes
## 4     30                   1      0       0          no         no
## 5     34                   1      1       0          no        yes&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;descriptive-data-analysis&quot;&gt;Descriptive Data Analysis&lt;/h3&gt;
&lt;p&gt;The fraction of figures in the dataset was 34/79, which is way higher than the proclaimed 1/7; possibly, because professionals egg collectors were at work...&lt;/p&gt;
&lt;p&gt;Of the 79 analysed eggs, 54 were categorized as non-rattling. The probability of such a non-rattling egg really containing a figure was 51.9%. This proportion is not impressive, but could be due to the data collector&#39;s having a different understanding of exactly how the variable &lt;em&gt;rattling&lt;/em&gt; was to be interpreted: Does it &lt;em&gt;rattle&lt;/em&gt;, or does it &lt;em&gt;rattle like a figure&lt;/em&gt;? In hindsight, a clearer definition and communication of this variable would have prevented ambiguity in the collection.&lt;/p&gt;
&lt;p&gt;A descriptive plot of the weight distribution of eggs with and without figure content shows, that eggs with figures tend to be slightly heavier:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-12-23-surprise/WEIGHTPLOT-1.png&quot; style=&quot;display: block; margin: auto;&quot; /&gt; Note: About 50% of the eggs were weighted on a standard supermarket scales, which showed the result in steps of 2g only.&lt;/p&gt;
&lt;p&gt;Below the proportion (in %) of eggs with figure content per observed weight:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##           weight
## figure_fac    26    28    29    30    31    32    33    34    35    36    40
##        no  100.0  50.0  66.7  53.3  71.4  72.7  75.0  25.0 100.0  33.3   0.0
##        yes   0.0  50.0  33.3  46.7  28.6  27.3  25.0  75.0   0.0  66.7 100.0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A simple selection rule based on weight would be to weigh eggs until you hit a 40g egg. A slightly less certain stopping rule would be to pick 34g eggs. However, modern statistics is more than counting and analysing proportions!&lt;/p&gt;
&lt;h2 id=&quot;machine-learning-the-egg-content&quot;&gt;Machine Learning the Egg Content&lt;/h2&gt;
&lt;p&gt;We use machine learning algorithms to solve the binary classification problem at hand. In particular, we use the &lt;code&gt;caret&lt;/code&gt; package &lt;span class=&quot;citation&quot; data-cites=&quot;caret&quot;&gt;(Kuhn 2016)&lt;/span&gt; and classify figure content using boosted regression trees as implemented in the &lt;a href=&quot;https://en.wikipedia.org/wiki/Xgboost&quot;&gt;&lt;code&gt;xgboost&lt;/code&gt;&lt;/a&gt; package &lt;span class=&quot;citation&quot; data-cites=&quot;xgboost&quot;&gt;(Chen et al. 2016)&lt;/span&gt;. Details on how to use the &lt;code&gt;caret&lt;/code&gt; package can, e.g., be found in the following &lt;a href=&quot;https://topepo.github.io/caret/index.html&quot;&gt;tutorial&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;library&lt;/span&gt;(caret)

##Grid with xgboost hyperparameters
xgb_hyperparam_grid =&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;expand.grid&lt;/span&gt;(
  &lt;span class=&quot;dt&quot;&gt;nrounds =&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;25&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;50&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;250&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;1000&lt;/span&gt;),
  &lt;span class=&quot;dt&quot;&gt;eta =&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;fl&quot;&gt;0.01&lt;/span&gt;, &lt;span class=&quot;fl&quot;&gt;0.001&lt;/span&gt;, &lt;span class=&quot;fl&quot;&gt;0.0001&lt;/span&gt;),
  &lt;span class=&quot;dt&quot;&gt;max_depth =&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;seq&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;16&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;by=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;),
  &lt;span class=&quot;dt&quot;&gt;subsample =&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;fl&quot;&gt;0.4&lt;/span&gt;,&lt;span class=&quot;fl&quot;&gt;0.5&lt;/span&gt;,&lt;span class=&quot;fl&quot;&gt;0.6&lt;/span&gt;),
  &lt;span class=&quot;dt&quot;&gt;gamma =&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;colsample_bytree =&lt;/span&gt; &lt;span class=&quot;fl&quot;&gt;0.8&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;min_child_weight =&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;
)
##caret training control object
control &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;trainControl&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;method=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;repeatedcv&amp;quot;&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;number=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;8&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;repeats=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;8&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;classProbs=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;,
                        &lt;span class=&quot;dt&quot;&gt;summaryFunction =&lt;/span&gt; twoClassSummary, &lt;span class=&quot;dt&quot;&gt;allowParallel=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;)
##train away and do it parallelized...
&lt;span class=&quot;kw&quot;&gt;library&lt;/span&gt;(doMC)
&lt;span class=&quot;kw&quot;&gt;registerDoMC&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;cores =&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;)
m_xgb &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;train&lt;/span&gt;( figure_fac ~&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;weight *&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;rattles_fac, &lt;span class=&quot;dt&quot;&gt;data=&lt;/span&gt;surprise, &lt;span class=&quot;dt&quot;&gt;method=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;xgbTree&amp;quot;&lt;/span&gt;,
               &lt;span class=&quot;dt&quot;&gt;trControl=&lt;/span&gt;control, &lt;span class=&quot;dt&quot;&gt;verbose=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;FALSE&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;metric=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;ROC&amp;quot;&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;tuneGrid=&lt;/span&gt;xgb_hyperparam_grid)
##look at the result
m_xgb&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## eXtreme Gradient Boosting  
##   
##  79 samples 
##   2 predictor 
##   2 classes: &amp;#39;no&amp;#39;, &amp;#39;yes&amp;#39;  
##   
##  No pre-processing 
##  Resampling: Cross-Validated (8 fold, repeated 8 times)  
##  Summary of sample sizes: 69, 70, 69, 69, 69, 68, ...  
##  Resampling results across tuning parameters: 
##   
##    eta    max_depth  subsample  nrounds  ROC        Sens       Spec      
##    1e-04   2         0.4          25     0.6661328  0.8661458  0.4328125 
##    1e-04   2         0.4          50     0.6657943  0.8661458  0.4359375 
##    1e-04   2         0.4         100     0.6760938  0.8661458  0.4398437 
##    ...  ...        ... 
##    1e-02  16         0.6         250     0.6769792  0.7901042  0.4210937 
##    1e-02  16         0.6        1000     0.6578516  0.7364583  0.4335938 
##   
##  Tuning parameter &amp;#39;gamma&amp;#39; was held constant at a value of 1 
##  Tuning 
##   parameter &amp;#39;colsample_bytree&amp;#39; was held constant at a value of 0.8 
##  Tuning 
##   parameter &amp;#39;min_child_weight&amp;#39; was held constant at a value of 1 
##  ROC was used to select the optimal model using  the largest value. 
##  The final values used for the model were nrounds = 250, max_depth = 6, eta = 0.01, 
##   gamma = 1, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 0.4.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The average AUC for the 64 resamples is 0.69. Average sensitivity and specificity are 84.0% and 42.1%, respectively. This shows that predicting figure content with the available data is better than simply picking an egg at random, but no figure-guaranteeing strategy appears possible on a per-egg basis.&lt;/p&gt;
&lt;h3 id=&quot;predicting-the-content-of-a-particular-egg&quot;&gt;Predicting the Content of a Particular Egg&lt;/h3&gt;
&lt;p&gt;Suppose the egg you look at weighs 36g and, when shaken, sounds like a lot of small parts being moved. In other words:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;predict&lt;/span&gt;(m_xgb, &lt;span class=&quot;dt&quot;&gt;newdata =&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;data.frame&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;weight=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;36&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;rattles_fac=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;yes&amp;quot;&lt;/span&gt;),&lt;span class=&quot;dt&quot;&gt;type=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;prob&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##          no       yes
## 1 0.4329863 0.5670137&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Despite the rattling noises, the classifier thinks that it&#39;s slightly more likely that the content is a figure. However, when we opened this particular egg:&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-12-23-surprise/pics/car.jpg&quot; /&gt;
&lt;/center&gt;
&lt;p&gt;
&lt;p&gt;...a car. Definitely not a figure! The proof of concept disappointment was, however, quickly counteracted by the surrounding chocolate...&lt;/p&gt;
&lt;p&gt;As a standard operating procedure for your optimized future supermarket hunt, below are shown the classifier&#39;s predicted probabilities for figure content as a function of egg weight and the &lt;code&gt;rattles_fac&lt;/code&gt; variable.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-12-23-surprise/CLASSIFIEROUTPUT-1.png&quot; style=&quot;display: block; margin: auto;&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;discussion&quot;&gt;Discussion&lt;/h2&gt;
&lt;p&gt;The present post only discusses the optimal selection on a per-egg basis. One could weight &amp;amp; shake several eggs and then select the one with the highest predicted probability for containing a figure. Future research is needed to solve this sequential decision making problem in an &lt;a href=&quot;http://staff.math.su.se/hoehle/blog/2016/06/12/optimalChoice.html&quot;&gt;optimal way&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&quot;outlook&quot;&gt;Outlook&lt;/h3&gt;
&lt;p&gt;We have retained a validation sample of 10 eggs and are willing to send an unconsumed 11th element of the sample to whoever obtains the best score on this validation sample. Anyone who knows how to upload this to &lt;a href=&quot;https://www.kaggle.com&quot;&gt;kaggle&lt;/a&gt;?&lt;/p&gt;
&lt;center&gt;
We wish all readers &lt;em&gt;God jul&lt;/em&gt; and a happy new year!
&lt;/center&gt;
&lt;p&gt;
&lt;h2 id=&quot;acknowledgments&quot;&gt;Acknowledgments&lt;/h2&gt;
&lt;p&gt;Thanks to former colleagues at the Department of Statistics, University of Munich, as well as numerous statistics students in Munich and Stockholm, for contributing to the data collection. In particular we thank Alexander Jerak for his idea of optimizing figure hunting in a data driven way more than 10 years ago.&lt;/p&gt;
&lt;h2 id=&quot;literature&quot; class=&quot;unnumbered&quot;&gt;Literature&lt;/h2&gt;
&lt;div id=&quot;refs&quot; class=&quot;references&quot;&gt;
&lt;div id=&quot;ref-xgboost&quot;&gt;
&lt;p&gt;Chen, Tianqi, Tong He, Michael Benesty, Vadim Khotilovich, and Yuan Tang. 2016. &lt;em&gt;Xgboost: Extreme Gradient Boosting&lt;/em&gt;. &lt;a href=&quot;https://CRAN.R-project.org/package=xgboost&quot; class=&quot;uri&quot;&gt;https://CRAN.R-project.org/package=xgboost&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-caret&quot;&gt;
&lt;p&gt;Kuhn, Max. 2016. &lt;em&gt;Caret: Classification and Regression Training&lt;/em&gt;. &lt;a href=&quot;https://CRAN.R-project.org/package=caret&quot; class=&quot;uri&quot;&gt;https://CRAN.R-project.org/package=caret&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
        <pubDate>Fri, 23 Dec 2016 00:00:00 +0100</pubDate>
        <link>http://staff.math.su.se/hoehle/blog/2016/12/23/surprise.html</link>
        <guid isPermaLink="true">http://staff.math.su.se/hoehle/blog/2016/12/23/surprise.html</guid>
        
        <category>rstats</category>
        
        <category>stats</category>
        
        <category>programming</category>
        
        <category>juleforsøg</category>
        
        <category>classification</category>
        
        
      </item>
    
      <item>
        <title>4x3 R-Hackathoning - The Finisher&#39;s Guide</title>
        <description>&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;We present experiences from organizing a small R hackathon aimed at advancing knowledge and documentation of the R package surveillance. The hackathon was piggybacked on the ESCAIDE2016 conference visited by current and potential package users in the area of infectious disease epidemiology. The output of the hackathon is available at &lt;a href=&quot;https://surveillancer.github.io/tutorials/&quot; class=&quot;uri&quot;&gt;https://surveillancer.github.io/tutorials/&lt;/a&gt;.&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-12-12-hackinthedark/ears-1.png&quot; /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br&gt; &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width:0&quot; src=&quot;https://i.creativecommons.org/l/by-sa/4.0/88x31.png&quot;/&gt;&lt;/a&gt; This work is licensed under a &lt;a rel=&quot;license&quot;
href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt;. The markdown+Rknitr source code of this blog is available under a &lt;a href=&quot;https://www.gnu.org/licenses/gpl-3.0.html&quot;&gt;GNU General Public License (GPL v3)&lt;/a&gt; license from &lt;a href=&quot;https://github.com/hoehleatsu/hoehleatsu.github.io&quot;&gt;&lt;img src=&quot;/hoehle/blog/images/GitHub-Mark-32px.png&quot; alt=&quot;github&quot; /&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;A &lt;strong&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Hackathon&quot;&gt;hackathon&lt;/a&gt;&lt;/strong&gt; is a extreme-programming sprint-like event where people involved in software development (and beyond) meet for a short period of time with the purpose of collaborative programming, typically in the context of &lt;strong&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Open-source_software&quot;&gt;open-source software&lt;/a&gt;&lt;/strong&gt;. The word hackathon is a merger of &lt;strong&gt;hack&lt;/strong&gt; and &lt;strong&gt;marathon&lt;/strong&gt;, where &lt;a href=&quot;http://www.dictionary.com/browse/hack&quot;&gt;&lt;em&gt;hacking&lt;/em&gt;&lt;/a&gt; is to be understood as the skillful modification of computer programs (and not the malicious circumvention of security measures). Lots of good guides have been written on &lt;a href=&quot;https://hackathon.guide/&quot;&gt;how to run a successful Hackathon&lt;/a&gt;. In the area of &lt;strong&gt;infectious disease epidemiology&lt;/strong&gt;, which has been the main area of motivation for our statistical developments and implementations, very successful events (&lt;a href=&quot;https://sites.google.com/site/hackoutwiki/home&quot;&gt;hackout&lt;/a&gt;, &lt;a href=&quot;https://sites.google.com/site/hackout2/&quot;&gt;hackout2&lt;/a&gt;, &lt;a href=&quot;http://hackout3.ropensci.org/&quot;&gt;hackout3&lt;/a&gt;) have previously been organized. At a much smaller scale we wanted to ignite the energy and enthusiasm such an event spawns.&lt;/p&gt;
&lt;p&gt;As a consequence, this blog post gathers our experiences from organising a small &lt;strong&gt;4x3 hackathon&lt;/strong&gt; (4 people, 3 days) for the surveillance R-package in connection with the &lt;a href=&quot;http://ecdc.europa.eu/en/escaide/Pages/ESCAIDE.aspx&quot;&gt;ESCAIDE2016&lt;/a&gt; conference in November 2016. Our hope is that these experiences might be useful for others - even if working in very different contexts.&lt;/p&gt;
&lt;h2 id=&quot;organizing-and-running-the-hackathon&quot;&gt;Organizing and Running the Hackathon&lt;/h2&gt;
&lt;p&gt;We report on a number of practical &amp;quot;?&amp;quot; and &amp;quot;!&amp;quot; below.&lt;/p&gt;
&lt;h3 id=&quot;why&quot;&gt;Why?&lt;/h3&gt;
&lt;p&gt;Over the last several years we worked on a package for the visualization, modelling and monitoring of surveillance time series. As most of us are busy with other tasks now, it felt like a good idea to all meet in person to work a little on the package and network with potential users in order to increase awareness of the package. The 10&#39;th European Scientific Conference on Applied Infectious Disease Epidemiology (&lt;a href=&quot;http://ecdc.europa.eu/en/escaide/Pages/ESCAIDE.aspx&quot;&gt;ESCAIDE2016&lt;/a&gt;) organized by the &lt;a href=&quot;http://ecdc.europa.eu&quot;&gt;European Centre for Disease Prevention and Control&lt;/a&gt; (ECDC) in Stockholm, Sweden, 28-30 Nov 2016, with its about 600 participants, felt like the right place to be.&lt;/p&gt;
&lt;h3 id=&quot;a-cool-name&quot;&gt;A Cool Name?&lt;/h3&gt;
&lt;p&gt;Stockholm is placed on the 59th parallel north, hence, during end of November daylight is limited to approximately &lt;a href=&quot;http://www.timeanddate.com/sun/sweden/stockholm&quot;&gt;6:30 hours&lt;/a&gt;. In other words: Perfect hacking conditions. In order to honour this, &lt;strong&gt;Hack in the Dark&lt;/strong&gt; became our internal handle for the hackathon.&lt;/p&gt;
&lt;h3 id=&quot;who&quot;&gt;Who?&lt;/h3&gt;
&lt;p&gt;Hackathons come in all sizes. We decided on a mini four person hackathon of experienced R users, who all knew the package well: two former Ph.D. students who had used the package as the implementational repository for their methodological developments (one of them now being the package maintainer), a former power-user of the package and the package creator. Alternatively, we could have involved new persons in order to expand awareness of the package and increase diversity of the hackathonians, but we decided to go for the small team in order to maximize efficiency.&lt;/p&gt;
&lt;h3 id=&quot;venue&quot;&gt;Venue?&lt;/h3&gt;
&lt;p&gt;Piggybacking on an existing conference held in a large conference centre meant we did not have to worry about WLAN, food and seating. Especially when only being 4 persons.&lt;/p&gt;
&lt;h3 id=&quot;what-to-do&quot;&gt;What to do?&lt;/h3&gt;
&lt;p&gt;We started about 8 weeks before the hackathon to brainstorm using &lt;a href=&quot;https://slack.com/&quot;&gt;slack&lt;/a&gt; as a messaging system. We then created a priority matrix in &lt;a href=&quot;http://docs.google.com&quot;&gt;google docs&lt;/a&gt; allowing each of the participants to prioritize the ideas. This gave us an initial idea of what we wanted to do. Unfortunately, most of us then got pretty busy with other activities so we never managed to revisit the matrix until a couple of days before the start of the hackathon. Instead, we recapitulated matters in an &amp;quot;indian buffet process&amp;quot; meeting in Stockholm at the night before the hackathon:&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;Write i/o tutorials explaining how to get data into the package and then use package functions for cool visualizations of the data&lt;/li&gt;
&lt;li&gt;Use open European data for the tutorials - the theme of ESCAIDE2016 was after all: &lt;strong&gt;Data for action&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Make a &lt;a href=&quot;https://shiny.rstudio.com/&quot;&gt;shiny app&lt;/a&gt; to visualize the effect of various parameters choices for the surveillance algorithms implemented in the package. The best choice of configuration has been a recurrent user question throughout the years.&lt;/li&gt;
&lt;li&gt;Demo twitter surveillance by monitoring the conference hashtag &lt;code&gt;#ESCAIDE2016&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;source-code-management&quot;&gt;Source Code Management?&lt;/h3&gt;
&lt;p&gt;We chose to create an organization &lt;strong&gt;surveillancer&lt;/strong&gt; on &lt;a href=&quot;http://www.github.com&quot;&gt;github&lt;/a&gt;, which we then all joined with our individual github accounts. All new projects were then conducted by initiating new repositories. The &lt;code&gt;surveillance&lt;/code&gt; package itself is still developed on &lt;a href=&quot;http://www.r-forge.r-project.org&quot;&gt;R-Forge&lt;/a&gt; using &lt;code&gt;svn&lt;/code&gt;, but since we knew most of our work would be &lt;em&gt;using&lt;/em&gt; the surveillance package rather than &lt;em&gt;developing&lt;/em&gt; the package, we decided to keep the existing infrastructure for the package and instead develop the planned tutorials and visualizations in a new github project. This worked ok, but switching between &lt;code&gt;svn&lt;/code&gt; and &lt;code&gt;git&lt;/code&gt; for commits on different projects was not always helpful: &lt;code&gt;git commit -a&lt;/code&gt; is a useful friend if you don&#39;t know the &lt;a href=&quot;https://githowto.com/staging_changes&quot;&gt;git staging area&lt;/a&gt;...&lt;/p&gt;
&lt;h3 id=&quot;project-output-format&quot;&gt;Project Output Format?&lt;/h3&gt;
&lt;p&gt;We decided to create an R package and then use Hadley Wickham&#39;s new &lt;a href=&quot;https://hadley.github.io/pkgdown/&quot;&gt;pkgdown&lt;/a&gt; package to create a website containing all hackathon output. The above specified tutorials were then created as vignettes. An immediate advantage of this approach was that all hackathon output was bundled and that vignette code was directly available for the interested user.&lt;/p&gt;
&lt;h3 id=&quot;demo-demo-demo&quot;&gt;Demo, demo, demo!&lt;/h3&gt;
&lt;p&gt;Inspired by the extreme programming paradigm, and because we wanted to interact with the conference, we decided to demo at least once a day by posting hackathon output on twitter. Besides the outgoing publicity we also frequently demo&#39;ed internally in order to get input and suggestions. This worked pretty well - there is nothing as motivating and interactive as getting constructive input and suggestions from your table neighbour!&lt;/p&gt;
&lt;p&gt;Interaction with the other conference participants, on the other hand, was moderate. We showed parts and pieces to interested people, but in hindsight we should have aimed for a poster presentation or a related activity in order to generate more real-life awareness of the hackathon outside the virtual world of twitter.&lt;/p&gt;
&lt;h2 id=&quot;summing-up&quot;&gt;Summing Up&lt;/h2&gt;
&lt;p&gt;The three days of hackathon passed quickly, but we managed to get the four formulated outputs done.&lt;/p&gt;
&lt;p&gt;Intense software sprints are hard work, thus, it was natural that towards the end of the hackathon the concentration decreased slightly. However, phases of intense coding are perfectly supplemented by listening to scientific talks, talking to former colleagues visting the conference or sharing the passion of R with others working in the field. In particular it was nice to exchange ideas with &lt;a href=&quot;http://www.imperial.ac.uk/people/t.jombart&quot;&gt;Thibaut Jombart&lt;/a&gt;, whose &lt;a href=&quot;http://www.repidemicsconsortium.org/&quot;&gt;R Epidemics Consortium (RECON)&lt;/a&gt; project hopefully is able to bundle the R initiatives in infectious disease epidemiology a little. Besides the availability of software, the training aspect of new users (e.g. trainee epidemiologists) is also crucial. Finally, the &lt;strong&gt;aftermath&lt;/strong&gt; of the hackathon is as important as the pre-event planning: dedicated coordinators have to ensure that loose ends are wrapped up. Here, the participants&#39; enthusiasm declines quickly as other activities become higher priorities. Again, it&#39;s essential to have a clear goal of what needs to be done (e.g. a blog entry...).&lt;/p&gt;
&lt;p&gt;Altogether, code sessions such as a &lt;a href=&quot;http://staff.math.su.se/hoehle/blog/2016/08/04/outbreakEnd.html&quot;&gt;reproducibility session&lt;/a&gt; or a &lt;strong&gt;toolbox session&lt;/strong&gt; could be components for spicing up scientific conferences. For example the toolbox event could consist of a set of interested people, who on conference day 1 decide to implement a particular method useful in practice, and then demo it on the last day. Obviously, all these suggestions take time away from other conference content and certainly are more stressful than dozing of in the plenary sessions...&lt;/p&gt;
&lt;p&gt;No matter what, focus of a hackathon should also be on social aspects. It also proves wise not to ignore fresh air &amp;amp; sunlight completely. To our surprise, the 6:30 hours of daylight were at times actually quite sunny in Stockholm!&lt;/p&gt;
&lt;h3 id=&quot;visit-the-hack-in-the-dark-output&quot;&gt;Visit the Hack in the Dark Output&lt;/h3&gt;
&lt;p&gt;The output of the hackathon can be found here:&lt;/p&gt;
&lt;center&gt;
&lt;a href=&quot;https://surveillancer.github.io/tutorials/&quot; class=&quot;uri&quot;&gt;https://surveillancer.github.io/tutorials/&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;
&lt;p&gt;In order to run the accompanying code (available from github by clicking on the &amp;quot;fork me on github&amp;quot; icons), version 1.13.0 of the &lt;code&gt;surveillance&lt;/code&gt; package is needed (available from CRAN). As an appetizer to check out the hackathon &lt;a href=&quot;https://surveillancer.github.io/tutorials/&quot;&gt;site&lt;/a&gt; or the &lt;a href=&quot;https://github.com/surveillancer/tutorials&quot;&gt;code&lt;/a&gt;, here are two of our tweets demoing output during the event:&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;
First draft output of the &lt;a href=&quot;https://twitter.com/hashtag/ESCAIDE2016?src=hash&quot;&gt;#ESCAIDE2016&lt;/a&gt; surveillance &lt;a href=&quot;https://twitter.com/hashtag/rstats?src=hash&quot;&gt;#rstats&lt;/a&gt; hackathon: Visualizing &lt;a href=&quot;https://twitter.com/hashtag/opendata?src=hash&quot;&gt;#opendata&lt;/a&gt; by &lt;a href=&quot;https://twitter.com/ECDC_EU&quot;&gt;&lt;span class=&quot;citation&quot; data-cites=&quot;ECDC_EU&quot;&gt;(&lt;span class=&quot;citeproc-not-found&quot; data-reference-id=&quot;ECDC_EU&quot;&gt;&lt;strong&gt;???&lt;/strong&gt;&lt;/span&gt;)&lt;/span&gt;&lt;/a&gt; on Salmonella Agona. &lt;a href=&quot;https://twitter.com/hashtag/data4action?src=hash&quot;&gt;#data4action&lt;/a&gt; &lt;a href=&quot;https://t.co/8ApaDNF07L&quot;&gt;pic.twitter.com/8ApaDNF07L&lt;/a&gt;
&lt;/p&gt;
— Michael Höhle (@m_hoehle) &lt;a href=&quot;https://twitter.com/m_hoehle/status/803270577150631937&quot;&gt;November 28, 2016&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;
Interactive illustration of monitoring algorithms for infectious disease surveillance &lt;a href=&quot;https://twitter.com/hashtag/escaide2016?src=hash&quot;&gt;#escaide2016&lt;/a&gt; &lt;a href=&quot;https://twitter.com/hashtag/rstats?src=hash&quot;&gt;#rstats&lt;/a&gt; &lt;a href=&quot;https://t.co/qizcqqMbEJ&quot;&gt;https://t.co/qizcqqMbEJ&lt;/a&gt; &lt;a href=&quot;https://t.co/LyZujDLsF2&quot;&gt;pic.twitter.com/LyZujDLsF2&lt;/a&gt;
&lt;/p&gt;
— Dirk Schumacher (@dirk_sch) &lt;a href=&quot;https://twitter.com/dirk_sch/status/803573405660286976&quot;&gt;November 29, 2016&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;h3 id=&quot;the-future&quot;&gt;The Future&lt;/h3&gt;
&lt;p&gt;We wish you all the best for your own hackathon event. Put software on the scientific agenda!&lt;/p&gt;
&lt;h2 id=&quot;acknowledgments&quot;&gt;Acknowledgments&lt;/h2&gt;
&lt;p&gt;Thanks to &lt;a href=&quot;http://www.masalmon.eu/&quot;&gt;Maëlle Salmon&lt;/a&gt;, &lt;a href=&quot;https://www.dirk-schumacher.net/&quot;&gt;Dirk Schumacher&lt;/a&gt; and &lt;a href=&quot;http://www.imbe.med.uni-erlangen.de/cms/sebastian_meyer.html&quot;&gt;Sebastian Meyer&lt;/a&gt; for all their great work and the creative atmosphere during the hackathon! The event was implicitly supported by the Swedish Research Council as part of the project Statistical Modelling, Monitoring and Predictive Analytics against Infectious Disease Outbreaks (grant number 2015-05182_VR).&lt;/p&gt;
&lt;div id=&quot;refs&quot; class=&quot;references&quot;&gt;

&lt;/div&gt;
</description>
        <pubDate>Mon, 12 Dec 2016 00:00:00 +0100</pubDate>
        <link>http://staff.math.su.se/hoehle/blog/2016/12/12/hackinthedark.html</link>
        <guid isPermaLink="true">http://staff.math.su.se/hoehle/blog/2016/12/12/hackinthedark.html</guid>
        
        <category>rstats</category>
        
        <category>stats</category>
        
        <category>programming</category>
        
        
      </item>
    
      <item>
        <title>Better Confidence Intervals for Quantiles</title>
        <description>&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
\newcommand{\bm}[1]{\boldsymbol{\mathbf{#1}}}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\]&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;We discuss the computation of confidence intervals for the median or any other quantile in R. In particular we are interested in the interpolated order statistic approach suggested by &lt;span class=&quot;citation&quot; data-cites=&quot;hettmansperger_sheather1986&quot;&gt;Hettmansperger and Sheather (1986)&lt;/span&gt; and &lt;span class=&quot;citation&quot; data-cites=&quot;nyblom1992&quot;&gt;Nyblom (1992)&lt;/span&gt;. In order to make the methods available to a greater audience we provide an implementation of these methods in the R package &lt;code&gt;quantileCI&lt;/code&gt; and a small simulation study is conducted to show that these intervals indeed have a very good coverage. The study also shows that these intervals perform better than the currently available approaches in R. We therefore propose that these intervals should be used more in the future!&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-10-23-quantileCI/FIRSTPICTURE-1.png&quot; /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br&gt; &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width:0&quot; src=&quot;https://i.creativecommons.org/l/by-sa/4.0/88x31.png&quot;/&gt;&lt;/a&gt; This work is licensed under a &lt;a rel=&quot;license&quot;
href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt;. The markdown+Rknitr source code of this blog is available under a &lt;a href=&quot;https://www.gnu.org/licenses/gpl-3.0.html&quot;&gt;GNU General Public License (GPL v3)&lt;/a&gt; license from &lt;a href=&quot;https://github.com/hoehleatsu/hoehleatsu.github.io&quot;&gt;&lt;img src=&quot;/hoehle/blog/images/GitHub-Mark-32px.png&quot; alt=&quot;github&quot; /&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Statistics 101 teaches that for a distribution, possibly contaminated with outliers, a robust measure of the central tendency is the median. Not knowing this fact can make your analysis worthy to report in the &lt;a href=&quot;http://www.sueddeutsche.de/wirtschaft/heilbronn-dieser-mann-ist-so-reich-dass-statistiken-seines-wohnorts-wertlos-sind-1.2705044&quot;&gt;newspaper&lt;/a&gt; (&lt;a href=&quot;https://translate.google.com/translate?sl=de&amp;amp;tl=en&amp;amp;js=y&amp;amp;prev=_t&amp;amp;hl=en&amp;amp;ie=UTF-8&amp;amp;u=http%3A%2F%2Fwww.sueddeutsche.de%2Fwirtschaft%2Fheilbronn-dieser-mann-ist-so-reich-dass-statistiken-seines-wohnorts-wertlos-sind-1.2705044&amp;amp;edit-text=&quot;&gt;Google translate&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Higher quantiles of a distribution also have a long history as threshold for when to declare an observation an outlier. For example, growth curves for children illustrate how the quantiles of, e.g., &lt;a href=&quot;http://www.cdc.gov/growthcharts/data/set1clinical/cj41l024.pdf&quot;&gt;the BMI distribution develop by age&lt;/a&gt;. &lt;strong&gt;Obesity&lt;/strong&gt; is then for children defined as exceedance of the &lt;a href=&quot;http://www.who.int/growthref/bmifa_girls_z_5_19_labels.pdf?ua=1&quot;&gt;97.7% quantile&lt;/a&gt; of the distribution at a particular age. Quantile regression is a non-parametric method to compute such curves and the statistical community has been quite busy lately investigating new ways to compute such quantile regressions models.&lt;/p&gt;
&lt;p&gt;The focus of this blog post is nevertheless the simplest setting: Given an iid. sample &lt;span class=&quot;math inline&quot;&gt;\(\bm{x}\)&lt;/span&gt; of size &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; from a univariate and absolutely continuous distribution &lt;span class=&quot;math inline&quot;&gt;\(F\)&lt;/span&gt;, how does one compute an estimate for the &lt;span class=&quot;math inline&quot;&gt;\(p\)&lt;/span&gt;-Quantile of &lt;span class=&quot;math inline&quot;&gt;\(F\)&lt;/span&gt; together with a corresponding two-sided &lt;span class=&quot;math inline&quot;&gt;\((1-\alpha)\cdot 100\%\)&lt;/span&gt; confidence interval for it?&lt;/p&gt;
&lt;h3 id=&quot;the-point-estimate&quot;&gt;The Point Estimate&lt;/h3&gt;
&lt;p&gt;Computing the quantile in a sample with statistical software is discussed in the excellent survey of &lt;span class=&quot;citation&quot; data-cites=&quot;hyndman_fan1996&quot;&gt;Hyndman and Fan (1996)&lt;/span&gt;. The simplest estimator is based on the &lt;a href=&quot;https://en.wikipedia.org/wiki/Order_statistic&quot;&gt;order statistic&lt;/a&gt; of the sample, i.e. &lt;span class=&quot;math inline&quot;&gt;\(x_{(1)} &amp;lt; x_{(2)} &amp;lt; \cdots &amp;lt; x_{(n)}\)&lt;/span&gt;. &lt;span class=&quot;math display&quot;&gt;\[
\hat{x}_p = \min_{k} \left\{\hat{F}(x_{(k)}) \geq p\right\} = x_{(\lceil n \cdot p\rceil)},
\]&lt;/span&gt; where &lt;span class=&quot;math inline&quot;&gt;\(\hat{F}\)&lt;/span&gt; is the &lt;a href=&quot;https://en.wikipedia.org/wiki/Empirical_distribution_function&quot;&gt;empirical cumulative distribution&lt;/a&gt; function of the sample. Since &lt;span class=&quot;math inline&quot;&gt;\(\hat{F}\)&lt;/span&gt; has jumps of size &lt;span class=&quot;math inline&quot;&gt;\(1/n\)&lt;/span&gt; the actual value of &lt;span class=&quot;math inline&quot;&gt;\(\hat{F}(\hat{x}_{p})\)&lt;/span&gt; can end up being somewhat larger than the desired &lt;span class=&quot;math inline&quot;&gt;\(p\)&lt;/span&gt;. Therefore, &lt;span class=&quot;citation&quot; data-cites=&quot;hyndman_fan1996&quot;&gt;Hyndman and Fan (1996)&lt;/span&gt; prefer estimators interpolating between the two values of the order statistic with &lt;span class=&quot;math inline&quot;&gt;\(\hat{F}\)&lt;/span&gt; just below and just above &lt;span class=&quot;math inline&quot;&gt;\(p\)&lt;/span&gt;. It is interesting that even &lt;a href=&quot;http://robjhyndman.com/hyndsight/sample-quantiles-20-years-later/&quot;&gt;20 years after&lt;/a&gt;, there still is no universally accepted way to do this in different statistical software and the &lt;code&gt;type&lt;/code&gt; argument of the &lt;code&gt;quantile&lt;/code&gt; function in R has been a close friend when comparing results with SPSS or Stata users. In what follows we will, however, stick with the simple &lt;span class=&quot;math inline&quot;&gt;\(x_{(\lceil n \cdot p\rceil)}\)&lt;/span&gt; estimator stated above.&lt;/p&gt;
&lt;p&gt;Below is illustrated how one would use R to compute the, say, the 80% quantile of a sample using the above estimator. We can compute this either manually or using the &lt;code&gt;quantile&lt;/code&gt; function with &lt;code&gt;type=1&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Make a tiny artificial dataset, say, the BMI z-score of 25 children
&lt;span class=&quot;kw&quot;&gt;sort&lt;/span&gt;(x &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;rnorm&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;25&lt;/span&gt;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##  [1] -1.44090165 -1.40318433 -1.21953433 -0.95029549 -0.90398754 -0.66095890 -0.47801787
##  [8] -0.43976149 -0.36174823 -0.34116984 -0.33047704 -0.31576897 -0.28904542 -0.03789851
## [15] -0.03764990 -0.03377687  0.22121130  0.30331291  0.43716773  0.47435054  0.60897987
## [22]  0.64611097  1.20086374  1.52483138  2.67862782&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Define the quantile we want to consider
p &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.8&lt;/span&gt;
##Since we know the true distribution we can easily find the true quantile
(x_p &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;qnorm&lt;/span&gt;(p))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8416212&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Compute the estimates using the quantile function and manually
&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;quantile=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;quantile&lt;/span&gt;(x, &lt;span class=&quot;dt&quot;&gt;type=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;prob=&lt;/span&gt;p), &lt;span class=&quot;dt&quot;&gt;manual=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;sort&lt;/span&gt;(x)[&lt;span class=&quot;kw&quot;&gt;ceiling&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;length&lt;/span&gt;(x)*p)])&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## quantile.80%       manual 
##    0.4743505    0.4743505&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;confidence-interval-for-the-quantile&quot;&gt;Confidence interval for the quantile&lt;/h3&gt;
&lt;p&gt;Besides the point estimate &lt;span class=&quot;math inline&quot;&gt;\(\hat{x}_p\)&lt;/span&gt; we also would like to report a two-sided &lt;span class=&quot;math inline&quot;&gt;\((1-\alpha)\cdot 100\%\)&lt;/span&gt; confidence interval &lt;span class=&quot;math inline&quot;&gt;\((x_p^{\text{l}}, x_p^{\text{u}})\)&lt;/span&gt; for the desired population quantile. The interval &lt;span class=&quot;math inline&quot;&gt;\((x_p^{\text{l}}, x_p^{\text{u}})\)&lt;/span&gt; should, hence, fulfill the following condition: &lt;span class=&quot;math display&quot;&gt;\[
P( (x_p^{\text{l}}, x_p^{\text{u}}) \ni x_p) = 1 - \alpha,
\]&lt;/span&gt; where we have used the &amp;quot;backwards&amp;quot; &lt;span class=&quot;math inline&quot;&gt;\(\in\)&lt;/span&gt; to stress the fact that it&#39;s the interval which is random. Restricting the limits of this confidence intervals to be &lt;strong&gt;one of the realisations from the order statistics&lt;/strong&gt; implies that we need to find indices &lt;span class=&quot;math inline&quot;&gt;\(d\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(e\)&lt;/span&gt; with &lt;span class=&quot;math inline&quot;&gt;\(d&amp;lt;e\)&lt;/span&gt; s.t. &lt;span class=&quot;math display&quot;&gt;\[
P( x_{(d)} \leq x_p \leq x_{(e)}) \geq 1 - \alpha.
\]&lt;/span&gt; Note that it may not be possible to achieve the desired coverage exactly in this case. For now we prefer the conservative choice of having to attain &lt;strong&gt;at least&lt;/strong&gt; the desired coverage. Note that for &lt;span class=&quot;math inline&quot;&gt;\(1\leq r \leq n\)&lt;/span&gt; we have &lt;span class=&quot;math display&quot;&gt;\[
\begin{align*}
P( x_{r} \leq x_p) &amp;amp;= P(\text{at least $r$ observations are smaller than or equal to $x_p$}) \\
      &amp;amp;= \sum_{k=r}^{n} P(\text{exactly $k$ observations are smaller than or equal to $x_p$}) \\
      &amp;amp;= \sum_{k=r}^{n} {n \choose k} P(X \leq x_p)^k (1-P(X \leq x_p))^{n-k} \\
      &amp;amp;= \sum_{k=r}^{n} {n \choose k} p^k (1-p)^{n-k} \\
      &amp;amp;= 1 - \sum_{k=0}^{r-1} {n \choose k} p^k (1-p)^{n-k}
\end{align*}
\]&lt;/span&gt; In principle, we could now try out all possible &lt;span class=&quot;math inline&quot;&gt;\((d,e)\)&lt;/span&gt; combinations and for each interval investigate, whether it has the desired &lt;span class=&quot;math inline&quot;&gt;\(\geq 1-\alpha/2\)&lt;/span&gt; property. If several combinations achieve this criterion we would, e.g., take the interval having minimal length. This is what the &lt;code&gt;MKmisc::quantileCI&lt;/code&gt; function does. However, the number of pairs to investigate is of order &lt;span class=&quot;math inline&quot;&gt;\(O(n^2)\)&lt;/span&gt;, which for large &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; quickly becomes lengthy to compute. Instead, we compute an &lt;strong&gt;equi-tailed confidence interval&lt;/strong&gt; by finding two one-sided &lt;span class=&quot;math inline&quot;&gt;\(1-\alpha/2\)&lt;/span&gt; intervals, i.e. we find &lt;span class=&quot;math inline&quot;&gt;\(d\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(e\)&lt;/span&gt; s.t. &lt;span class=&quot;math inline&quot;&gt;\(P(x_{(d)} \leq x_p) = 1-\alpha/2\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(P(x_p \geq x_{(e)}) = 1-\alpha/2\)&lt;/span&gt;. In other words,&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
\begin{align*}
d &amp;amp;= \argmax P(x_{(r)} \leq x_p) \geq 1 - \frac{\alpha}{2} \\
  &amp;amp;= \texttt{qbinom(alpha/2, size=n, prob=p)} \\
e &amp;amp;= \argmin P(x_p \geq x_{(r)}) \geq 1 - \frac{\alpha}{2} \\
  &amp;amp;= \texttt{qbinom(1-alpha/2, size=n, prob=p) + 1}
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Note that the problem can arise, that the above solutions are zero or &lt;span class=&quot;math inline&quot;&gt;\(n+1\)&lt;/span&gt;, respectively. In this case one has to decide how to proceed. For an illustration of the above in case of the median see the &lt;a href=&quot;http://freakonometrics.hypotheses.org/4199&quot;&gt;post&lt;/a&gt; by &lt;a href=&quot;https://twitter.com/freakonometrics&quot;&gt;@freakonometrics&lt;/a&gt;. Also note that the &lt;code&gt;qbinom&lt;/code&gt; function uses the &lt;a href=&quot;https://en.wikipedia.org/wiki/Cornish%E2%80%93Fisher_expansion&quot;&gt;Cornish-Fisher Expansion&lt;/a&gt; to come up with an initial guess for the quantile, which is then refined by a numerical search. In other words, the function is of order &lt;span class=&quot;math inline&quot;&gt;\(O(1)\)&lt;/span&gt; and will, hence, be fast even for large &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;When it comes to confidence intervals for quantiles the set of alternative implementations in R is extensive. &lt;a href=&quot;http://finzi.psych.upenn.edu/cgi-bin/namazu.cgi?query=confidence+interval+for+quantiles&amp;amp;max=100&amp;amp;result=normal&amp;amp;sort=score&amp;amp;idxname=functions&amp;amp;idxname=vignettes&amp;amp;idxname=views&quot;&gt;Searching for this on CRAN&lt;/a&gt;, we found the following functionality:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col style=&quot;width: 24%&quot; /&gt;
&lt;col style=&quot;width: 12%&quot; /&gt;
&lt;col style=&quot;width: 63%&quot; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&quot;header&quot;&gt;
&lt;th&gt;Package::Function&lt;/th&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;Version&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;&lt;a href=&quot;http://finzi.psych.upenn.edu/R/library/MKmisc/html/quantileCI.html&quot;&gt;&lt;code&gt;MKMisc::quantileCI&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;0.993&lt;/td&gt;
&lt;td&gt;Implements an exact but very slow &lt;span class=&quot;math inline&quot;&gt;\(O(n^2)\)&lt;/span&gt; search as well as an asymptotic method approximating the exact procedure. Due to the method being slow it is not investigated further, but looking at it an &lt;code&gt;Rcpp&lt;/code&gt; implementation of the nested loop might be able to speed up the performance substantially.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;&lt;a href=&quot;http://finzi.psych.upenn.edu/R/library/jmuOutlier/html/quantileCI.html&quot;&gt;&lt;code&gt;jmuOutlier::quantileCI&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;1.1&lt;/td&gt;
&lt;td&gt;Implements the exact method.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;&lt;a href=&quot;http://finzi.psych.upenn.edu/R/library/EnvStats/html/eqnpar.html&quot;&gt;&lt;code&gt;envStats::eqnpar&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;2.1.1&lt;/td&gt;
&lt;td&gt;implements both an exact and an asymptotic interval&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;&lt;a href=&quot;http://finzi.psych.upenn.edu/R/library/asht/html/quantileTest.html&quot;&gt;&lt;code&gt;asht::quantileTest&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;0.6&lt;/td&gt;
&lt;td&gt;also implements an exact method&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;&lt;a href=&quot;http://finzi.psych.upenn.edu/R/library/Qtools/html/confint.midquantile.html&quot;&gt;&lt;code&gt;Qtools::confint.midquantile&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;1.1&lt;/td&gt;
&lt;td&gt;operates on the mid-quantile (whatever that is). The method is not investigated further.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;
&lt;p&gt;There might even be more, but for now we are satisfied comparing just the above mentioned procedures:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;as.numeric&lt;/span&gt;(MKmisc::&lt;span class=&quot;kw&quot;&gt;quantileCI&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;x=&lt;/span&gt;x, &lt;span class=&quot;dt&quot;&gt;prob=&lt;/span&gt;p, &lt;span class=&quot;dt&quot;&gt;method=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;exact&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;conf.level=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.95&lt;/span&gt;)$CI)
&lt;span class=&quot;kw&quot;&gt;as.numeric&lt;/span&gt;(MKmisc::&lt;span class=&quot;kw&quot;&gt;quantileCI&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;x=&lt;/span&gt;x, &lt;span class=&quot;dt&quot;&gt;prob=&lt;/span&gt;p, &lt;span class=&quot;dt&quot;&gt;method=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;asymptotic&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;conf.level=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.95&lt;/span&gt;)$CI)
&lt;span class=&quot;kw&quot;&gt;as.numeric&lt;/span&gt;(jmuOutlier::&lt;span class=&quot;kw&quot;&gt;quantileCI&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;x=&lt;/span&gt;x, &lt;span class=&quot;dt&quot;&gt;probs=&lt;/span&gt;p, &lt;span class=&quot;dt&quot;&gt;conf.level=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.95&lt;/span&gt;)[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;lower&amp;quot;&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;upper&amp;quot;&lt;/span&gt;)])
&lt;span class=&quot;kw&quot;&gt;as.numeric&lt;/span&gt;(EnvStats::&lt;span class=&quot;kw&quot;&gt;eqnpar&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;x=&lt;/span&gt;x, &lt;span class=&quot;dt&quot;&gt;p=&lt;/span&gt;p, &lt;span class=&quot;dt&quot;&gt;ci=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;ci.method=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;exact&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;approx.conf.level=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.95&lt;/span&gt;)$interval$limits)
&lt;span class=&quot;kw&quot;&gt;as.numeric&lt;/span&gt;(EnvStats::&lt;span class=&quot;kw&quot;&gt;eqnpar&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;x=&lt;/span&gt;x, &lt;span class=&quot;dt&quot;&gt;p=&lt;/span&gt;p, &lt;span class=&quot;dt&quot;&gt;ci=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;ci.method=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;normal.approx&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;approx.conf.level=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.95&lt;/span&gt;)$interval$limits)
&lt;span class=&quot;kw&quot;&gt;as.numeric&lt;/span&gt;(asht::&lt;span class=&quot;kw&quot;&gt;quantileTest&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;x=&lt;/span&gt;x,&lt;span class=&quot;dt&quot;&gt;p=&lt;/span&gt;p,&lt;span class=&quot;dt&quot;&gt;conf.level=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.95&lt;/span&gt;)$conf.int)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## [1] -0.03377687  1.52483138
## [1] -0.03377687  1.52483138
## [1] -0.03377687  1.52483138
## [1] 0.2212113 2.6786278
## [1] -0.03377687  1.52483138
## [1] -0.03377687  2.67862782&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An impressive number of similar, but yet, different results! To add to the confusion here is our take at this as developed in the &lt;code&gt;quantileCI&lt;/code&gt; package available from github:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;devtools::&lt;span class=&quot;kw&quot;&gt;install_github&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;hoehleatsu/quantileCI&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The package provides three methods for computing confidence intervals for quantiles:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;quantileCI::&lt;span class=&quot;kw&quot;&gt;quantile_confint_nyblom&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;x=&lt;/span&gt;x, &lt;span class=&quot;dt&quot;&gt;p=&lt;/span&gt;p, &lt;span class=&quot;dt&quot;&gt;conf.level=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.95&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;interpolate=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;FALSE&lt;/span&gt;)
quantileCI::&lt;span class=&quot;kw&quot;&gt;quantile_confint_nyblom&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;x=&lt;/span&gt;x, &lt;span class=&quot;dt&quot;&gt;p=&lt;/span&gt;p, &lt;span class=&quot;dt&quot;&gt;conf.level=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.95&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;interpolate=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;)
quantileCI::&lt;span class=&quot;kw&quot;&gt;quantile_confint_boot&lt;/span&gt;(x, &lt;span class=&quot;dt&quot;&gt;p=&lt;/span&gt;p, &lt;span class=&quot;dt&quot;&gt;conf.level=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.95&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;R=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;999&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;type=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## [1] -0.03377687  2.67862782
## [1] 0.07894831 1.54608644
## [1] -0.0376499  1.2008637&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first procedure with &lt;code&gt;interpolate=FALSE&lt;/code&gt; implements the previously explained exact approach, which is also implemented in some of the other packages. However, when the &lt;code&gt;interpolate&lt;/code&gt; argument is set to &lt;code&gt;TRUE&lt;/code&gt; (the default), an additional interpolation step between the two neighbouring order statistics is performed as suggested in the work of &lt;span class=&quot;citation&quot; data-cites=&quot;nyblom1992&quot;&gt;Nyblom (1992)&lt;/span&gt;, which extends work for the median by &lt;span class=&quot;citation&quot; data-cites=&quot;hettmansperger_sheather1986&quot;&gt;Hettmansperger and Sheather (1986)&lt;/span&gt; to arbitrary quantiles. It generates intervals of the form:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
\left( (1-\lambda_1) x_{(d)} + \lambda_1 x_{(d+1)}, (1-\lambda_2) x_{(e-1)} + \lambda_1 x_{(e)} \right)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;with &lt;span class=&quot;math inline&quot;&gt;\(0 \leq \lambda_1, \lambda_2 \leq 1\)&lt;/span&gt; chosen appropriately to get as close to the desired coverage as possible without knowing the exact underlying distribution - see the paper for details.&lt;/p&gt;
&lt;p&gt;The last call in the above is to a basic bootstrap procedure, which resamples the data with replacement, computes the quantile using &lt;code&gt;type=1&lt;/code&gt; and then reports the 2.5% and 97.5% percentiles of this bootstrapped distribution. Such percentiles of the basic bootstrap are a popular way to get confidence intervals for the quantile, e.g., this is what we have used in &lt;span class=&quot;citation&quot; data-cites=&quot;hoehle_hoehle2009&quot;&gt;Höhle and Höhle (2009)&lt;/span&gt; for reporting the 95% quantile of the absolute difference in height at so called &lt;strong&gt;check points&lt;/strong&gt; in the assessment of accuracy for a digital elevation model (DEM) in photogrammetry. However, the coverage of the percentile bootstrap procedure is not without problems, because the convergence rate as a function of the number of replicates &lt;span class=&quot;math inline&quot;&gt;\(r\)&lt;/span&gt; is only of order &lt;span class=&quot;math inline&quot;&gt;\(O(r^{-\frac{1}{2}})\)&lt;/span&gt; for quantiles (&lt;span class=&quot;citation&quot; data-cites=&quot;falk_kaufmann1991&quot;&gt;Falk and Kaufmann (1991)&lt;/span&gt;). As a trade-off between accuracy and speed we use &lt;span class=&quot;math inline&quot;&gt;\(R=999\)&lt;/span&gt; throughout this post.&lt;/p&gt;
&lt;h2 id=&quot;simulation-study-to-determine-coverage&quot;&gt;Simulation Study to Determine Coverage&lt;/h2&gt;
&lt;p&gt;We write a function, which for a given sample &lt;code&gt;x&lt;/code&gt; computes two-sided confidence intervals for the p-Quantile using a selection of the above described procedures:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;quantile_confints&lt;/span&gt;(x, &lt;span class=&quot;dt&quot;&gt;p=&lt;/span&gt;p, &lt;span class=&quot;dt&quot;&gt;conf.level=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.95&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##   jmuOutlier_exact EnvStats_exact EnvStats_asymp asht_quantTest nyblom_exact
## 1      -0.03377687      0.2212113    -0.03377687    -0.03377687  -0.03377687
## 2       1.52483138      2.6786278     1.52483138     2.67862782   2.67862782
##   nyblom_interp        boot
## 1    0.07894831 -0.03377687
## 2    1.54608644  1.26565726&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In order to evaluate the various methods and implementations we conduct a Monte Carlo simulation study to assess each methods&#39; coverage. For this purpose we write a small wrapper function to conduct the simulation study using &lt;a href=&quot;http://gforge.se/2015/02/how-to-go-parallel-in-r-basics-tips/&quot;&gt;parallel computation&lt;/a&gt;. The function wraps the &lt;code&gt;quantileCI::qci_coverage_one_sim&lt;/code&gt; function, which lets the user define a simulation scenario (true underlying distribution, size of the sample, etc.), then applies all confidence interval methods gathered in the above &lt;code&gt;quantile_confints&lt;/code&gt; and finally assesses whether each confidence interval covers the true value or not.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;simulate.coverage_qci &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;n,&lt;span class=&quot;dt&quot;&gt;p=&lt;/span&gt;p,&lt;span class=&quot;dt&quot;&gt;conf.level=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.9&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;nSim=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;10e3&lt;/span&gt;, ...) {
  ##Windows users: change to below lapply function or use snow.
  ##lapplyFun &amp;lt;- function(x, mc.cores=NA, ...) pblapply(x, ...)
  lapplyFun &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;parallel::mclapply

  sims &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;dplyr::&lt;span class=&quot;kw&quot;&gt;bind_rows&lt;/span&gt;(
    &lt;span class=&quot;kw&quot;&gt;lapplyFun&lt;/span&gt;(1L:nSim, function(i) {
      quantileCI::&lt;span class=&quot;kw&quot;&gt;qci_coverage_one_sim&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;qci_fun=&lt;/span&gt;quantile_confints, &lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;n,&lt;span class=&quot;dt&quot;&gt;p=&lt;/span&gt;p,&lt;span class=&quot;dt&quot;&gt;conf.level=&lt;/span&gt;conf.level,...)
    }, &lt;span class=&quot;dt&quot;&gt;mc.cores =&lt;/span&gt; parallel::&lt;span class=&quot;kw&quot;&gt;detectCores&lt;/span&gt;() -&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)
  ) %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;summarise_each&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;funs&lt;/span&gt;(mean))
  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt;(sims)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id=&quot;simulation-1&quot;&gt;Simulation 1&lt;/h4&gt;
&lt;p&gt;We can now compare the coverage of the different implementation for the particular &lt;code&gt;n&lt;/code&gt;=25 and &lt;code&gt;p&lt;/code&gt;=0.8 setting:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;simulate.coverage_qci&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;25&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;p=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.8&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;conf.level=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.95&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##   jmuOutlier_exact EnvStats_exact EnvStats_asymp asht_quantTest nyblom_exact
## 1           0.9536         0.9473         0.9536         0.9786       0.9786
##   nyblom_interp   boot
## 1        0.9464 0.9154&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that the &lt;code&gt;nyblom_interp&lt;/code&gt; procedure is closer to the nominal coverage than it&#39;s exact cousin &lt;code&gt;nyblom_exact&lt;/code&gt; and the worst results are obtained by the bootstrap percentile method. We also note that the results of the &lt;code&gt;jmuOutlier_exact&lt;/code&gt; method appear to deviate from &lt;code&gt;asht_quantTest&lt;/code&gt; as well as &lt;code&gt;nyblom_exact&lt;/code&gt;, which is surprising, because they should implement the same approach.&lt;/p&gt;
&lt;h4 id=&quot;simulation-2&quot;&gt;Simulation 2&lt;/h4&gt;
&lt;p&gt;As a further test-case we consider the situation for the median in a smaller sample:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;simulate.coverage_qci&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;11&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;p=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.5&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;conf.level=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.95&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##   jmuOutlier_exact EnvStats_exact EnvStats_asymp asht_quantTest nyblom_exact
## 1           0.9873         0.9352          0.961         0.9873       0.9873
##   nyblom_interp   boot hs_interp
## 1        0.9462 0.9352    0.9462&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We note that the &lt;code&gt;EnvStats_exact&lt;/code&gt; procedure again has a lower coverage than the nominal required level, it must therefore implement a slightly different procedure than expected. That coverage is less than the nominal for an &lt;em&gt;exact&lt;/em&gt; method is, however, still somewhat &lt;em&gt;surprising&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;In this study for the median, the original &lt;span class=&quot;citation&quot; data-cites=&quot;hettmansperger_sheather1986&quot;&gt;Hettmansperger and Sheather (1986)&lt;/span&gt; procedure implemented in &lt;code&gt;quantileCI&lt;/code&gt; as function &lt;code&gt;median_confint_hs&lt;/code&gt; is also included in the comparison (&lt;code&gt;hs_interp&lt;/code&gt;). Note that the &lt;span class=&quot;citation&quot; data-cites=&quot;nyblom1992&quot;&gt;Nyblom (1992)&lt;/span&gt; procedure for &lt;span class=&quot;math inline&quot;&gt;\(p=\frac{1}{2}\)&lt;/span&gt; just boils down to this approach. Since the neighbouring order statistics are combined using a weighted mean, the actual level is just close to the nominal level. It can, as observed for the above setting, be slightly lower than the nominal level. The bootstrap method again doesn&#39;t look too impressive.&lt;/p&gt;
&lt;h4 id=&quot;simulation-3&quot;&gt;Simulation 3&lt;/h4&gt;
&lt;p&gt;We finally also add one of the scenarios from Table 1 of the &lt;span class=&quot;citation&quot; data-cites=&quot;nyblom1992&quot;&gt;Nyblom (1992)&lt;/span&gt; paper, which allows us to check our implementation against the numerical integration performed in the paper to assess coverage.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;simulate.coverage_qci&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;11&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;p=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.25&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;conf.level=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.90&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##   jmuOutlier_exact EnvStats_exact EnvStats_asymp asht_quantTest nyblom_exact
## 1           0.9249         0.7722         0.8472         0.9249       0.9249
##   nyblom_interp   boot
## 1        0.9033 0.8848&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In particular the results of &lt;code&gt;EnvStats_exact&lt;/code&gt; look disturbing. The coverage of the interpolated order statistic approach again looks convincing.&lt;/p&gt;
&lt;h4 id=&quot;simulation-4&quot;&gt;Simulation 4&lt;/h4&gt;
&lt;p&gt;Finally, a setup with a large sample, but now with the t-distribution with one degree of freedom:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;simulate.coverage_qci&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;101&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;p=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.9&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;rfunc=&lt;/span&gt;rt, &lt;span class=&quot;dt&quot;&gt;qfunc=&lt;/span&gt;qt, &lt;span class=&quot;dt&quot;&gt;conf.level=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.95&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;df=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##   jmuOutlier_exact EnvStats_exact EnvStats_asymp asht_quantTest nyblom_exact
## 1           0.9553         0.9343         0.9553         0.9553       0.9553
##   nyblom_interp   boot
## 1        0.9502 0.9306&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again the interpolation method provides the most convincing results. The bootstrap on the other hand again has the worst coverage, a larger &lt;span class=&quot;math inline&quot;&gt;\(R\)&lt;/span&gt; might have helped here, but would have made the simulation study even more time consuming.&lt;/p&gt;
&lt;h1 id=&quot;conclusion-and-future-work&quot;&gt;Conclusion and Future Work&lt;/h1&gt;
&lt;p&gt;Can we based on the above recommend one procedure to use in practice? Well, even though the simulation study is small, the exact &lt;code&gt;EnvStats::eqnpar&lt;/code&gt; approach appears to yield below nominal coverage intervals, sometimes even substantially, and hence is not to be recommended. On the other hand, &lt;code&gt;jmuOutlier_exact&lt;/code&gt;, &lt;code&gt;asht_quantTest&lt;/code&gt;, and &lt;code&gt;nyblom_exact&lt;/code&gt; in all four cases provide above nominal level coverage, i.e. the intervals are conservative in as much as they are too wide. Also slightly disturbing is that the results of the exact confidence interval methods varied somewhat between the different R implementations. Part of the differences arise from handling the discreteness of the procedure as well as the edge cases differently. The basic percentile bootstrap method is a simple approach, providing acceptable, but not optimal coverage and also depends in part on &lt;span class=&quot;math inline&quot;&gt;\(R\)&lt;/span&gt;. In particular for very large &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; or for a large number of replication in the simulation study, the method with a large &lt;span class=&quot;math inline&quot;&gt;\(R\)&lt;/span&gt; can be slow. Suggestions exist in the literature on how to improve the speed of coverage convergence by smoothing (see, e.g., &lt;span class=&quot;citation&quot; data-cites=&quot;deangelis_etal1993&quot;&gt;De Angelis, Hall, and Young (1993)&lt;/span&gt;), but such work is beyond the scope of this post.&lt;/p&gt;
&lt;p&gt;The &lt;span class=&quot;citation&quot; data-cites=&quot;hettmansperger_sheather1986&quot;&gt;Hettmansperger and Sheather (1986)&lt;/span&gt; and &lt;span class=&quot;citation&quot; data-cites=&quot;nyblom1992&quot;&gt;Nyblom (1992)&lt;/span&gt; method, respectively, provide very good coverage close to the nominal level. The method is fast to compute, available through the &lt;code&gt;quantileCI&lt;/code&gt; R package and would be our recommendation to use in practice.&lt;/p&gt;
&lt;p&gt;Altogether, we summarise our findings as follows: &lt;strong&gt;More confidence in confidence intervals for quantiles!&lt;/strong&gt; and let the following picture illustrating 90% confidence intervals for the 80% quantile of the standard normal distribution based on the above sample of size &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt;=25 say this in less than 1000 words.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-10-23-quantileCI/FIRSTPICTURE-1.png&quot; style=&quot;display: block; margin: auto;&quot; /&gt;&lt;/p&gt;
&lt;h1 id=&quot;appendix&quot;&gt;Appendix&lt;/h1&gt;
&lt;p&gt;Given PDF &lt;span class=&quot;math inline&quot;&gt;\(f\)&lt;/span&gt; and CDF &lt;span class=&quot;math inline&quot;&gt;\(F\)&lt;/span&gt; of the underlying distribution, the coverage probability of the one sided Nyblom &lt;span class=&quot;math inline&quot;&gt;\((1-\alpha/2)\cdot 100\%\)&lt;/span&gt; confidence interval &lt;span class=&quot;math inline&quot;&gt;\((1-\lambda) x_{(r)} + \lambda x_{(r+1)}\)&lt;/span&gt; for &lt;span class=&quot;math inline&quot;&gt;\(x_p\)&lt;/span&gt; can be found as follows: Let &lt;span class=&quot;math inline&quot;&gt;\(z = (1-\lambda) x_{(r)} + \lambda x_{(r+1)}\)&lt;/span&gt;. If the considered interval is a lower-confidence interval, we are interested in finding &lt;span class=&quot;math inline&quot;&gt;\(P( z \leq x_p)=\int_{-\infty}^{x_p} f_z(z) dz\)&lt;/span&gt;. Here, the PDF of &lt;span class=&quot;math inline&quot;&gt;\(z\)&lt;/span&gt; is found as&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
f_z(z) = \int_{-\infty}^{z} f_{x_{(r)},x_{(r+1)}}( x_{(r)},
x_{(r+1)}^*) dx_{(r)}, \quad\text{where}\quad x_{(r+1)}^* = \frac{z-(1-\lambda)x_{(r)}}{\lambda}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The &lt;a href=&quot;https://en.wikipedia.org/wiki/Order_statistic#The_joint_distribution_of_the_order_statistics_of_an_absolutely_continuous_distribution&quot;&gt;joint distribution of the order statistic&lt;/a&gt; is here&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
f_{x_{(r)},x_{(r+1)}}( x_{(r)},
x_{(r+1)}) = \frac{n!}{(r-1)!(n-r-1)!} F(x_{(r)})^{r-1}
\left( 1- F(x_{(r+1)})\right)^{n-r-1} f(x_{(r+1)}) f(x_{(r)}).
\]&lt;/span&gt; The two nested integrals can be solved by numerical integration using, e.g., the &lt;code&gt;integral&lt;/code&gt; function.&lt;/p&gt;
&lt;h1 id=&quot;references&quot; class=&quot;unnumbered&quot;&gt;References&lt;/h1&gt;
&lt;div id=&quot;refs&quot; class=&quot;references&quot;&gt;
&lt;div id=&quot;ref-deangelis_etal1993&quot;&gt;
&lt;p&gt;De Angelis, D., P. Hall, and G. A. Young. 1993. “A Note on Coverage Error of Bootstrap Confidence Intervals for Quantiles.” &lt;em&gt;Mathematical Proceedings of the Cambridge Philosophical Society&lt;/em&gt; 114: 517–31. &lt;a href=&quot;http://sci-prew.inf.ua/v114/3/S0305004100071802.pdf&quot; class=&quot;uri&quot;&gt;http://sci-prew.inf.ua/v114/3/S0305004100071802.pdf&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-falk_kaufmann1991&quot;&gt;
&lt;p&gt;Falk, Michael, and Edgar Kaufmann. 1991. “Coverage Probabilities of Bootstrap-Confidence Intervals for Quantiles.” &lt;em&gt;Ann. Statist.&lt;/em&gt; 19 (1). The Institute of Mathematical Statistics: 485–95. doi:&lt;a href=&quot;https://doi.org/10.1214/aos/1176347995&quot;&gt;10.1214/aos/1176347995&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-hettmansperger_sheather1986&quot;&gt;
&lt;p&gt;Hettmansperger, T. P., and S. J Sheather. 1986. “Confidence Intervals Based on Interpolated Order Statistics.” &lt;em&gt;Statistics and Probability Letters&lt;/em&gt; 4: 75–79. doi:&lt;a href=&quot;https://doi.org/10.1016/0167-7152(86)90021-0&quot;&gt;10.1016/0167-7152(86)90021-0&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-hoehle_hoehle2009&quot;&gt;
&lt;p&gt;Höhle, J., and M. Höhle. 2009. “Accuracy Assessment of Digital Elevation Models by Means of Robust Statistical Methods.” &lt;em&gt;ISPRS Journal of Photogrammetry and Remote Sensing&lt;/em&gt; 64 (4): 398–406. doi:&lt;a href=&quot;https://doi.org/10.1016/j.isprsjprs.2009.02.003&quot;&gt;10.1016/j.isprsjprs.2009.02.003&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-hyndman_fan1996&quot;&gt;
&lt;p&gt;Hyndman, R. J., and Y. Fan. 1996. “Sample Quantiles in Statistical Packages.” &lt;em&gt;American Statistician&lt;/em&gt; 50 (4): 361–65. doi:&lt;a href=&quot;https://doi.org/10.2307/2684934&quot;&gt;10.2307/2684934&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-nyblom1992&quot;&gt;
&lt;p&gt;Nyblom, J. 1992. “Note on Interpolated Order Statistics.” &lt;em&gt;Statistics and Probability Letters&lt;/em&gt; 14: 129–31. &lt;a href=&quot;10.1016/0167-7152(92)90076-H&quot; class=&quot;uri&quot;&gt;10.1016/0167-7152(92)90076-H&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
        <pubDate>Sun, 23 Oct 2016 00:00:00 +0200</pubDate>
        <link>http://staff.math.su.se/hoehle/blog/2016/10/23/quantileCI.html</link>
        <guid isPermaLink="true">http://staff.math.su.se/hoehle/blog/2016/10/23/quantileCI.html</guid>
        
        <category>rstats</category>
        
        <category>stats</category>
        
        <category>nonparametrics</category>
        
        
      </item>
    
      <item>
        <title>Cartograms with R</title>
        <description>&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;We show how to create &lt;a href=&quot;https://en.wikipedia.org/wiki/Cartogram&quot;&gt;cartograms&lt;/a&gt; with R by illustrating the population and age-distribution of the planning regions of Berlin by static plots and animations.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-10-10-cartograms/CARTOGRAM-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br&gt; &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width:0&quot; src=&quot;https://i.creativecommons.org/l/by-sa/4.0/88x31.png&quot;/&gt;&lt;/a&gt; This work is licensed under a &lt;a rel=&quot;license&quot;
href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt;. The markdown+Rknitr source code of this blog is available under a &lt;a href=&quot;https://www.gnu.org/licenses/gpl-3.0.html&quot;&gt;GNU General Public License (GPL v3)&lt;/a&gt; license from &lt;a href=&quot;https://github.com/hoehleatsu/hoehleatsu.github.io&quot;&gt;&lt;img src=&quot;/hoehle/blog/images/GitHub-Mark-32px.png&quot; alt=&quot;github&quot; /&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Every good lecture on sophisticated statistical modelling starts with underlining the importance of &lt;strong&gt;data visualization&lt;/strong&gt; as the first step of an analysis. &lt;a href=&quot;https://en.wikipedia.org/wiki/Choropleth_map&quot;&gt;Choropleth maps&lt;/a&gt; are a common choice for visualizing the spatial distribution of a feature recorded in administrative regions, e.g., population density or the incidence rate of a disease. Here, each region is shaded with a color selected in accordance with the feature variable, e.g., higher hue if the feature value is higher. Choosing the right palette for such visualizations is a science of its own, see e.g. &lt;span class=&quot;citation&quot; data-cites=&quot;zeileis_etal2009&quot;&gt;Zeileis, Hornik, and Murrell (2009)&lt;/span&gt; or the &lt;a href=&quot;http://colorbrewer2.org/&quot;&gt;ColorBrewer&lt;/a&gt; project, which is available in R through the &lt;a href=&quot;https://cran.r-project.org/web/packages/RColorBrewer/index.html&quot;&gt;&lt;code&gt;RColorBrewer&lt;/code&gt;&lt;/a&gt; package. A nice way to further spice up your spatial visualizations are &lt;strong&gt;area cartograms&lt;/strong&gt;, where the boundary shape of each region is warped such that its area becomes proportional to the value of the feature variable you want to illustrate. The difficult part here is to preserve the arrangement of the regions, see for example &lt;span class=&quot;citation&quot; data-cites=&quot;gastner_newman2004&quot;&gt;Gastner and Newman (2004)&lt;/span&gt; for the methodological challenges of this task.&lt;/p&gt;
&lt;p&gt;In this post we show how such area cartograms can easily be created with R using the packages &lt;code&gt;Rcartogram&lt;/code&gt; and &lt;code&gt;getcartr&lt;/code&gt; together with the powerful packages &lt;code&gt;sp&lt;/code&gt;, &lt;code&gt;rgeos&lt;/code&gt; and &lt;code&gt;rgdal&lt;/code&gt; for the spatial data wrangling. Both &lt;code&gt;Rcartogram&lt;/code&gt; and &lt;code&gt;getcartr&lt;/code&gt; are only available from github, because the license of the underlying &lt;a href=&quot;http://www-personal.umich.edu/~mejn/cart/&quot;&gt;&lt;code&gt;Cart&lt;/code&gt;&lt;/a&gt; C fragment implementing the method of &lt;span class=&quot;citation&quot; data-cites=&quot;gastner_newman2004&quot;&gt;Gastner and Newman (2004)&lt;/span&gt; does not appear to be GPL (or the like) compatible.&lt;/p&gt;
&lt;h1 id=&quot;the-data&quot;&gt;The Data&lt;/h1&gt;
&lt;p&gt;We use population numbers for the 447 planning regions of Berlin (Lebensweltlich orientierte Räume (LOR)). The boundaries of these regions are available as ESRI Shapefile through the &lt;a href=&quot;http://daten.berlin.de/datensaetze/rbs-lor-lebensweltlich-orientierte-r%C3%A4ume-dezember-2015&quot;&gt;open data portal of Berlin&lt;/a&gt; under the CC BY license. The 2015 population data of the LORs are available as CSV file through the same &lt;a href=&quot;http://daten.berlin.de/datensaetze/einwohnerinnen-und-einwohner-berlin-lor-planungsr%C3%A4umen-am-31122015&quot;&gt;data portal&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;tmpfile &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;paste0&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;tempfile&lt;/span&gt;(),&lt;span class=&quot;st&quot;&gt;&amp;quot;.zip&amp;quot;&lt;/span&gt;)
&lt;span class=&quot;kw&quot;&gt;download.file&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;https://www.statistik-berlin-brandenburg.de/opendata/RBS_OD_LOR_2015_12.zip&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;destfile=&lt;/span&gt;tmpfile)
&lt;span class=&quot;kw&quot;&gt;unzip&lt;/span&gt;(tmpfile,&lt;span class=&quot;dt&quot;&gt;exdir=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;file.path&lt;/span&gt;(filePath,&lt;span class=&quot;st&quot;&gt;&amp;quot;RBS_OD_LOR_2015_12&amp;quot;&lt;/span&gt;))
&lt;span class=&quot;kw&quot;&gt;download.file&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;https://www.statistik-berlin-brandenburg.de/opendata/EWR201512E_Matrix.csv&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;destfile=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;file.path&lt;/span&gt;(filePath,&lt;span class=&quot;st&quot;&gt;&amp;quot;EWR201512E_Matrix.csv&amp;quot;&lt;/span&gt;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;With the help of the &lt;code&gt;rgdal&lt;/code&gt;, &lt;code&gt;sp&lt;/code&gt; and the &lt;code&gt;rgeos&lt;/code&gt; CRAN packages, R can be used as a &lt;a href=&quot;https://en.wikipedia.org/wiki/Geographic_information_system&quot;&gt;geographic information system (GIS)&lt;/a&gt;. This allows for easy merging of these two data sources together with a spatial aggregation to the &lt;strong&gt;Prognoseräume&lt;/strong&gt; level, which is a slightly higher level of aggregation than the LORs (60 regions instead of 447). The output of these data wrangling steps will be a SpatialPolygonsDataFrame object &lt;code&gt;pgrs&lt;/code&gt; - see GitHub code for details.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;library&lt;/span&gt;(rgdal)
&lt;span class=&quot;kw&quot;&gt;library&lt;/span&gt;(sp)
&lt;span class=&quot;kw&quot;&gt;library&lt;/span&gt;(rgeos)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Read shapefile
lor &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;readOGR&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;dsn=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;file.path&lt;/span&gt;(filePath,&lt;span class=&quot;st&quot;&gt;&amp;quot;RBS_OD_LOR_2015_12&amp;quot;&lt;/span&gt;),&lt;span class=&quot;dt&quot;&gt;layer=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;RBS_OD_LOR_2015_12&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## OGR data source with driver: ESRI Shapefile 
## Source: &amp;quot;/Users/hoehle/Sandbox/Blog/figure/source/2016-10-10-cartograms//RBS_OD_LOR_2015_12&amp;quot;, layer: &amp;quot;RBS_OD_LOR_2015_12&amp;quot;
## with 447 features
## It has 8 fields&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;proj4string&lt;/span&gt;(lor)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;+proj=utm +zone=33 +ellps=GRS80 +units=m +no_defs&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Compute area of each LOR in km^2 area (unit: meters -&amp;gt; convert to square km)
lor$area &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;gArea&lt;/span&gt;(lor, &lt;span class=&quot;dt&quot;&gt;byid=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;) /&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;(&lt;span class=&quot;fl&quot;&gt;1e6&lt;/span&gt;)

##Read population
pop &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;readr::&lt;span class=&quot;kw&quot;&gt;read_csv2&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;file=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;file.path&lt;/span&gt;(filePath, &lt;span class=&quot;st&quot;&gt;&amp;quot;EWR201512E_Matrix.csv&amp;quot;&lt;/span&gt;))

##Merge SpatialPolygonsDataFrame with population information
lor_pop &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;merge&lt;/span&gt;(lor, pop, &lt;span class=&quot;dt&quot;&gt;by.x=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;PLR&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;by.y=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;RAUMID&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Plotting the result of the &lt;code&gt;pgrs&lt;/code&gt; object as an instance of &lt;code&gt;SpatialPolygonsDataFrame&lt;/code&gt; can be done using the standard &lt;code&gt;Spatial*&lt;/code&gt; plotting routines documented extensively in, e.g, &lt;span class=&quot;citation&quot; data-cites=&quot;bivand_etal2008&quot;&gt;Bivand, Pebesma, and Gómez-Rubio (2008)&lt;/span&gt; and its comprehensive &lt;a href=&quot;http://www.asdar-book.org/&quot;&gt;webpage&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;######################################################################
## Plotting the result, see nice tutorial by
## http://www.nickeubank.com/wp-content/uploads/2015/10/RGIS3_MakingMaps_part1_mappingVectorData.html
## or the Bivand et al. (2008) book - a must read!
## Note: there is a 2nd edition available nowadays.
######################################################################

&lt;span class=&quot;kw&quot;&gt;library&lt;/span&gt;(RColorBrewer)
my.palette &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;brewer.pal&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n =&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;6&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;name =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;Purples&amp;quot;&lt;/span&gt;)
##Helper function for making labels for each entry
sp.label &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(x, label) {&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;sp.text&amp;quot;&lt;/span&gt;, &lt;span class=&quot;kw&quot;&gt;coordinates&lt;/span&gt;(x), label,&lt;span class=&quot;dt&quot;&gt;cex=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.5&lt;/span&gt;)}
borderCol &amp;lt;-&lt;span class=&quot;st&quot;&gt; &amp;quot;white&amp;quot;&lt;/span&gt;

&lt;span class=&quot;co&quot;&gt;#Plot choropleth map&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;spplot&lt;/span&gt;(pgrs, &lt;span class=&quot;st&quot;&gt;&amp;quot;density&amp;quot;&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;col.regions =&lt;/span&gt; my.palette, &lt;span class=&quot;dt&quot;&gt;cuts =&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;length&lt;/span&gt;(my.palette)-&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;col =&lt;/span&gt; borderCol,&lt;span class=&quot;dt&quot;&gt;main=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;Choropleth map of Population Density&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;sp.layout=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;sp.label&lt;/span&gt;(pgrs, pgrs$EXTPGRNAME))
&lt;span class=&quot;kw&quot;&gt;require&lt;/span&gt;(grid)
&lt;span class=&quot;kw&quot;&gt;grid.text&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;expression&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;Population density (Persons / &amp;quot;&lt;/span&gt;~km^&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;~&lt;span class=&quot;st&quot;&gt;&amp;quot;)&amp;quot;&lt;/span&gt;), &lt;span class=&quot;dt&quot;&gt;x=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;unit&lt;/span&gt;(&lt;span class=&quot;fl&quot;&gt;0.95&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;&amp;quot;npc&amp;quot;&lt;/span&gt;), &lt;span class=&quot;dt&quot;&gt;y=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;unit&lt;/span&gt;(&lt;span class=&quot;fl&quot;&gt;0.50&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;&amp;quot;npc&amp;quot;&lt;/span&gt;), &lt;span class=&quot;dt&quot;&gt;rot=&lt;/span&gt;-&lt;span class=&quot;dv&quot;&gt;90&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-10-10-cartograms/CHOROPLETH-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;h2 id=&quot;installing-the-cartogram-r-packages&quot;&gt;Installing the Cartogram R packages&lt;/h2&gt;
&lt;p&gt;Two packages &lt;code&gt;Rcartogram&lt;/code&gt; and &lt;code&gt;getcartr&lt;/code&gt; make the functionality of the &lt;span class=&quot;citation&quot; data-cites=&quot;gastner_newman2004&quot;&gt;Gastner and Newman (2004)&lt;/span&gt; procedure available for working with objects of class &lt;code&gt;Spatial*&lt;/code&gt;. Installing &lt;code&gt;Rcartogram&lt;/code&gt; requires the &lt;a href=&quot;http://www.fftw.org/&quot;&gt;&lt;code&gt;fftw&lt;/code&gt; library&lt;/a&gt; to be installed. How to best do that depends on your system, for Mac OS X the &lt;a href=&quot;http://brew.sh/&quot;&gt;homebrew package system&lt;/a&gt; makes this installation easy.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##On command line in OS/X with homebrew. Wrapped in FALSE statement to not run system() unintentionally
if (&lt;span class=&quot;ot&quot;&gt;FALSE&lt;/span&gt;) {
  &lt;span class=&quot;kw&quot;&gt;system&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;brew install fftw&amp;quot;&lt;/span&gt;)
}
##Install the R implementation of Cart by Gastner and Newman (2004)
devtools::&lt;span class=&quot;kw&quot;&gt;install_github&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;omegahat/Rcartogram&amp;quot;&lt;/span&gt;)
devtools::&lt;span class=&quot;kw&quot;&gt;install_github&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;#39;chrisbrunsdon/getcartr&amp;#39;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;subdir=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;#39;getcartr&amp;#39;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We are now ready to compute our first cartogram using the &lt;code&gt;getcartr::quick.carto&lt;/code&gt; function.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;library&lt;/span&gt;(Rcartogram)
&lt;span class=&quot;kw&quot;&gt;library&lt;/span&gt;(getcartr)

##Make a cartogram
pgrs_carto &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;quick.carto&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;spdf=&lt;/span&gt;pgrs,&lt;span class=&quot;dt&quot;&gt;v=&lt;/span&gt;pgrs$E_E,&lt;span class=&quot;dt&quot;&gt;res=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;256&lt;/span&gt;)

##Display it using sp functionality
&lt;span class=&quot;kw&quot;&gt;spplot&lt;/span&gt;(pgrs_carto, &lt;span class=&quot;st&quot;&gt;&amp;quot;area&amp;quot;&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;col.regions =&lt;/span&gt; my.palette, &lt;span class=&quot;dt&quot;&gt;cuts =&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;length&lt;/span&gt;(my.palette)-&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;col =&lt;/span&gt; borderCol,&lt;span class=&quot;dt&quot;&gt;main=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;Population Cartogram as Choropleth of Area&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;sp.layout=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;sp.label&lt;/span&gt;(pgrs_carto, &lt;span class=&quot;dt&quot;&gt;label=&lt;/span&gt;pgrs_carto$EXTPGRNAME))
grid::&lt;span class=&quot;kw&quot;&gt;grid.text&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;expression&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;Area (km&amp;quot;&lt;/span&gt;^&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;*&lt;span class=&quot;st&quot;&gt;&amp;quot;)&amp;quot;&lt;/span&gt;), &lt;span class=&quot;dt&quot;&gt;x=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;unit&lt;/span&gt;(&lt;span class=&quot;fl&quot;&gt;0.95&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;&amp;quot;npc&amp;quot;&lt;/span&gt;), &lt;span class=&quot;dt&quot;&gt;y=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;unit&lt;/span&gt;(&lt;span class=&quot;fl&quot;&gt;0.50&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;&amp;quot;npc&amp;quot;&lt;/span&gt;), &lt;span class=&quot;dt&quot;&gt;rot=&lt;/span&gt;-&lt;span class=&quot;dv&quot;&gt;90&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-10-10-cartograms/CARTOGRAM-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;With the cartogram functionality now being directly available through R allows one to embedd cartogram making in a full R pipeline. We illustrate this by generating a sequence of cartograms into an animated GIF file using the &lt;code&gt;animation&lt;/code&gt; package. The animation below shows a cartogram for the population size for each of the 32 age groups in the Berlin data set. One observes that the 25-45 year old tend to live in the city centre, while the 95-110 year old seem to concentrate in the wealthy regions in the south west.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-10-10-cartograms/pop-cartograms.gif&quot; /&gt;
&lt;/figure&gt;
&lt;h1 id=&quot;outlook&quot;&gt;Outlook&lt;/h1&gt;
&lt;p&gt;While writing this posts some other useRs have posted on how to create &lt;a href=&quot;https://twitter.com/Victpir/status/785852075129315333&quot;&gt;interactive cartograms&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&quot;references&quot; class=&quot;unnumbered&quot;&gt;References&lt;/h1&gt;
&lt;div id=&quot;refs&quot; class=&quot;references&quot;&gt;
&lt;div id=&quot;ref-bivand_etal2008&quot;&gt;
&lt;p&gt;Bivand, R. S., E. J. Pebesma, and V. Gómez-Rubio. 2008. &lt;em&gt;Applied Spatial Data Analysis with R&lt;/em&gt;. Springer-Verlag.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-gastner_newman2004&quot;&gt;
&lt;p&gt;Gastner, Michael T., and M. E. J. Newman. 2004. “Diffusion-Based Method for Producing Density-Equalizing Maps.” &lt;em&gt;Proceedings of the National Academy of Sciences of the United States of America&lt;/em&gt; 101 (20): 7499–7504. doi:&lt;a href=&quot;https://doi.org/10.1073/pnas.0400280101&quot;&gt;10.1073/pnas.0400280101&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-zeileis_etal2009&quot;&gt;
&lt;p&gt;Zeileis, Achim, Kurt Hornik, and Paul Murrell. 2009. “Escaping RGBland: Selecting Colors for Statistical Graphics.” &lt;em&gt;Computational Statistics &amp;amp; Data Analysis&lt;/em&gt; 53 (9): 3259–70. doi:&lt;a href=&quot;https://doi.org/http://dx.doi.org/10.1016/j.csda.2008.11.033&quot;&gt;http://dx.doi.org/10.1016/j.csda.2008.11.033&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
        <pubDate>Mon, 10 Oct 2016 00:00:00 +0200</pubDate>
        <link>http://staff.math.su.se/hoehle/blog/2016/10/10/cartograms.html</link>
        <guid isPermaLink="true">http://staff.math.su.se/hoehle/blog/2016/10/10/cartograms.html</guid>
        
        <category>dataviz</category>
        
        <category>rstats</category>
        
        <category>spatial</category>
        
        <category>GIS</category>
        
        
      </item>
    
      <item>
        <title>Surveillance Out of the Box - The #Zombie Experiment</title>
        <description>&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;We perform a social experiment to investigate, if zombie related twitter posts can be used as a reliable indicator for an early warning system. We show how such a system can be set up almost out-of-the-box using R - a free software environment for statistical computing and graphics. &lt;strong&gt;Warning&lt;/strong&gt;: This blog entry contains toxic doses of Danish irony and sarcasm as well as disturbing graphs. &lt;strong&gt;Update&lt;/strong&gt;: The blog post was extended with additional data, graphs and text at 2016-11-03 00:08:27. Scroll to the end of the post for details.&lt;/p&gt;
&lt;p&gt;&lt;br&gt; &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width:0&quot; src=&quot;https://i.creativecommons.org/l/by-sa/4.0/88x31.png&quot;/&gt;&lt;/a&gt; This work is licensed under a &lt;a rel=&quot;license&quot;
href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt;. The markdown+Rknitr source code of this blog is available under a &lt;a href=&quot;https://www.gnu.org/licenses/gpl-3.0.html&quot;&gt;GNU General Public License (GPL v3)&lt;/a&gt; license from &lt;a href=&quot;https://github.com/hoehleatsu/hoehleatsu.github.io&quot;&gt;&lt;img src=&quot;/hoehle/blog/images/GitHub-Mark-32px.png&quot; alt=&quot;github&quot; /&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Proposing statistical methods is only mediocre fun if nobody applies them. As an act of desperation the prudent statistician has been forced to provide R packages supplemented with a CRAN, github, useR! or word-of-mouth advertising strategy. To underpin efforts, a reproducibility-crisis has been announced in order to scare decent comma-separated scientists &lt;a href=&quot;https://www.washingtonpost.com/news/wonk/wp/2016/08/26/an-alarming-number-of-scientific-papers-contain-excel-errors/&quot;&gt;from using Excel&lt;/a&gt;. Social media marketing strategies of your R package include hashtag &lt;code&gt;#rstats&lt;/code&gt; twitter announcements, possibly enhanced by a picture or animation showing your package at its best:&lt;/p&gt;
&lt;center&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;
Introducing gganimate: &lt;a href=&quot;https://twitter.com/hashtag/rstats?src=hash&quot;&gt;#rstats&lt;/a&gt; package for adding animation to any ggplot2 figure &lt;a href=&quot;https://t.co/UBWKHmIc0e&quot;&gt;https://t.co/UBWKHmIc0e&lt;/a&gt; &lt;a href=&quot;https://t.co/oQhQaYBqOj&quot;&gt;pic.twitter.com/oQhQaYBqOj&lt;/a&gt;
&lt;/p&gt;
— David Robinson (@drob) &lt;a href=&quot;https://twitter.com/drob/status/694274942813102080&quot;&gt;February 1, 2016&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/center&gt;
&lt;p&gt;
&lt;p&gt;Unfortunately, little experience with the interactive aspect of this statistical software marketing strategy appears to be available. In order to fill this scientific advertising gap, this blog post constitutes an advertisement for the &lt;strong&gt;out-of-the-box-functionality&lt;/strong&gt; of the &lt;code&gt;surveillance&lt;/code&gt; package hidden as social experiment. It shows shows what you can do with R when combining a couple of packages, wrangle the data, cleverly visualize the results and then team up with the fantastic R community.&lt;/p&gt;
&lt;h2 id=&quot;the-setup-detecting-a-zombie-attack&quot;&gt;The Setup: Detecting a Zombie Attack&lt;/h2&gt;
&lt;p&gt;As previously explained in an &lt;a href=&quot;http://user2015.math.aau.dk/lightning_talks&quot;&gt;useR! 2015 lightning talk&lt;/a&gt;, Max Brooks&#39; &lt;a href=&quot;https://en.wikipedia.org/wiki/The_Zombie_Survival_Guide&quot;&gt;Zombie Survival Guide&lt;/a&gt; is very concerned about the &lt;strong&gt;early warning&lt;/strong&gt; of Zombie outbreaks.&lt;/p&gt;
&lt;center&gt;
&lt;a href=&quot;http://staff.math.su.se/hoehle/software/surveillance/hoehle-userR2015-web.pdf&quot;&gt;&lt;img src=&quot;/hoehle/blog/figure/source/2016-09-25-sootb/zombiepreparedness.png&quot;&gt;&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;However, despite of extensive research and recommendations, no reliable service appears available for the early detection of such upcoming events. Twitter, on the other hand, has become the media darling to stay informed about news as they unfold. Hence, continuous monitoring of hashtags like &lt;code&gt;#zombie&lt;/code&gt; or &lt;code&gt;#zombieattack&lt;/code&gt; appears an essential component of your zombie survival strategy.&lt;/p&gt;
&lt;h1 id=&quot;tight-clothes-short-hair-and-r&quot;&gt;Tight Clothes, Short Hair and R&lt;/h1&gt;
&lt;p&gt;Extending the recommendations of the Zombie Survival guide we provide an out-of-the-box (OOTB) monitoring system by using the &lt;code&gt;rtweet&lt;/code&gt; R package to obtain all individual tweets containing the hashtags &lt;code&gt;#zombie&lt;/code&gt; or &lt;code&gt;#zombieattack&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;the_query &amp;lt;-&lt;span class=&quot;st&quot;&gt; &amp;quot;#zombieattack OR #zombie&amp;quot;&lt;/span&gt;
geocode &amp;lt;-&lt;span class=&quot;st&quot;&gt; &amp;quot;&amp;quot;&lt;/span&gt;  &lt;span class=&quot;co&quot;&gt;#To limit the seach to berlin &amp;amp; surroundings: geocode &amp;lt;- &amp;quot;52.520583,13.402765,25km&amp;quot;&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#Converted query string which works for storing as file&lt;/span&gt;
safe_query &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;stringr::&lt;span class=&quot;kw&quot;&gt;str_replace_all&lt;/span&gt;(the_query, &lt;span class=&quot;st&quot;&gt;&amp;quot;[^[:alnum:]]&amp;quot;&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;&amp;quot;X&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In particular, the &lt;a href=&quot;https://github.com/mkearney/rtweet&quot;&gt;README&lt;/a&gt; of the &lt;code&gt;rtweet&lt;/code&gt; package provides helpful information on how to create a twitter app to automatically search tweets using the twitter API. One annoyance of the twitter REST API is that only the tweets of the past 7 days are kept in the index. Hence, your time series are going to be short unless you accumulate data over several queries spread over a time period. Instead of using a fancy database setup for this data collection, we provide a simple R solution based on &lt;code&gt;dplyr&lt;/code&gt; and &lt;code&gt;saveRDS&lt;/code&gt; - see the underlying R code of this post by clicking on the github logo in the license statement of this post. Basically,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;all tweets fulfilling the above hashtag search queries are extracted&lt;/li&gt;
&lt;li&gt;each tweet is extended with a time stamp of the query-time&lt;/li&gt;
&lt;li&gt;the entire result of each query us stored into a separate RDS-files using &lt;code&gt;saveRDS&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In a next step, all stored queries are loaded from the RDS files and put together. Subsequently, only the newest time stamped entry about each tweet is kept - this ensures that the re-tweeted counts are up-to-date and no post is counted twice. All these data wrangling operations are easily conducted using &lt;code&gt;dplyr&lt;/code&gt;. Of course a full database solution would have been more elegant, but R does the job just as well as long it&#39;s not millions of queries. Actually, in the example we are going to use the results of a single query. No matter the data backend, at the end of this pipeline we have a database of tweets.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;co&quot;&gt;#Read the tweet database&lt;/span&gt;
tw &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;readRDS&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;file=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;paste0&lt;/span&gt;(filePath,&lt;span class=&quot;st&quot;&gt;&amp;quot;Tweets-Database-&amp;quot;&lt;/span&gt;,safe_query,&lt;span class=&quot;st&quot;&gt;&amp;quot;-&amp;quot;&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;2016-09-25&amp;quot;&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;.RDS&amp;quot;&lt;/span&gt;))
&lt;span class=&quot;kw&quot;&gt;options&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;width=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;300&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;tibble.width =&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;Inf&lt;/span&gt;)
tw %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt;(created_at, retweet_count,screen_name,text,hashtags,query_at)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10,974 × 6
##             created_at retweet_count    screen_name                                                                                                                                          text  hashtags            query_at
##                 &amp;lt;dttm&amp;gt;         &amp;lt;int&amp;gt;          &amp;lt;chr&amp;gt;                                                                                                                                         &amp;lt;chr&amp;gt;    &amp;lt;list&amp;gt;              &amp;lt;dttm&amp;gt;
## 1  2016-09-25 10:26:28             0       Lovebian                                               The latest #Zombie Nation! https://t.co/8ZkOFSZH2v Thanks to @NJTVNews @MaxfireXSA @Xtopgun901X &amp;lt;chr [1]&amp;gt; 2016-09-25 10:30:44
## 2  2016-09-25 10:25:49             2  MilesssAwaaay RT @Shaaooun: I&amp;#39;m gonna turn to a zombie soon! xdxdxdxd #AlmostSurvived #204Days #ITried #Zombie #StuckInMyRoom #Haha\n\n#MediaDoomsDay #Kame &amp;lt;chr [7]&amp;gt; 2016-09-25 10:30:44
## 3  2016-09-25 10:21:10             6 catZzinthecity          RT @ZombieEventsUK: 7 reasons #TheGirlWithAllTheGifts is the best #zombie movie in years https://t.co/MB82ssxss2 via @MetroUK #Metro &amp;lt;chr [3]&amp;gt; 2016-09-25 10:30:44
## 4  2016-09-25 10:19:41             0  CoolStuff2Get                             Think Geek Zombie Plush Slippers https://t.co/0em920WCMh #Zombie #Slippers #MyFeetAreCold https://t.co/iCEkPBykCa &amp;lt;chr [3]&amp;gt; 2016-09-25 10:30:44
## 5  2016-09-25 10:19:41             4  TwitchersNews    RT @zOOkerx: Nur der frhe Vogel fngt den #zombie also schaut gemtlich rein bei @booty_pax! Now live #dayz on #twitch \n\nhttps://t.co/OIk6 &amp;lt;chr [3]&amp;gt; 2016-09-25 10:30:44
## 6  2016-09-25 10:17:45             0 ZombieExaminer     Washington mall shooting suspect Arcan Cetin was &amp;#39;#Zombie-like&amp;#39; during arrest - USA TODAY https://t.co/itoDXG3L8T https://t.co/q2mURi24DB &amp;lt;chr [1]&amp;gt; 2016-09-25 10:30:44
## 7  2016-09-25 10:17:44             4       SpawnRTs    RT @zOOkerx: Nur der frhe Vogel fngt den #zombie also schaut gemtlich rein bei @booty_pax! Now live #dayz on #twitch \n\nhttps://t.co/OIk6 &amp;lt;chr [3]&amp;gt; 2016-09-25 10:30:44
## 8  2016-09-25 10:17:23             0   BennyPrabowo                   bad miku - bad oni-chan... no mercy\n.\n.\n.\n.\n#left4dead #games #hatsunemiku #fps #zombie #witch https://t.co/YP0nRDFFj7 &amp;lt;chr [6]&amp;gt; 2016-09-25 10:30:44
## 9  2016-09-25 10:12:53            62   Nblackthorne  RT @PennilessScribe: He would end her pain, but he could no longer live in a world that demanded such sacrifice. #zombie #apocalypse\nhttps: &amp;lt;chr [2]&amp;gt; 2016-09-25 10:30:44
## 10 2016-09-25 10:06:46             0   mthvillaalva                                                             Pak ganern!!! Kakatapos ko lang kumain ng dugo! \n#Zombie https://t.co/Zyd0btVJH4 &amp;lt;chr [1]&amp;gt; 2016-09-25 10:30:44
## # ... with 10,964 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;ootb-zombie-surveillance&quot;&gt;OOTB Zombie Surveillance&lt;/h3&gt;
&lt;p&gt;We are now ready to prospectively detect changes using the &lt;code&gt;surveillance&lt;/code&gt; R package &lt;span class=&quot;citation&quot; data-cites=&quot;salmon_etal2016a&quot;&gt;(Salmon, Schumacher, and Höhle 2016)&lt;/span&gt;.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;library&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;surveillance&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We shall initially focus on the &lt;code&gt;#zombie&lt;/code&gt; series as it contains more counts. The first step is to convert the &lt;code&gt;data.frame&lt;/code&gt; of individual tweets into a time series of daily counts.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;co&quot;&gt;#&amp;#39; Function to convert data.frame to queries. For convenience we store the time series&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#&amp;#39; and the data.frame jointly as a list. This allows for easy manipulations later on&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#&amp;#39; as we see data.frame and time series to be a joint package.&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#&amp;#39;&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#&amp;#39; @param tw data.frame containing the linelist of tweets.&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#&amp;#39; @param the_query_subset String containing a regexp to restrict the hashtags&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#&amp;#39; @param delete_first_day (boolean) Delete first day of the series due to it being incomplete&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#&amp;#39; @return List containing sts object as well as the original data frame.&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#&amp;#39;&lt;/span&gt;
df_2_timeseries &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(tw, the_query_subset, &lt;span class=&quot;dt&quot;&gt;delete_first_day=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;) {
  tw_subset &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;tw %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;filter&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;grepl&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;gsub&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;#&amp;quot;&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;&amp;quot;&lt;/span&gt;,the_query_subset),hashtags))

  &lt;span class=&quot;co&quot;&gt;#Aggregate data per day and convert times series to sts object&lt;/span&gt;
  ts &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;surveillance::&lt;span class=&quot;kw&quot;&gt;linelist2sts&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;as.data.frame&lt;/span&gt;(tw_subset), &lt;span class=&quot;dt&quot;&gt;dateCol=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;created_at_Date&amp;quot;&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;aggregate.by=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;1 day&amp;quot;&lt;/span&gt;)
  &lt;span class=&quot;co&quot;&gt;#Drop first day with observations, due to the moving window of the twitter index, this count is incomplete&lt;/span&gt;
  if (delete_first_day) ts &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;ts[-&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,]

  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;tw=&lt;/span&gt;tw_subset,&lt;span class=&quot;dt&quot;&gt;ts=&lt;/span&gt;ts, &lt;span class=&quot;dt&quot;&gt;the_query_subset=&lt;/span&gt;the_query_subset))
}

zombie &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;df_2_timeseries&lt;/span&gt;(tw, &lt;span class=&quot;dt&quot;&gt;the_query_subset =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;#zombie&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It&#39;s easy to visualize the resulting time series using the plotting functionality of the surveillance package.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-09-25-sootb/unnamed-chunk-9-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;We see that the counts on the last day are incomplete. This is because the query was performed at 10:30 CEST and not at midnight. We therefore adjust counts on the last day based on simple inverse probability weighting. This just means that we scale up the counts by the inverse of the fraction the query-hour (10:30 CEST) makes up of 24h (see github code for details). The usefulness of this adjustment relies on the assumption that queries are evenly distributed over the day.&lt;/p&gt;
&lt;p&gt;We are now ready to apply a surveillance algorithm to the pre-processed time series. We shall pick the so called C1 version of the EARS algorithm documented in &lt;span class=&quot;citation&quot; data-cites=&quot;hutwagner_etal2003&quot;&gt;Hutwagner et al. (2003)&lt;/span&gt; or &lt;span class=&quot;citation&quot; data-cites=&quot;fricker_etal2008&quot;&gt;Fricker, Hegler, and Dunfee (2008)&lt;/span&gt;. For a monitored time point &lt;span class=&quot;math inline&quot;&gt;\(s\)&lt;/span&gt; (here: a particular day, say, 2016-09-23), this simple algorithm takes the previous seven observations before &lt;span class=&quot;math inline&quot;&gt;\(s\)&lt;/span&gt; in order to compute the mean and standard deviation, i.e. &lt;span class=&quot;math display&quot;&gt;\[
\begin{align*}
\bar{y}_s             &amp;amp;= \frac{1}{7} \sum_{t=s-8}^{s-1} y_t, \\
\operatorname{sd}_s^2   &amp;amp;= \frac{1}{7-1} \sum_{t=s-8}^{s-1} (y_t - \bar{y}_s)^2.
\end{align*}
\]&lt;/span&gt; The algorithm then computes the z-statistic &lt;span class=&quot;math inline&quot;&gt;\(\operatorname{C1}_s = (y_s - \bar{y}_s)/\operatorname{sd}_s\)&lt;/span&gt; for each time point to monitor. Once the value of this statistic is above 3 an alarm is flagged. This means that we assume that the previous 7 observations are what is to be expected when no unusual activity is going on. One can interpret the statistic as a transformation to (standard) normality: once the current observation is too extreme under this model an alarm is sounded. Such normal-approximations are justified given the large number of daily counts in the zombie series we consider, but does not take secular trends or day of the week effects into account. Note also that the calculations can also be reversed in order to determine how large the number of observations needs to be in order to generate an alarm (shown as a red line in the graph).&lt;/p&gt;
&lt;p&gt;We now apply the EARS C1 monitoring procedure to the zombie time series starting at the 8th day of the time series. It is important to realize that the result of monitoring a time point in the graphic is obtained by only &lt;strong&gt;looking into the past&lt;/strong&gt;. Hence, the relevant time point to consider today is if an alarm would have occurred 2016-09-25. We also show the other time points to see, if we could have detected potential alarms earlier.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;zombie[[&lt;span class=&quot;st&quot;&gt;&amp;quot;sts&amp;quot;&lt;/span&gt;]] &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;earsC&lt;/span&gt;(zombie$ts, &lt;span class=&quot;dt&quot;&gt;control=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;range =&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;8&lt;/span&gt;:&lt;span class=&quot;kw&quot;&gt;nrow&lt;/span&gt;(zombie$ts),
                         &lt;span class=&quot;dt&quot;&gt;method =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;C1&amp;quot;&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;alpha =&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;-&lt;span class=&quot;kw&quot;&gt;pnorm&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;)))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-09-25-sootb/ZOMBIE-TS-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;What a relief! No suspicious zombie activity appears to be ongoing. Actually, it would have taken 511 additional tweets before we would have raised an alarm on 2016-09-25. This is quite a number.&lt;/p&gt;
&lt;p&gt;As an additional sensitivity analysis we redo the analyses for the &lt;code&gt;#zombieattack&lt;/code&gt; hashtag. Here the use of the normal approximation in the computation of the alerts is more questionable. Still, we can get a time series of counts together with the alarm limits.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-09-25-sootb/ZOMBIEATTACK-TS-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;Also no indication of zombie activity. The number of additional tweets needed before alarm in this case is: 21. Altogether, it looks safe out there...&lt;/p&gt;
&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;
&lt;p&gt;R provides ideal functionality to quickly extract and monitor twitter time series. Combining with statistical process control methods allows you to prospectively monitor the use of hashtags. Twitter has released a dedicated package for this purpose, however, in case of low count time series it is better to use count-time series monitoring devices as implemented in the &lt;code&gt;surveillance&lt;/code&gt; package. &lt;span class=&quot;citation&quot; data-cites=&quot;salmon_etal2016a&quot;&gt;Salmon, Schumacher, and Höhle (2016)&lt;/span&gt; contains further details on how to proceed in this case.&lt;/p&gt;
&lt;p&gt;The important question although remains: Does this really work in practice? Can you sleep tight, while your R zombie monitor scans twitter? Here is where the &lt;strong&gt;social experiment&lt;/strong&gt; starts: Please help by retweeting the post below to create a drill alarm situation. More than 511 (!) and 21 additional tweets, respectively, are needed before an alarm will sound.&lt;/p&gt;
&lt;center&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;de&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;
New blog entry: Please RT to help me evaluate my &lt;a href=&quot;https://twitter.com/hashtag/zombie?src=hash&quot;&gt;#zombie&lt;/a&gt; monitoring system - &lt;a href=&quot;https://t.co/b0gNfpJ0RM&quot;&gt;https://t.co/b0gNfpJ0RM&lt;/a&gt; &lt;a href=&quot;https://twitter.com/hashtag/zombieattack?src=hash&quot;&gt;#zombieattack&lt;/a&gt; &lt;a href=&quot;https://twitter.com/hashtag/biosurveillance?src=hash&quot;&gt;#biosurveillance&lt;/a&gt; &lt;a href=&quot;https://twitter.com/hashtag/rstats?src=hash&quot;&gt;#rstats&lt;/a&gt; &lt;a href=&quot;https://t.co/N3PTZBnaw4&quot;&gt;pic.twitter.com/N3PTZBnaw4&lt;/a&gt;
&lt;/p&gt;
— Michael Höhle (@m_hoehle) &lt;a href=&quot;https://twitter.com/m_hoehle/status/780037067183157248&quot;&gt;25. September 2016&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/center&gt;
&lt;p&gt;I will continuously update the graphs in this post to see how our efforts are reflected in the time series of tweets containing the &lt;code&gt;#zombieattack&lt;/code&gt; and &lt;code&gt;#zombie&lt;/code&gt; hashtags. Thanks for your help!&lt;/p&gt;
&lt;p&gt;
&lt;center&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-09-25-sootb/zombie.png&quot; title=&quot;Source: https://openclipart.org/detail/201838/zombie-head&quot; /&gt; &lt;img src=&quot;/hoehle/blog/figure/source/2016-09-25-sootb/zombie.png&quot; title=&quot;Source: https://openclipart.org/detail/201838/zombie-head&quot; /&gt; &lt;img src=&quot;/hoehle/blog/figure/source/2016-09-25-sootb/zombie.png&quot; title=&quot;Source: https://openclipart.org/detail/201838/zombie-head&quot; /&gt;
&lt;/center&gt;
&lt;p&gt;
&lt;p&gt;
&lt;h3 id=&quot;update-at-2016-11-03-000831&quot;&gt;Update at 2016-11-03 00:08:31&lt;/h3&gt;
&lt;p&gt;Below we show how the &lt;code&gt;#zombieattack&lt;/code&gt; series developed after the post was made public:&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-09-25-sootb/ZOMBIEATTACK_UPDATED-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;The orange part of the bars indicates the fake outbreak tweet (1) as well as its retweets (10). It is obvious that despite the increased activity due to the fake outbreak tweets, no alarm was generated because of them. In parts this is explained by the high activity during 20-21 Sep. A previous outbreak? No, advertisements of &lt;a href=&quot;https://www.etsy.com/listing/480088383/zombie-pin-up-badges-zombie-themed-gifts?ref=shop_home_feat_4&quot;&gt;zombie pinup badges on etsy&lt;/a&gt;. Since the EARS algorithm sequentially estimates the variance of the baseline counts, the peak on 20-21 Sep inflates the mean and variance and thus results in a high upperbound as long as it enters the baseline. Despite some extra activity 25-27 Sep due to the fake outbreak tweets, none of the days are above this bound. However, once the 20-21 Sep peak is out of the previous 7 days baseline, the alarm threshold decreases noticeably. We thus get an alarm for the peak on 30 September, even though it&#39;s not higher than the previous peak on 20-21 Sep and it appears to be caused by other phenomena not related to our fake outbreak. A more careful analysis of the tweets reveals that they are caused by a &lt;a href=&quot;http://charityfunrun2016.tumblr.com/post/149930159797/charity-fun-run-2016&quot;&gt;charity fun run&lt;/a&gt; near Kuala Lumpur with a &lt;a href=&quot;https://www.instagram.com/p/BK-_l8oDD38/&quot;&gt;zombie attack theme&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;
SPAM FAM 😋 &lt;a href=&quot;https://twitter.com/hashtag/zombieattack?src=hash&quot;&gt;#zombieattack&lt;/a&gt; &lt;a href=&quot;https://twitter.com/hashtag/charityfunrun2016?src=hash&quot;&gt;#charityfunrun2016&lt;/a&gt; &lt;a href=&quot;https://t.co/YJW8Mjpd0L&quot;&gt;pic.twitter.com/YJW8Mjpd0L&lt;/a&gt;
&lt;/p&gt;
— PAAN (@noorfarhan_) &lt;a href=&quot;https://twitter.com/noorfarhan_/status/781887252519460864&quot;&gt;September 30, 2016&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;p&gt;
&lt;p&gt;For further comparison, we also use a negative binomial CUSUM, which keeps the baseline steady, but allows the detection of sustained increases.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-09-25-sootb/ZOMBIEUPDATE-NBINOM-CUSUM-PLOT-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;The gray line shows the estimated mean from the eight base-line counts, the orange line shows the corresponding upper 99% quantile of this estimated distribution. The red line shows the alarm limit of a CUSUM method where the potential shift in the mean is estimated by maximum likelihood at each monitoring instance. The threshold is tuned such that it initially roughly coincides with the 99% quantile of the estimated distribution. Here, no signal is detected. Of course this depends on the quantile used for the detection and the 20-21 September peak being included fully in the baseline. Still, according to this metric occasional fake zombie runs are part of the routine.&lt;/p&gt;
&lt;p&gt;Altogether, the &amp;quot;failed&amp;quot;&amp;quot; test proves several points:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;its hard to distinguish between previous outbreaks and irregular tweeting behaviour&lt;/li&gt;
&lt;li&gt;robust estimation of the baseline parameters might be needed&lt;/li&gt;
&lt;li&gt;the results are sensitive to the choice of which values to include in the baseline and the underlying probability model&lt;/li&gt;
&lt;li&gt;is twitter monitoring really sensitive enough to detect weak signals early enough?&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;the-take-home-message-of-this-update&quot;&gt;The take home message of this update&lt;/h4&gt;
&lt;p&gt;To enhance statistical competence and preserve sleep: stick with the negative binomial CUSUM!&lt;/p&gt;
&lt;h1 id=&quot;references&quot; class=&quot;unnumbered&quot;&gt;References&lt;/h1&gt;
&lt;div id=&quot;refs&quot; class=&quot;references&quot;&gt;
&lt;div id=&quot;ref-fricker_etal2008&quot;&gt;
&lt;p&gt;Fricker, R. D., B. L. Hegler, and D. A. Dunfee. 2008. “Comparing syndromic surveillance detection methods: EARS’ versus a CUSUM-based methodology.” &lt;em&gt;Stat Med&lt;/em&gt; 27 (17): 3407–29.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-hutwagner_etal2003&quot;&gt;
&lt;p&gt;Hutwagner, L., W. Thompson, G. M. Seeman, and T. Treadwell. 2003. “The bioterrorism preparedness and response Early Aberration Reporting System (EARS).” &lt;em&gt;J Urban Health&lt;/em&gt; 80 (2 Suppl 1): 89–96.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-salmon_etal2016a&quot;&gt;
&lt;p&gt;Salmon, M., D. Schumacher, and M. Höhle. 2016. “Monitoring Count Time Series in R: Aberration Detection in Public Health Surveillance.” &lt;em&gt;Journal of Statistical Software&lt;/em&gt; 70 (10). doi:&lt;a href=&quot;https://doi.org/10.18637/jss.v070.i10&quot;&gt;10.18637/jss.v070.i10&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
        <pubDate>Sun, 25 Sep 2016 00:00:00 +0200</pubDate>
        <link>http://staff.math.su.se/hoehle/blog/2016/09/25/sootb.html</link>
        <guid isPermaLink="true">http://staff.math.su.se/hoehle/blog/2016/09/25/sootb.html</guid>
        
        <category>datascience</category>
        
        <category>rstats</category>
        
        <category>statistical process control</category>
        
        <category>biosurveillance</category>
        
        
      </item>
    
      <item>
        <title>The Olympic Medal Table Visualized Gapminder Style</title>
        <description>&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Following Hans Rosling&#39;s Gapminder animation style we visualize the total number of medals a country wins during each olympic summer games in relation to the country&#39;s &lt;a href=&quot;https://en.wikipedia.org/wiki/Gross_domestic_product&quot;&gt;gross domestic product&lt;/a&gt; (GDP) per capita. We illustrate how R&#39;s data wrangling capabilities provide a useful toolbox to make such an analysis happen.&lt;/p&gt;
&lt;p&gt;&lt;br&gt; &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width:0&quot; src=&quot;https://i.creativecommons.org/l/by-sa/4.0/88x31.png&quot;/&gt;&lt;/a&gt; This work is licensed under a &lt;a rel=&quot;license&quot;
href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt;. The markdown+Rknitr source code of this blog is available under a &lt;a href=&quot;https://www.gnu.org/licenses/gpl-3.0.html&quot;&gt;GNU General Public License (GPL v3)&lt;/a&gt; license from &lt;a href=&quot;https://github.com/hoehleatsu/hoehleatsu.github.io&quot;&gt;&lt;img src=&quot;/hoehle/blog/images/GitHub-Mark-32px.png&quot; alt=&quot;github&quot; /&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Long Swedish winter nights are best spent watching &lt;a href=&quot;https://en.wikipedia.org/wiki/Hans_Rosling&quot;&gt;Hans Rosling&lt;/a&gt;&#39;s inspiring &lt;a href=&quot;https://www.youtube.com/watch?v=hVimVzgtD6w&quot;&gt;TED talks&lt;/a&gt;. Such visualizations help the statistician make points about temporal trends in a x-axis to y-axis relationship, which otherwise might drown in modelling details. Recently, I stumbled over a &lt;a href=&quot;https://rpubs.com/sjackman/gapminder-gganimate&quot;&gt;blog post&lt;/a&gt; on how to use the &lt;a href=&quot;https://github.com/dgrtwo/gganimate&quot;&gt;&lt;code&gt;gganimate&lt;/code&gt;&lt;/a&gt; R package to animate the Gapminder data available from the &lt;code&gt;gapminder&lt;/code&gt; package. In order to perform a similar &lt;em&gt;Rosling style&lt;/em&gt; animation consider the following: Today, the Olympic Summer Games in Rio de Janeiro end. As usual this spawns a debate, whether the nation&#39;s participation has been successful. For this purpose the &lt;a href=&quot;https://en.wikipedia.org/wiki/Olympic_medal_table&quot;&gt;olympic medal table&lt;/a&gt; is often taken as basis for comparisons, e.g., to mock your &lt;a href=&quot;http://politiken.dk/sport/ol/ECE3349634/danmark-og-sverige-kaemper-til-det-sidste---men-hvor-daelen-er-norge-henne/&quot;&gt;neighbouring countries&lt;/a&gt;. Recent analyses and visualization have been interested in how to correct these tables for, e.g., population size or, more interesting, analyse the influence of GDP. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Google provides &lt;a href=&quot;https://landing.google.com/altmedaltable/&quot;&gt;alternative Olympics medal tables&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Time Magazine discusses whether it is fair &lt;a href=&quot;http://time.com/4452128/olympics-medals-per-capita-rankings/&quot;&gt;to rank countries by medals achieved alone&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The aim of the present blog note is to visualize how countries perform in the medal table in relation to their GDP per capita. From a technical viewpoint we experiment with using R to scrape the olympic medal tables from Wikipedia and animate the results Gapminder style. &lt;strong&gt;Disclaimer&lt;/strong&gt;: We only show the potential of such an analysis and, hence, worry less about the scientific validity of the analysis.&lt;/p&gt;
&lt;h1 id=&quot;data&quot;&gt;Data&lt;/h1&gt;
&lt;p&gt;We use the data of &lt;a href=&quot;https://www.gapminder.org/&quot;&gt;Gapminder&lt;/a&gt; in order to obtain country specific population and GDP per capita data for each of the years in the period of 1960-2016. The olympic medal tables are &#39;harvested&#39; from Wikipedia.&lt;/p&gt;
&lt;h2 id=&quot;olympic-medal-tables&quot;&gt;Olympic medal tables&lt;/h2&gt;
&lt;p&gt;Olympic medal tables were extracted using the &lt;code&gt;rvest&lt;/code&gt; package from the corresponding Wikipedia pages by using table-extracting-code described in the post by &lt;a href=&quot;http://blog.corynissen.com/2015/01/using-rvest-to-scrape-html-table.html&quot;&gt;Cory Nissen&lt;/a&gt;. The Wikipedia tables contain the current state of the medal table and hence take changes in the medal distribution, e.g. deprivation due to doping, into account. For details on such a table, see for example the &lt;a href=&quot;https://en.wikipedia.org/wiki/2012_Summer_Olympics_medal_table&quot;&gt;medal table of the 2012 summer games&lt;/a&gt; in London. In order to stay focused we hide the scraping functionality in the function &lt;code&gt;scrape_medaltab&lt;/code&gt; - see the code on GitHub for more details.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;co&quot;&gt;#Years which had olympic games&lt;/span&gt;
olympic_years &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;seq&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1960&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;2016&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;by=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;4&lt;/span&gt;)

&lt;span class=&quot;co&quot;&gt;# Extract olympic medal table from all olympic years since 1960&lt;/span&gt;
medals &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;bind_rows&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;lapply&lt;/span&gt;(olympic_years, scrape_medaltab))

&lt;span class=&quot;co&quot;&gt;# Show result&lt;/span&gt;
DT::&lt;span class=&quot;kw&quot;&gt;datatable&lt;/span&gt;(medals)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-08-21-gapMedal/unnamed-chunk-2-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;h2 id=&quot;gapminder-data&quot;&gt;Gapminder data&lt;/h2&gt;
&lt;p&gt;We obtain GDP per capita and population data from &lt;a href=&quot;https://www.gapminder.org/data/&quot;&gt;Gapminder&lt;/a&gt;. Unfortunately, these need to be fetched and merged manually. A more convenient way would have been to take these directly from the package &lt;a href=&quot;https://cran.r-project.org/web/packages/gapminder/index.html&quot;&gt;&lt;code&gt;gapminder&lt;/code&gt;&lt;/a&gt;, but newer &lt;a href=&quot;https://www.gapminder.org/data/documentation/gd001/&quot;&gt;GDP data&lt;/a&gt; are now available. Again, we hide the details of the data wrangling activities and refer to GitHub code.&lt;/p&gt;
&lt;p&gt;For convenience, we also extract the corresponding continent each country belongs to. This can be done conveniently by comparing with the &lt;code&gt;gapminder&lt;/code&gt; dataset (see code for details).&lt;/p&gt;
&lt;h2 id=&quot;joining-the-two-data-sources&quot;&gt;Joining the two data sources&lt;/h2&gt;
&lt;p&gt;In principle, all that is left to do is to join the two data sources using the country name of the gapminder dataset and the nation names of the olympic medal tables. However, a challenge of the present country based analysis is how to incorporate the many political changes which happened during the analysis period. As an example, East Germany participated as independent national olympic committee during 1968-1988, but the gapminder data only contain GDP data for Germany as a total. We therefore aggregate the results of the two countries for the analysis. A further important change is the split of the former Soviet Union into several independent states. As a consequence, in 1992 a subset of the former Soviet republics participated as &lt;a href=&quot;https://en.wikipedia.org/wiki/Unified_Team_at_the_1992_Summer_Olympics&quot;&gt;Unified Team&lt;/a&gt;. The GDP values for the Soviet Union thus have to be computed from the Gapminder data by manually summing the individual Soviet republic GDP values. Again we skip further data munging details and simply refer to the GitHub code for a &lt;strong&gt;transparent &amp;amp; reproducible&lt;/strong&gt; account. Warning: Only few of the entries in the list of &lt;a href=&quot;https://en.wikipedia.org/wiki/All-time_Olympic_Games_medal_table#Notes&quot;&gt;obsolete nations &amp;amp; name changes&lt;/a&gt; are taken into account.&lt;/p&gt;
&lt;p&gt;Conditioned on the success of the previous wrangling step, we can now join the two data sources:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;medals_gm &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;left_join&lt;/span&gt;(medals_mod, gapminder_manual, &lt;span class=&quot;dt&quot;&gt;by=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;Nation&amp;quot;&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;Year&amp;quot;&lt;/span&gt;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1 id=&quot;results&quot;&gt;Results&lt;/h1&gt;
&lt;p&gt;First we analyse the &lt;a href=&quot;https://en.wikipedia.org/wiki/All-time_Olympic_Games_medal_table&quot;&gt;all-time summer olympic medal table&lt;/a&gt; for the period 1960-2016.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;medals_alltime &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;medals_gm  %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;group_by&lt;/span&gt;(Nation)  %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;summarise&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;Total=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;sum&lt;/span&gt;(Total))  %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;arrange&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;desc&lt;/span&gt;(Total))
DT::&lt;span class=&quot;kw&quot;&gt;datatable&lt;/span&gt;(medals_alltime)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-08-21-gapMedal/unnamed-chunk-7-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;We now plot of the total number of medals awarded for each summer games in the period of 1960-2016.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;nTotal &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;medals_gm %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;group_by&lt;/span&gt;(Year) %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;summarise&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;TotalOfGames=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;sum&lt;/span&gt;(Total))
&lt;span class=&quot;kw&quot;&gt;ggplot&lt;/span&gt;(nTotal, &lt;span class=&quot;kw&quot;&gt;aes&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;x=&lt;/span&gt;Year,&lt;span class=&quot;dt&quot;&gt;y=&lt;/span&gt;TotalOfGames)) +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;geom_line&lt;/span&gt;() +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;ylab&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;Total number of medals per Summer Games&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-08-21-gapMedal/TOTALMEDALSPERGAME-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;A distinct increasing trend is observed in the above figure. Hence, in order to make between-country comparisons over time based on the number of medals won, we normalize the medals by the total number of medals awarded during the corresponding games. The result is stored in the column &lt;code&gt;Frac&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;medals_gm &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;medals_gm %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;left_join&lt;/span&gt;(nTotal, &lt;span class=&quot;dt&quot;&gt;by=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;Year&amp;quot;&lt;/span&gt;) %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;mutate&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;Frac =&lt;/span&gt; Total /&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;TotalOfGames)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After all these pre-processing steps, we can now compare country results for all summer games in the period 2000-2016.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-08-21-gapMedal/FACET2000ANDBEYOND-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;Note that for better visualization of the many countries with a small number of medals, an &lt;span class=&quot;math inline&quot;&gt;\(\sqrt{}\)&lt;/span&gt;-transform of the y-axis is used.&lt;/p&gt;
&lt;p&gt;Finally, we can use the &lt;code&gt;gganimate&lt;/code&gt; package to visualize the dependence of the total number of medals won in the summer games 1960-2016 as a function of GDP per capita.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-08-21-gapMedal/olympicMedals-gapminder-style.gif&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;As before a &lt;span class=&quot;math inline&quot;&gt;\(\sqrt{}\)&lt;/span&gt;-transform of the y-axis is used for better visualization. One interesting observation we see from the animation is that the home-country of the Olympics always appears to do well in the following Olympics. Also note that the &lt;a href=&quot;https://en.wikipedia.org/wiki/1980_Summer_Olympics_boycott&quot;&gt;1980&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/1984_Summer_Olympics_boycott&quot;&gt;1984&lt;/a&gt; were special due to boycotts. With respect to the top-5 nations it is also worth noticing that China, due to protests against the participation of Taiwan, did not participate in the Olympics 1956-1980. Furthermore, up to 1988 the team denoted &amp;quot;Germany&amp;quot; in the animation consists of the combined number of medals of &amp;quot;East Germany&amp;quot; and &amp;quot;West Germany&amp;quot;.&lt;/p&gt;
&lt;h3 id=&quot;fun-with-flags&quot;&gt;Fun with Flags&lt;/h3&gt;
&lt;p&gt;Update: After being made aware of the concurrent &lt;a href=&quot;http://pmassicotte.github.io/2016-08-25-olympics2016&quot;&gt;blog entry&lt;/a&gt; by &lt;a href=&quot;https://www.researchgate.net/profile/Philippe_Massicotte&quot;&gt;Philippe Massicotte&lt;/a&gt; on how to visualize the Rio medal table using the &lt;code&gt;ggflags&lt;/code&gt; package, the above gapminder visualization can easily be extended to use flags instead of nation names. As the &lt;code&gt;ggflags&lt;/code&gt; package only contains the flags of currently existing countries we start the visualization in 1990. For better visability we also add the trajectory of each nation.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-08-21-gapMedal/olympicMedals-flags.gif&quot; /&gt;
&lt;/figure&gt;
&lt;h3 id=&quot;number-of-medals-per-population&quot;&gt;Number of Medals per Population&lt;/h3&gt;
&lt;p&gt;To see the medal tables in a different light, we instead visualize a quantity relative to the number of medals per population. To enable cross-year comparisons we therefore compute the following index for each country and olympic summer games: &lt;span class=&quot;math display&quot;&gt;\[
\frac{\text{Fraction of All Medals the Country got in that Year}}{\text{Population in the Country that Year}} \times 10^6.
\]&lt;/span&gt; We shall call this index a country&#39;s fraction of all medals per million population. A similar animation as above, now with logarithmic y-axis, illustrates the dynamics. To provide &lt;strong&gt;evidence supported neighbour mocking&lt;/strong&gt;, we highlight the position of the three Nordic countries (Denmark, Sweden and Norway).&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-08-21-gapMedal/olympicMedals-perpop-gapminder-style.gif&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;Jamaica, Bahamas and Grenada appear to do reasonably well lately compared to their population size. However, more more important - did you noticed the position of Denmark at the 2016 games in Rio?&lt;/p&gt;
&lt;div id=&quot;refs&quot; class=&quot;references&quot;&gt;

&lt;/div&gt;
</description>
        <pubDate>Sun, 21 Aug 2016 00:00:00 +0200</pubDate>
        <link>http://staff.math.su.se/hoehle/blog/2016/08/21/gapMedal.html</link>
        <guid isPermaLink="true">http://staff.math.su.se/hoehle/blog/2016/08/21/gapMedal.html</guid>
        
        <category>datascience</category>
        
        <category>rstats</category>
        
        <category>olympic games</category>
        
        
      </item>
    
      <item>
        <title>No Sleep During the Reproducibility Session</title>
        <description>&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;R code is provided for implementing a statistical method by &lt;span class=&quot;citation&quot; data-cites=&quot;nishiura_etal2016&quot;&gt;Nishiura, Miyamatsu, and Mizumoto (2016)&lt;/span&gt; to assess when to declare the end of an outbreak of a person-to-person transmitted disease. The motivating example is the MERS-CoV outbreak in Korea, 2015. From a greater perspective, the blog entry is an attempt to advocate for spicing up statistical conferences by a &lt;strong&gt;reproducibility session&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;br&gt; &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width:0&quot; src=&quot;https://i.creativecommons.org/l/by-sa/4.0/88x31.png&quot;/&gt;&lt;/a&gt; This work is licensed under a &lt;a rel=&quot;license&quot;
href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt;. The markdown+Rknitr source code of this blog is available under a &lt;a href=&quot;https://www.gnu.org/licenses/gpl-3.0.html&quot;&gt;GNU General Public License (GPL v3)&lt;/a&gt; license from &lt;a href=&quot;https://github.com/hoehleatsu/hoehleatsu.github.io&quot;&gt;&lt;img src=&quot;/hoehle/blog/images/GitHub-Mark-32px.png&quot; alt=&quot;github&quot; /&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;A few weeks ago I went to the &lt;a href=&quot;https://biometricconference.org/&quot;&gt;International Biometric Conference (IBC)&lt;/a&gt; in Victoria. Conferences are good for meeting people, but with respect to scientific content, there is typically no more than 2-3 talks in a week, which you really remember. Partly, this is due to the format of statistics conferences not developing much in recent decades: it is plenary talks, invited sessions, contributed sessions, showcase sessions and poster sessions all over. However, some developments have occurred, e.g.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the German joint statistical meeting introduced the concept of a &lt;a href=&quot;http://www.uni-goettingen.de/de/501387.html&quot;&gt;stats bazaar&lt;/a&gt; talk.&lt;/li&gt;
&lt;li&gt;the &lt;a href=&quot;http://user2016.org/&quot;&gt;R User Conference&lt;/a&gt; has added some interesting additional formats, e.g. lightning talks, in order to make life at a conference more interesting. Thomas Leeper has written an inspiring &lt;a href=&quot;http://thomasleeper.com/2015/07/user2015-lessons/&quot;&gt;blog post&lt;/a&gt; about this issue.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Not all science is &#39;fun&#39;, but when balancing between adding yet-another-table-from-a-simulation-study against 95% of the audience dozing off, I urge you to aim for an awake audience.&lt;/p&gt;
&lt;p&gt;So here is an additional session format in the spirit of &lt;strong&gt;reproducible science&lt;/strong&gt;, which might help make statistics conference more alive again: Take the contents of a talk, find the corresponding paper/technical report/slides, download the data (of course these are available) and start implementing. After all, hacking a statistical method is the best way to understand it and reproducing the results of an analysis is a form of peer-review we should do much more as statisticians. The important &lt;a href=&quot;The%20Importance%20of%20Reproducible%20Research%20in%20High-Throughput%20Biology:%20Case%20Studies%20in%20Forensic%20Bioinformatics&quot;&gt;talk&lt;/a&gt; by &lt;a href=&quot;http://odin.mdacc.tmc.edu/~kabaggerly/&quot;&gt;Keith A. Baggerly&lt;/a&gt; about reproducibility in bioinformatics more than underlines this.&lt;/p&gt;
&lt;p&gt;As a consequence, this blog entry is my attempt of a &lt;strong&gt;repro-session&lt;/strong&gt; in connection with the IBC: The talk entitled &lt;em&gt;&lt;a href=&quot;https://biometricconference.org/contributed-sessions/oral/detail/?sessionID=CS.15&quot;&gt;Determining the end of an epidemic with human-to-human transmission&lt;/a&gt;&lt;/em&gt; by &lt;a href=&quot;http://plaza.umin.ac.jp/~infepi/hnishiura.htm&quot;&gt;Hiroshi Nishiura&lt;/a&gt; was both interesting, from a field I&#39;m interested in (infectious disease epidemiology) and the method looked like it could be re-implemented in finite time. The question the method tries to answer is the following: at which time point can one declare an outbreak of a person-to-person transmitted disease as having ended? Answering this question can be important in order to calm the population, attract tourists again, export goods or reduce alertness status. The current WHO method for answering the question requires that a period of two times the longest possible incubation time needs to have passed since the last cases before an outbreak can be declared as being over. However, as stated in their paper (&lt;span class=&quot;citation&quot; data-cites=&quot;nishiura_etal2016&quot;&gt;Nishiura, Miyamatsu, and Mizumoto (2016)&lt;/span&gt;), the criterion clearly lacks a statistical motivation. As an improvement Nishiura and co-workers formulate a statistical criterion based on the serial interval distribution and the offspring distribution.&lt;/p&gt;
&lt;p&gt;In what follows we shall quickly describe their method and apply it to their motivating example, which was the 2015 MERS-CoV outbreak in Korea. As a small outlook, we shall implement some own thoughts on how to answer the posed questions using a hierarchical model.&lt;/p&gt;
&lt;h1 id=&quot;method&quot;&gt;Method&lt;/h1&gt;
&lt;p&gt;Let &lt;span class=&quot;math inline&quot;&gt;\(Y_t\)&lt;/span&gt; be a count variable representing the number of symptom onset in cases we observe on a given day &lt;span class=&quot;math inline&quot;&gt;\(t\)&lt;/span&gt; during the outbreak. The sequence of the &lt;span class=&quot;math inline&quot;&gt;\(Y_t\)&lt;/span&gt; is also called the &lt;a href=&quot;http://www.cdc.gov/foodsafety/outbreaks/investigating-outbreaks/epi-curves.html&quot;&gt;&lt;strong&gt;epidemic cuve&lt;/strong&gt;&lt;/a&gt; of the outbreak. Furthermore, let &lt;span class=&quot;math inline&quot;&gt;\(D=\{t_i; i=1,\ldots,n\}\)&lt;/span&gt;, be the currently available outbreak data containing the time of symptom onset in in each of the &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; cases of the outbreak. In what follows we will be interested in what happens with &lt;span class=&quot;math inline&quot;&gt;\(Y_t\)&lt;/span&gt; for future time points, i.e. time points after the last currently observed onset time. In particular we will be interested in, whether we will observe zero cases or more than zero cases.&lt;/p&gt;
&lt;p&gt;The important result of &lt;span class=&quot;citation&quot; data-cites=&quot;nishiura_etal2016&quot;&gt;Nishiura, Miyamatsu, and Mizumoto (2016)&lt;/span&gt; is that the probability &lt;span class=&quot;math inline&quot;&gt;\(\pi_t = P(Y_t &amp;gt; 0\&amp;gt;|\&amp;gt;D)\)&lt;/span&gt; can be computed as follows: &lt;span class=&quot;math display&quot;&gt;\[
\begin{align*}
\pi_t = 1 - \prod_{i=1}^n \sum_{o=0}^{\infty} f_{\text{offspring}}(o; R_0, k) \cdot \left[ F_{\text{serial}}(t-t_i) \right]^{o},
\end{align*}
\]&lt;/span&gt; where &lt;span class=&quot;math inline&quot;&gt;\(f_{\text{offspring}}\)&lt;/span&gt; denotes the PMF for the number of secondary cases one primary case induces. It is assumed that this distribution is negative binomial with expectation &lt;span class=&quot;math inline&quot;&gt;\(R_0&amp;gt;0\)&lt;/span&gt; and clumping parameter &lt;span class=&quot;math inline&quot;&gt;\(k&amp;gt;0\)&lt;/span&gt;. In other words, &lt;span class=&quot;math inline&quot;&gt;\(\operatorname{E}(O)=R_0\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(\operatorname{Var}(O)=R_0 + R_0^2/k\)&lt;/span&gt;. Furthermore, &lt;span class=&quot;math inline&quot;&gt;\(F_{\text{serial}}\)&lt;/span&gt; denotes the CDF of the serial interval distribution of the disease of interest. The serial interval is the time period between the onset of symptoms in the primary and onset of symptoms in the secondary case, see &lt;span class=&quot;citation&quot; data-cites=&quot;svensson2007&quot;&gt;Svensson (2007)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Once &lt;span class=&quot;math inline&quot;&gt;\(\pi_t\)&lt;/span&gt; is below some pre-defined threshold &lt;span class=&quot;math inline&quot;&gt;\(c\)&lt;/span&gt;, say &lt;span class=&quot;math inline&quot;&gt;\(c=0.05\)&lt;/span&gt;, one would declare the outbreak to be over, if no new cases have been observed by time &lt;span class=&quot;math inline&quot;&gt;\(t\)&lt;/span&gt;. In other words: &lt;span class=&quot;math display&quot;&gt;\[
T_{\text{end}} = \min_{t&amp;gt;t^*} \{ \pi_t &amp;lt; c \}.
\]&lt;/span&gt; where &lt;span class=&quot;math inline&quot;&gt;\(t^* = \max_{i=1,\ldots,n} t_i\)&lt;/span&gt;, i.e. the onset time in the last observed case.&lt;/p&gt;
&lt;p&gt;Note that the formulated approach is conservative, because every available case is treated as having the potential to generate new secondary cases according to the entire offspring distribution. In practice, however, observed cases towards the end will be secondary cases of some of the earlier cases. Hence, these primary cases will be attributed as having the ability to generate more secondary cases than they actually have in practice. Another important assumption of the method is that all cases are observed: no asymptomatic cases nor under-reporting is taken into account.&lt;/p&gt;
&lt;h2 id=&quot;data-from-the-mers-cov-oubtreak-in-korea-2015&quot;&gt;Data from the MERS-Cov Oubtreak in Korea, 2015&lt;/h2&gt;
&lt;p&gt;The data basis for our analysis is the WHO data set on the &lt;a href=&quot;http://www.who.int/csr/don/21-july-2015-mers-korea/en/&quot;&gt;MERS-Cov outbreak in Korea&lt;/a&gt;, which occurred during May-July 2015. It contains the information about 185 cases of the MERS-CoV outbreak in Korea, 2015. These were already analysed in a previous &lt;a href=&quot;./2016-07-19-nowCast.Rmd&quot;&gt;blog entry&lt;/a&gt; for the purpose of nowcasting. However, we shall now be interested in answering the following question: Given the observations of symptoms on the last (known) case on 2015-07-02. How many days without new infections would have to pass, before we would declare the outbreak as having &lt;strong&gt;ended&lt;/strong&gt;?&lt;/p&gt;
&lt;h2 id=&quot;results&quot;&gt;Results&lt;/h2&gt;
&lt;p&gt;In what follows we shall distinguish results between model parameters to be estimated from data and the computation of the probability &lt;span class=&quot;math inline&quot;&gt;\(\pi_t\)&lt;/span&gt;. Focus of this blog entry is on the later part. Details on the first part is available in the code.&lt;/p&gt;
&lt;h2 id=&quot;parameter-estimation&quot;&gt;Parameter Estimation&lt;/h2&gt;
&lt;p&gt;The parameters to estimate are the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;parameters of the parametric distributional family governing the serial interval distribution (in &lt;span class=&quot;citation&quot; data-cites=&quot;nishiura_etal2016&quot;&gt;Nishiura, Miyamatsu, and Mizumoto (2016)&lt;/span&gt; this is assumed to be a gamma distribution)&lt;/li&gt;
&lt;li&gt;parameters of the offspring distribution, which here is assumed to be negative binomial with mean &lt;span class=&quot;math inline&quot;&gt;\(R_0\)&lt;/span&gt; and clumping parameter &lt;span class=&quot;math inline&quot;&gt;\(k\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The first step is easily accomplished in &lt;span class=&quot;citation&quot; data-cites=&quot;nishiura_etal2015&quot;&gt;Nishiura et al. (2015)&lt;/span&gt; by solving for given mean and standard deviation for the serial interval distribution observed in secondary data - see the paper for details. The solution can be found analytically given the values.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;E &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;12.6&lt;/span&gt;
SD &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;2.8&lt;/span&gt;
(theta_serial &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(E^&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;/SD^&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;,E/SD^&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## [1] 20.25  1.61&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The second part is addressed in &lt;span class=&quot;citation&quot; data-cites=&quot;nishiura_etal2015&quot;&gt;Nishiura et al. (2015)&lt;/span&gt; by analysing final-size and generation data using a maximum likelihood approach. We will here only implement the methods using the data presented in Figure 1 and Table 1 of the paper. Unfortunately, one cluster size is not immediately reconstructable from the data in the paper, but guesstimating from the table on p.4 of the &lt;a href=&quot;http://ecdc.europa.eu/en/publications/Publications/RRA-Middle-East-respiratory-syndrome-coronavirus-Korea.pdf&quot;&gt;ECDC Rapid Risk Assessment&lt;/a&gt; it appears to be the outbreak in Jordan with a size of 19. The likelihood is then maximized for &lt;span class=&quot;math inline&quot;&gt;\(\mathbf{\theta}=(\log(R_0),\log(k))&amp;#39;\)&lt;/span&gt; using &lt;code&gt;optim&lt;/code&gt;. Based on the Hessian, a numeric approximation of the variance-covariance matrix of &lt;span class=&quot;math inline&quot;&gt;\(\hat{\mathbf{\theta}}\)&lt;/span&gt; can be obtained.&lt;/p&gt;
&lt;p&gt;Altogether, we maximize the combined likelihood consisting of 36 as well as the corresponding number of generations by:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;theta_mle &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;optim&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;log&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;),&lt;span class=&quot;kw&quot;&gt;log&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)),ll_combine, &lt;span class=&quot;dt&quot;&gt;outbreaks=&lt;/span&gt;outbreaks, &lt;span class=&quot;dt&quot;&gt;control=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;fnscale=&lt;/span&gt;-&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;),&lt;span class=&quot;dt&quot;&gt;hessian=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;)
&lt;span class=&quot;kw&quot;&gt;exp&lt;/span&gt;(theta_mle$par)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.826 0.128&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These numbers deviate slightly from the values of &lt;span class=&quot;math inline&quot;&gt;\(\hat{R}_0=0.75\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(\hat{k}=0.14\)&lt;/span&gt; reported by &lt;span class=&quot;citation&quot; data-cites=&quot;nishiura_etal2015&quot;&gt;Nishiura et al. (2015)&lt;/span&gt;. One explanation might be the unclear cluster size of the Jordan outbreak, here it would have been helpful to have had all data directly available in electronic form.&lt;/p&gt;
&lt;h2 id=&quot;outbreak-end&quot;&gt;Outbreak End&lt;/h2&gt;
&lt;p&gt;The above &lt;span class=&quot;math inline&quot;&gt;\(\pi_t\)&lt;/span&gt; equation is implemented below as function &lt;code&gt;p_oneormore&lt;/code&gt;. It requires the use of the PMF of the offspring distribution (&lt;code&gt;doffspring&lt;/code&gt;), which here is the negative binomial offspring distribution.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Offspring distribution, this is just the negative binomial PMF.
doffspring &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(y, R_0, k, &lt;span class=&quot;dt&quot;&gt;log=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;FALSE&lt;/span&gt;) {
  &lt;span class=&quot;kw&quot;&gt;dnbinom&lt;/span&gt;(y, &lt;span class=&quot;dt&quot;&gt;mu=&lt;/span&gt;R_0, &lt;span class=&quot;dt&quot;&gt;size=&lt;/span&gt;k, &lt;span class=&quot;dt&quot;&gt;log=&lt;/span&gt;log)
}

##Probability for one or more cases at time t.
p_oneormore &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;Vectorize&lt;/span&gt;(function(t,R_0,k,theta_serial,&lt;span class=&quot;dt&quot;&gt;yMax=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;1e4&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;verbose=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;FALSE&lt;/span&gt;) {
  if (verbose) &lt;span class=&quot;kw&quot;&gt;cat&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;paste0&lt;/span&gt;(t,&lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;ch&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;))
  res &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;

  ##Loop over all cases as in eqn (1) of the suppl. of Nishiura (2016).
  ##Setup process bar for this action.
  if (verbose) {
    pb &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;startpb&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;kw&quot;&gt;nrow&lt;/span&gt;(linelist))
    &lt;span class=&quot;kw&quot;&gt;on.exit&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;closepb&lt;/span&gt;(pb))
  }

  for (i in &lt;span class=&quot;kw&quot;&gt;seq_len&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;nrow&lt;/span&gt;(linelist))) {
    if (verbose) { &lt;span class=&quot;kw&quot;&gt;setpb&lt;/span&gt;(pb, i) }
    serial_time &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;as.numeric&lt;/span&gt;(t -&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;linelist$Date.of.symptoms.onset[i])
    cdf &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;pgamma&lt;/span&gt;(serial_time, theta_serial[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;], theta_serial[&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;])
    y &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;0L:yMax
    ysum &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;sum&lt;/span&gt;( &lt;span class=&quot;kw&quot;&gt;doffspring&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;y=&lt;/span&gt;y,&lt;span class=&quot;dt&quot;&gt;R_0=&lt;/span&gt;R_0,&lt;span class=&quot;dt&quot;&gt;k=&lt;/span&gt;k)*cdf^y)
    res &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;res *&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;ysum
  }
  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;-res)
},&lt;span class=&quot;dt&quot;&gt;vectorize.args=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;t&amp;quot;&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;R_0&amp;quot;&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;k&amp;quot;&lt;/span&gt;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The function allows us to re-calculate the results of &lt;span class=&quot;citation&quot; data-cites=&quot;nishiura_etal2016&quot;&gt;Nishiura, Miyamatsu, and Mizumoto (2016)&lt;/span&gt;:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Results from the Nishiura et al. (2015) paper
##R_0_hat &amp;lt;- 0.75 ; k_hat &amp;lt;- 0.14
##Use MLE found with the data we were able to extract.
R_0_hat &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;exp&lt;/span&gt;(theta_mle$par[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;])
k_hat   &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;exp&lt;/span&gt;(theta_mle$par[&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;])

## Compute prob for one or more cases on a grid of dates
df &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;data_frame&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;t=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;seq&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;as.Date&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;2015-07-15&amp;quot;&lt;/span&gt;),&lt;span class=&quot;kw&quot;&gt;as.Date&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;2015-08-05&amp;quot;&lt;/span&gt;),&lt;span class=&quot;dt&quot;&gt;by=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;1 day&amp;quot;&lt;/span&gt;))
df &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;df %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;mutate&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;pi =&lt;/span&gt;  &lt;span class=&quot;kw&quot;&gt;p_oneormore&lt;/span&gt;(t,&lt;span class=&quot;dt&quot;&gt;R_0=&lt;/span&gt;R_0_hat, &lt;span class=&quot;dt&quot;&gt;k=&lt;/span&gt;k_hat, &lt;span class=&quot;dt&quot;&gt;theta_serial=&lt;/span&gt;theta_serial, &lt;span class=&quot;dt&quot;&gt;yMax=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;250&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;verbose=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;FALSE&lt;/span&gt;))
&lt;span class=&quot;kw&quot;&gt;head&lt;/span&gt;(df, &lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## Source: local data frame [3 x 2]
## 
##            t    pi
##       (date) (dbl)
## 1 2015-07-15 0.366
## 2 2015-07-16 0.297
## 3 2015-07-17 0.226&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can embed estimation uncertainty originating from the estimation of &lt;span class=&quot;math inline&quot;&gt;\(R_0\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(k\)&lt;/span&gt; by adding an additional bootstrap step with values of &lt;span class=&quot;math inline&quot;&gt;\((\log R_0, \log k)&amp;#39;\)&lt;/span&gt; sampled from the asymptotic normal distribution. This distribution has expectation equal to the MLE and variance-covariance matrix equal to the observed Fisher information. Pointwise percentile-based 95% confidence intervals are then easily computed. The figure below shows this 95% CI (shaded area) together with the &lt;span class=&quot;math inline&quot;&gt;\(\pi_t\)&lt;/span&gt; curve.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-08-04-outbreakEnd/unnamed-chunk-8-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;Altogether, the date where we would declare the outbreak to be over is found as:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;c_threshold &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.05&lt;/span&gt;
(tEnd &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;df2 %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;filter&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;dt&quot;&gt;quantile.97.5%&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;`&lt;/span&gt; &amp;lt;&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;c_threshold) %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;slice&lt;/span&gt;(1L))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##            t     pi quantile.2.5% quantile.97.5%
## 1 2015-07-21 0.0345        0.0253         0.0454&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In other words, given the assumptions of the model and the chosen threshold, we would declare the outbreak to be over, if no new cases are observed by 2015-07-21. The adequate choice of &lt;span class=&quot;math inline&quot;&gt;\(c\)&lt;/span&gt; as cut-off in the procedure in general depends on what is at stake. Hence, choosing &lt;span class=&quot;math inline&quot;&gt;\(c=0.05\)&lt;/span&gt; without additional thought is more than arbitrary, but a more careful discussion is beyond the scope of this blog note.&lt;/p&gt;
&lt;h2 id=&quot;hierarchical-model&quot;&gt;Hierarchical model&lt;/h2&gt;
&lt;p&gt;Commenting on the derivations done in &lt;span class=&quot;citation&quot; data-cites=&quot;nishiura_etal2016&quot;&gt;Nishiura, Miyamatsu, and Mizumoto (2016)&lt;/span&gt; from a Bayesian viewpoint, it appears more natural to formulate the model directly in hierarchical terms:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
\begin{align*}
N_i                  &amp;amp;\sim \operatorname{NegBin}(R_0,k),                    &amp;amp; i&amp;amp;=1,\ldots,n,\\
\mathbf{O}_i\&amp;gt;|\&amp;gt;N_i &amp;amp;\sim \operatorname{M}(N_i,\mathbf{p}_{\text{serial}}),&amp;amp; i&amp;amp;=1,\ldots,n,\\
Y_t\&amp;gt;|\&amp;gt; \mathbf{O}  &amp;amp;= \sum_{i=1}^n O_{i,t_i-t}, &amp;amp; t&amp;amp;=t^*+1,t^*+2,\ldots,\\
\end{align*}
\]&lt;/span&gt; where &lt;span class=&quot;math inline&quot;&gt;\(\mathbf{p}_{\text{serial}}\)&lt;/span&gt; is the PMF of the discretized serial interval distribution for exampling obtained by computing &lt;span class=&quot;math inline&quot;&gt;\(p_{y} = F_{\text{serial}}(y) - F_{\text{serial}}(y-1)\)&lt;/span&gt; for &lt;span class=&quot;math inline&quot;&gt;\(0&amp;lt;y\leq S\)&lt;/span&gt;, where &lt;span class=&quot;math inline&quot;&gt;\(S\)&lt;/span&gt; is the largest possible/relevant serial interval to consider, and letting &lt;span class=&quot;math inline&quot;&gt;\(p_{0} = 0\)&lt;/span&gt;. Furthermore, &lt;span class=&quot;math inline&quot;&gt;\(O_{i,t_i-t}=0\)&lt;/span&gt; if &lt;span class=&quot;math inline&quot;&gt;\(t_i-t&amp;lt;0\)&lt;/span&gt; or &lt;span class=&quot;math inline&quot;&gt;\(t_i-t&amp;gt;S\)&lt;/span&gt; and corresponds to the value obtained from &lt;span class=&quot;math inline&quot;&gt;\(M(N_i,\mathbf{p}_{\text{serial}})\)&lt;/span&gt; otherwise. Finally, &lt;span class=&quot;math inline&quot;&gt;\(\mathbf{O}=(\mathbf{O}_1,\ldots,\mathbf{O}_n)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Given &lt;span class=&quot;math inline&quot;&gt;\(R_0\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(k\)&lt;/span&gt; it is easy to use Monte Carlo simulation to obtain instances of &lt;span class=&quot;math inline&quot;&gt;\(Y_t\)&lt;/span&gt; for a selected time-range from the above model. The code for this function &lt;code&gt;simulation&lt;/code&gt; is available as part of this R-markdown document (again, see the underlying source on the github repository for details). Similarly to the previous model the hierarchical model is also slightly conservative, because it does not take existing secondary cases in the data into account and samples &lt;span class=&quot;math inline&quot;&gt;\(N_i\)&lt;/span&gt; new secondary cases for each observed case.&lt;/p&gt;
&lt;p&gt;Since we for this model will be using simulations it is easy to modify the criterion for fade-out slightly to the more natural probability &lt;span class=&quot;math inline&quot;&gt;\(\pi_t^*\)&lt;/span&gt; that no case at &lt;span class=&quot;math inline&quot;&gt;\(t\)&lt;/span&gt; &lt;em&gt;nor beyond &lt;span class=&quot;math inline&quot;&gt;\(t\)&lt;/span&gt;&lt;/em&gt; will occur, i.e. &lt;span class=&quot;math display&quot;&gt;\[
\pi_t^* = P\left( \bigwedge_{i=t}^\infty \{Y_t = 0\} \right).
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We perform a study with 10000 different simulations each evaluated on a grid from 2015-07-03 to 2015-07-27. The resulting values are stored in the &lt;span class=&quot;math inline&quot;&gt;\(25 \times 10000\)&lt;/span&gt; matrix &lt;code&gt;Y&lt;/code&gt; from which we can compute:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;pi &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;apply&lt;/span&gt;(Y,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,mean)
pi[pi &amp;lt;&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;c_threshold]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## 2015-07-21 2015-07-22 2015-07-23 2015-07-24 2015-07-25 2015-07-26 2015-07-27 
##     0.0341     0.0197     0.0095     0.0037     0.0021     0.0013     0.0004&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Better way to calc extinction prob.
pi_star &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;rev&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;apply&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;apply&lt;/span&gt;(Y,&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;,function(x) &lt;span class=&quot;kw&quot;&gt;cumsum&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;rev&lt;/span&gt;(x))&amp;gt;&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;),&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,mean))
pi_star[pi_star &amp;lt;&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;c_threshold]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## 2015-07-22 2015-07-23 2015-07-24 2015-07-25 2015-07-26 2015-07-27 
##     0.0343     0.0168     0.0075     0.0038     0.0017     0.0004&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We note that the result, when using &lt;span class=&quot;math inline&quot;&gt;\(\pi_t^*\)&lt;/span&gt; instead of &lt;span class=&quot;math inline&quot;&gt;\(\pi_t\)&lt;/span&gt;, leads to the outbreak being declared over one day later. Additional uncertainty handling is performed as before by obtaining bootstrap samples for &lt;span class=&quot;math inline&quot;&gt;\((\log R_0, \log k)&amp;#39;\)&lt;/span&gt; from the asymptotic normal distribution. For each such sample the above Monte Carlo procedure is executed allowing us to determine point-wise confidence intervals for the probability by the percentile method.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-08-04-outbreakEnd/Y_UNCERTAINTY-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;h1 id=&quot;discussion&quot;&gt;Discussion&lt;/h1&gt;
&lt;p&gt;The present note introduced the statistical model based approach of &lt;span class=&quot;citation&quot; data-cites=&quot;nishiura_etal2016&quot;&gt;Nishiura, Miyamatsu, and Mizumoto (2016)&lt;/span&gt; for declaring the end of a person-to-person transmitted disease outbreak such as MERS-Cov, Ebola, etc. If the considered outbreak has a different mode of transmission, e.g. foodborne or originates from a point-source, then different formulas apply, see e.g. &lt;span class=&quot;citation&quot; data-cites=&quot;brookmeyer_you2006&quot;&gt;Brookmeyer and You (2006)&lt;/span&gt;. Interestingly enough, there appears to be some methodological overlap between declaring the end of an outbreak and declaring a software product to be free of errors.&lt;/p&gt;
&lt;p&gt;To summarise: The results of the &lt;span class=&quot;citation&quot; data-cites=&quot;nishiura_etal2016&quot;&gt;Nishiura, Miyamatsu, and Mizumoto (2016)&lt;/span&gt; paper could - with some fiddling to guesstimate the data - be approximately reproduced. A hierarchical model with simulation based inference was able to produce similar results. Availability of the full data in electronic form would have been helpful. Altoghether, it was fun to implement the method and hope is that the avaibility of the present analysis and R code might be helpful to someone at some point. You are certainly invited to &lt;strong&gt;reprofy&lt;/strong&gt; the present analysis.&lt;/p&gt;
&lt;center&gt;
&lt;embed src=&quot;https://openclipart.org/image/300px/svg_to_png/169987/copy.png&amp;amp;disposition=attachment&quot; /&gt;
&lt;/center&gt;
&lt;p&gt;
&lt;h3 id=&quot;acknowledgements&quot;&gt;Acknowledgements&lt;/h3&gt;
&lt;p&gt;I thank Hiroshi Nishiura for answering questions about their paper.&lt;/p&gt;
&lt;h1 id=&quot;references&quot; class=&quot;unnumbered&quot;&gt;References&lt;/h1&gt;
&lt;div id=&quot;refs&quot; class=&quot;references&quot;&gt;
&lt;div id=&quot;ref-brookmeyer_you2006&quot;&gt;
&lt;p&gt;Brookmeyer, R., and X. You. 2006. “A hypothesis test for the end of a common source outbreak.” &lt;em&gt;Biometrics&lt;/em&gt; 62 (1): 61–65. doi:&lt;a href=&quot;https://doi.org/10.1111/j.1541-0420.2005.00421.x&quot;&gt;10.1111/j.1541-0420.2005.00421.x&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-nishiura_etal2016&quot;&gt;
&lt;p&gt;Nishiura, H., Y. Miyamatsu, and K. Mizumoto. 2016. “Objective Determination of End of MERS Outbreak, South Korea, 2015.” &lt;em&gt;Emerging Infect. Dis.&lt;/em&gt; 22 (1): 146–48. doi:&lt;a href=&quot;https://doi.org/10.3201/eid2201.151383&quot;&gt;10.3201/eid2201.151383&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-nishiura_etal2015&quot;&gt;
&lt;p&gt;Nishiura, H., Y. Miyamatsu, G. Chowell, and M. Saitoh. 2015. “Assessing the risk of observing multiple generations of Middle East respiratory syndrome (MERS) cases given an imported case.” &lt;em&gt;Euro Surveill.&lt;/em&gt; 20 (27). doi:&lt;a href=&quot;https://doi.org/10.2807/1560-7917.ES2015.20.27.21181 &quot;&gt;10.2807/1560-7917.ES2015.20.27.21181&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-svensson2007&quot;&gt;
&lt;p&gt;Svensson, Å. 2007. “A note on generation times in epidemic models.” &lt;em&gt;Math Biosci&lt;/em&gt; 208 (1): 300–311. doi:&lt;a href=&quot;https://doi.org/10.1016/j.mbs.2006.10.010&quot;&gt;10.1016/j.mbs.2006.10.010&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
        <pubDate>Thu, 04 Aug 2016 00:00:00 +0200</pubDate>
        <link>http://staff.math.su.se/hoehle/blog/2016/08/04/outbreakEnd.html</link>
        <guid isPermaLink="true">http://staff.math.su.se/hoehle/blog/2016/08/04/outbreakEnd.html</guid>
        
        <category>rstats</category>
        
        <category>infectious disease epidemiology</category>
        
        <category>open data</category>
        
        <category>MERS</category>
        
        
      </item>
    
      <item>
        <title>Casting Call for MERS-CoV in Korea, 2015</title>
        <description>&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;We perform an adjustment for observed-but-not-yet-reported cases (aka. nowcasting) for the epidemic curve of the Middle East respiratory syndrome coronavirus (MERS-CoV) outbreak in Korea, 2015. The analysis is based on the publically available WHO data and aims at illustrating how one could do real-time public health surveillance during critical outbreaks.&lt;/p&gt;
&lt;p&gt;&lt;br&gt; &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width:0&quot; src=&quot;https://i.creativecommons.org/l/by-sa/4.0/88x31.png&quot;/&gt;&lt;/a&gt; This work is licensed under a &lt;a rel=&quot;license&quot;
href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt;. The markdown+Rknitr source code of this blog is available under a &lt;a href=&quot;https://www.gnu.org/licenses/gpl-3.0.html&quot;&gt;GNU General Public License (GPL v3)&lt;/a&gt; license from &lt;a href=&quot;https://github.com/hoehleatsu/hoehleatsu.github.io&quot;&gt;&lt;img src=&quot;/hoehle/blog/images/GitHub-Mark-32px.png&quot; alt=&quot;github&quot; /&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Short-range (0-6h) forecasts in the world of meteorology are also called &lt;strong&gt;nowcasts&lt;/strong&gt;. The term has also found its way into real-time infectious disease monitoring where one of its uses has been to adjust the currently available epidemic curve during an outbreak for structural and reporting delays.&lt;/p&gt;
&lt;p&gt;Whereas the original work in &lt;span class=&quot;citation&quot; data-cites=&quot;hoehle_anderheiden2014&quot;&gt;Höhle and an der Heiden (2014)&lt;/span&gt; was motivated by the large STEC O104:H4 outbreak in Germany 2011, one of our secondary motivations was to develop a tool the quantitative epidemiologist could use during similar high-profiled outbreaks (instead of having to re-invent the wheel during times of maximal stress). After my talk at the &lt;a href=&quot;https://biometricconference.org/showcases/biometrics-showcase/&quot;&gt;IBC2016 conference&lt;/a&gt; (&lt;a href=&quot;http://staff.math.su.se/hoehle/talks/IBC2016-Hoehle.pdf&quot;&gt;slides of the talk&lt;/a&gt;) one of the questions from the audience was how much impact the work had in terms of being useful for other outbreaks. Besides an analysis of an Adenovirus outbreak and a recent analysis of an O157 outbreak, I was a little short on a convincing answer. In addition, when trying to make a quick analysis for the O157 outbreak with the currently available code in the &lt;code&gt;surveillance&lt;/code&gt; package it became obvious that the nowcasting functionality in the package currently is a little rough and certainly in need of a user-friendliness polishing.&lt;/p&gt;
&lt;p&gt;So this little blog-note serves three purposes:&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;Illustrate how you can nowcasts with R, if you ever have to.&lt;/li&gt;
&lt;li&gt;Act as literate programming document for facilitating some code improvements of the &lt;code&gt;nowcast&lt;/code&gt; function while providing a vignette supported story.&lt;/li&gt;
&lt;li&gt;Perform an analysis of the WHO open-data on the MERS-CoV outbreak in Korea in 2015.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The structure of this blog entry is as follows. We first discuss and visualize the WHO data on the MERS-CoV outbreak. The findings from the descriptive data analysis are then used to set up nowcasts adjusting the observed epidemic curve during the outbreak for reporting delays between onset of symptoms in cases and the date the case report arrived at the WHO. Finally, we illustrate how to visualize a sequence of nowcasts during an outbreak using an animation.&lt;/p&gt;
&lt;h1 id=&quot;data&quot;&gt;Data&lt;/h1&gt;
&lt;p&gt;The data basis for our analysis is the WHO data on the &lt;a href=&quot;http://www.who.int/csr/don/21-july-2015-mers-korea/en/&quot;&gt;MERS-Cov outbreak in Korea&lt;/a&gt;, which occured during May-July 2015. Of interest will be the delay (here measured in days) between the time point on which a case has the onset of its MERS symptoms and the day the WHO learns about this case. In other words we put ourself in the role of an epidemiologist working at the WHO and who during the outbreak has to report on how the outbreak is evolving in Korea.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Load library to read excel files
&lt;span class=&quot;kw&quot;&gt;library&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;openxlsx&amp;quot;&lt;/span&gt;)

##Obtain file from link found at (if it doesn&amp;#39;t already exist)
##http://www.who.int/csr/don/21-july-2015-mers-korea/en/
if (!&lt;span class=&quot;kw&quot;&gt;file.exists&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;../downloads/MERS-CoV-cases-rok-21Jul15.xlsx&amp;quot;&lt;/span&gt;)) {
  &lt;span class=&quot;kw&quot;&gt;download.file&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;url=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;http://www.who.int/entity/csr/disease/coronavirus_infections/MERS-CoV-cases-rok-21Jul15.xlsx?ua=1&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;destfile=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;../downloads/MERS-CoV-cases-rok-21Jul15.xlsx&amp;quot;&lt;/span&gt;)
}

##Read data
linelist &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;read.xlsx&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;../downloads/MERS-CoV-cases-rok-21Jul15.xlsx&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;startRow=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;4&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;detectDates=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;)

##Base R style - IMHO easier to understand than the dplyr way to do the same
for (dateCol in &lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;Date.of.notification.to.WHO&amp;quot;&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;Date.of.symptoms.onset&amp;quot;&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;Date.of.first.hospitalization&amp;quot;&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;Date.of.laboratory.confirmation&amp;quot;&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;Date.of.outcome&amp;quot;&lt;/span&gt;)) {
  linelist[,dateCol] &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;as.Date&lt;/span&gt;(linelist[,dateCol],&lt;span class=&quot;dt&quot;&gt;format=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;%d/%m/%Y&amp;quot;&lt;/span&gt;)
}

##Make a delay column
linelist$delay &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;with&lt;/span&gt;(linelist,Date.of.notification.to.WHO -&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;Date.of.symptoms.onset)

&lt;span class=&quot;kw&quot;&gt;head&lt;/span&gt;(linelist,&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##   Case.no. Date.of.notification.to.WHO Age Sex Health.care.worker Comorbidities
## 1        1                  2015-05-20  68   M                 No          &amp;lt;NA&amp;gt;
## 2        2                  2015-05-22  63   F                 No          &amp;lt;NA&amp;gt;
## 3        3                  2015-05-22  76   M                 No          &amp;lt;NA&amp;gt;
##   Date.of.symptoms.onset Date.of.first.hospitalization Date.of.laboratory.confirmation
## 1             2015-05-11                    2015-05-15                      2015-05-20
## 2             2015-05-19                          &amp;lt;NA&amp;gt;                      2015-05-20
## 3             2015-05-20                          &amp;lt;NA&amp;gt;                      2015-05-20
##     Status Date.of.outcome  delay
## 1    Alive            &amp;lt;NA&amp;gt; 9 days
## 2    Alive            &amp;lt;NA&amp;gt; 3 days
## 3 Deceased      2015-06-04 2 days&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As the outbreak is already over, it is easy to visualize the epidemic curve in retrospect. We do so for the date of symptom onset.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Show the epidemic curve as it occurs at the end of the outbreak
##using simple call to ggplot
ggplot2::&lt;span class=&quot;kw&quot;&gt;ggplot&lt;/span&gt;( linelist, &lt;span class=&quot;kw&quot;&gt;aes&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;x=&lt;/span&gt;Date.of.symptoms.onset)) +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;geom_histogram&lt;/span&gt;() +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;xlab&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;Date of onset of symptoms&amp;quot;&lt;/span&gt;) +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;ylab&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;Number of cases&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-07-19-nowCast/EPICURVE-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;Furthermore, we can look at the delay distribution as it looks at the end of the outbreak. We shall later look in more detail at this distribution, but for now the plot gives an idea about the range of the delay: in most cases the delay is between 1-14 days, actually 97.1% of the observations have a lag smaller or equal to &lt;span class=&quot;math inline&quot;&gt;\(D=14\)&lt;/span&gt;. As a consequence, we shall use &lt;span class=&quot;math inline&quot;&gt;\(D=14\)&lt;/span&gt; as the maximum relevant lag to adjust for.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;ggplot&lt;/span&gt;( linelist, &lt;span class=&quot;kw&quot;&gt;aes&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;x=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;as.integer&lt;/span&gt;(delay),&lt;span class=&quot;dt&quot;&gt;y=&lt;/span&gt;..prop..)) +
&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;stat_count&lt;/span&gt;() +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;scale_y_continuous&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;labels =&lt;/span&gt; scales::percent) +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;xlab&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;Delay (days)&amp;quot;&lt;/span&gt;) +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;ylab&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-07-19-nowCast/unnamed-chunk-3-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;Instead of using &lt;code&gt;ggplot&lt;/code&gt; to show the epidemic curve, this can also be done directly from the surveillance package using the function &lt;code&gt;linelist2sts&lt;/code&gt;. This function takes a &lt;code&gt;data.frame&lt;/code&gt; representing a linelist and converts this into an object of class &lt;code&gt;sts&lt;/code&gt; (surveillance time series) used by the package. This then allows the use of all the plotting functionality of such objects as described in &lt;span class=&quot;citation&quot; data-cites=&quot;salmon_etal2016a&quot;&gt;Salmon, Schumacher, and Höhle (2016)&lt;/span&gt;. Note: For the nowcasting code of this blog entry to work, the newest development version of the package, i.e. version 1.12.2 available from Rforge using&lt;/p&gt;
&lt;p&gt;
&lt;center&gt;
&lt;code&gt;install.packages(&amp;quot;surveillance&amp;quot;,repos=&amp;quot;http://r-forge.r-project.org&amp;quot;)&lt;/code&gt;
&lt;/center&gt;
&lt;p&gt;
&lt;p&gt;is needed. The code then looks as follows:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Load surveillance pkg.
&lt;span class=&quot;kw&quot;&gt;library&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;surveillance&amp;quot;&lt;/span&gt;)

##Range of the symptom onset date variable
so_range &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;range&lt;/span&gt;(linelist$Date.of.symptoms.onset,&lt;span class=&quot;dt&quot;&gt;na.rm=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;)

##Create an sts time series from the linelist, which contains daily counts.
sts &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;linelist2sts&lt;/span&gt;(linelist, &lt;span class=&quot;dt&quot;&gt;dateCol=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;Date.of.symptoms.onset&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;aggregate.by=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;1 day&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;dRange=&lt;/span&gt;so_range)

##Show the resulting time series using the plot functionality for sts objects.
&lt;span class=&quot;kw&quot;&gt;plot&lt;/span&gt;(sts,&lt;span class=&quot;dt&quot;&gt;legend.opts=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;NULL&lt;/span&gt;,
     &lt;span class=&quot;dt&quot;&gt;xaxis.tickFreq=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;%d&amp;quot;&lt;/span&gt;=atChange,&lt;span class=&quot;st&quot;&gt;&amp;quot;%m&amp;quot;&lt;/span&gt;=atChange),
     &lt;span class=&quot;dt&quot;&gt;xaxis.labelFreq=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;%d&amp;quot;&lt;/span&gt;=at2ndChange),&lt;span class=&quot;dt&quot;&gt;xaxis.labelFormat=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;%d-%b&amp;quot;&lt;/span&gt;,
     &lt;span class=&quot;dt&quot;&gt;xlab=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;Time (days)&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;lty=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;),&lt;span class=&quot;dt&quot;&gt;lwd=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;),
     &lt;span class=&quot;dt&quot;&gt;ylab=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;No. symptom onsets&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-07-19-nowCast/EPICURVE-SURVEILLANCE-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;h2 id=&quot;nowcasting&quot;&gt;Nowcasting&lt;/h2&gt;
&lt;p&gt;We now move on to the nowcasts.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##State which date to nowcast
now &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;as.Date&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;2015-06-12&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Say (in a mathematical sense) we move back time to 2015-06-12. In the notation of &lt;span class=&quot;citation&quot; data-cites=&quot;hoehle_anderheiden2014&quot;&gt;Höhle and an der Heiden (2014)&lt;/span&gt; this means &lt;span class=&quot;math inline&quot;&gt;\(T=2015-06-12\)&lt;/span&gt;. We want to illustrate what the WHO could see at this point and, on the basis on how the available reports, estimate the delay distribution and adjust the observed cases accordingly. We shall here only use the right-truncation delay adjusted procedure operating on the generalized Dirichlet distribution. Since the nowcasts for the time points very close to now are very volatile (i.e. have very large credibility regions), it&#39;s opportune to not display these casts as they can be very hard to communicate. Also note that the selected date for &lt;code&gt;now&lt;/code&gt; is selected such that enough cases are available to give a sufficiently reliable estimate for the delay distribution.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Nowcasts are displayed up to time (now - safePredictLag)
safePredictLag &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;
nowcastDates &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;seq&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;from =&lt;/span&gt; so_range[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;], &lt;span class=&quot;dt&quot;&gt;to =&lt;/span&gt; now -&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;safePredictLag, &lt;span class=&quot;dt&quot;&gt;by =&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We now perform right-truncation adjusted Bayesian nowcasting using the generalized Dirichlet distribution. An important choice is here the prior for the expected number of cases per day, i.e. &lt;span class=&quot;math inline&quot;&gt;\(\lambda_t\)&lt;/span&gt; in the notation of &lt;span class=&quot;citation&quot; data-cites=&quot;hoehle_anderheiden2014&quot;&gt;Höhle and an der Heiden (2014)&lt;/span&gt;. In the conjugate case this is specified by assuming an iid. Gamma-distribution for &lt;span class=&quot;math inline&quot;&gt;\(\lambda_t\)&lt;/span&gt;, which is specified through prior mean and prior variance of the Gamma distribution. We here select here an empirical Bayes inspired approach and estimate these parameters from the currently available data. However, note: These data are by definition of the problem incomplete. As a dirty fix we therefore just inflate the prior variance by a factor - as future work this needs to be improved upon by following a proper marginal likelihood approach.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;nc.control &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(
  &lt;span class=&quot;dt&quot;&gt;N.tInf.prior =&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;structure&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;poisgamma&amp;quot;&lt;/span&gt;,
                           &lt;span class=&quot;dt&quot;&gt;mean.lambda =&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;mean&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;observed&lt;/span&gt;(sts)),
                           &lt;span class=&quot;dt&quot;&gt;var.lambda =&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;5&lt;/span&gt;*&lt;span class=&quot;kw&quot;&gt;var&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;observed&lt;/span&gt;(sts))
                           ),
  ##compute predictive distribution as wel, which is needed for some of the
  ##animations.
  &lt;span class=&quot;dt&quot;&gt;predPMF =&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;,
  &lt;span class=&quot;dt&quot;&gt;dRange =&lt;/span&gt; so_range)

## Now run the nowcast (NA dates are removed from the dataset).
nc &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;nowcast&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;now =&lt;/span&gt; now, &lt;span class=&quot;dt&quot;&gt;when =&lt;/span&gt; nowcastDates, &lt;span class=&quot;dt&quot;&gt;data =&lt;/span&gt; linelist,
              &lt;span class=&quot;dt&quot;&gt;dEventCol =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;Date.of.symptoms.onset&amp;quot;&lt;/span&gt;,
              &lt;span class=&quot;dt&quot;&gt;dReportCol =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;Date.of.notification.to.WHO&amp;quot;&lt;/span&gt;,
              &lt;span class=&quot;dt&quot;&gt;method =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;bayes.trunc&amp;quot;&lt;/span&gt;, &lt;span class=&quot;co&quot;&gt;#use the conjugate generalized dirichlet&lt;/span&gt;
              &lt;span class=&quot;dt&quot;&gt;aggregate.by =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;1 day&amp;quot;&lt;/span&gt;,
              &lt;span class=&quot;dt&quot;&gt;D =&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;14&lt;/span&gt;, &lt;span class=&quot;co&quot;&gt;#adjust cases up to 2 weeks back.&lt;/span&gt;
              &lt;span class=&quot;dt&quot;&gt;control =&lt;/span&gt; nc.control)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## Removed 13 records due to NA dates.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The resulting object is of class &lt;code&gt;stsNC&lt;/code&gt;, which is just a class inheriting from the &lt;code&gt;sts&lt;/code&gt; class. Hence, all the usual plotting functions apply to it. In addition, a plot of an &lt;code&gt;stsNC&lt;/code&gt; object as shown below, contains the median of the pointwise predictive distribution (thick blue line) as well as equi-tailed 95% credibility regions (dashed orange lines).&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;plot&lt;/span&gt;(nc, &lt;span class=&quot;dt&quot;&gt;legend.opts=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;NULL&lt;/span&gt;,
     &lt;span class=&quot;dt&quot;&gt;xaxis.tickFreq=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;%d&amp;quot;&lt;/span&gt;=atChange,&lt;span class=&quot;st&quot;&gt;&amp;quot;%m&amp;quot;&lt;/span&gt;=atChange),
     &lt;span class=&quot;dt&quot;&gt;xaxis.labelFreq=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;%d&amp;quot;&lt;/span&gt;=at2ndChange),&lt;span class=&quot;dt&quot;&gt;xaxis.labelFormat=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;%d-%b&amp;quot;&lt;/span&gt;,
     &lt;span class=&quot;dt&quot;&gt;xlab=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;Time (days)&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;lty=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;),&lt;span class=&quot;dt&quot;&gt;lwd=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;),
     &lt;span class=&quot;dt&quot;&gt;ylab=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;No. symptom onsets&amp;quot;&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;ylim=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;kw&quot;&gt;max&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;observed&lt;/span&gt;(nc),&lt;span class=&quot;kw&quot;&gt;upperbound&lt;/span&gt;(nc),&lt;span class=&quot;kw&quot;&gt;predint&lt;/span&gt;(nc),&lt;span class=&quot;dt&quot;&gt;na.rm=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;)))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-07-19-nowCast/NOWCASTPLOT-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;Finally, we can for &lt;code&gt;stsNC&lt;/code&gt; objects show a simple non-parametric estimate of the delay distribution as a function of time using a window-smoothed approach with window width &lt;span class=&quot;math inline&quot;&gt;\(2w+1\)&lt;/span&gt;, see &lt;span class=&quot;citation&quot; data-cites=&quot;hoehle_anderheiden2014&quot;&gt;Höhle and an der Heiden (2014)&lt;/span&gt; for details.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;plot&lt;/span&gt;(nc, &lt;span class=&quot;dt&quot;&gt;type=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;delay&amp;quot;&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;dates=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;seq&lt;/span&gt;(so_range[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;],now,&lt;span class=&quot;dt&quot;&gt;by=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;1 day&amp;quot;&lt;/span&gt;),&lt;span class=&quot;dt&quot;&gt;w=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-07-19-nowCast/NOWCASTDELAY-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;The figure shows for each time point &lt;span class=&quot;math inline&quot;&gt;\(t\)&lt;/span&gt; the median as well as the 10% and 90% quantile of the empirical distribution of delays within the window of &lt;span class=&quot;math inline&quot;&gt;\(t-w,\ldots,t+w\)&lt;/span&gt;. Note: This simple estimate ignores the right- truncation, hence, within the period of &lt;code&gt;(now-D):now&lt;/code&gt; there will be a bias of these estimates towards shorter delays. This biased period is illustrated in the figure by the light-gray shaded area. Furthermore, the median of the model based estimate for the delay distribution is shown for the period of &lt;code&gt;(now-m:now)&lt;/code&gt;. From the figure one has the suspicion that the delay decreased a bit over time, but the decrease totally at the end could also be due to right-truncation. However, assuming a &lt;strong&gt;time-invariant delay distribution&lt;/strong&gt; for the entire outbreak would probably give unsatisfactory results. Hence, we shall for each time point use only a moving window consisting of all observations occuring within the period &lt;code&gt;(now-m):now&lt;/code&gt;. We select &lt;span class=&quot;math inline&quot;&gt;\(m=14\)&lt;/span&gt; for estimating the delay distribution.&lt;/p&gt;
&lt;h2 id=&quot;showing-a-sequence-of-nowcasts&quot;&gt;Showing a sequence of nowcasts&lt;/h2&gt;
&lt;p&gt;Once a couple of nowcasts have been performed it can also be helpful to visualize the sequence of nowcasts using an animation. This is easily done by first generating a list of nowcast results followed by a call to &lt;code&gt;surveillance::animate_nowcasts&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Nowcast all time points (except for the first three weeks). This might take a while.
nowcasts &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;()
animRange &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;seq&lt;/span&gt;(so_range[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;]+&lt;span class=&quot;dv&quot;&gt;21&lt;/span&gt;,so_range[&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;],&lt;span class=&quot;dt&quot;&gt;by=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;1 day&amp;quot;&lt;/span&gt;)

##Do nowcasts for the rage of dates
for (i in &lt;span class=&quot;kw&quot;&gt;seq_len&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;length&lt;/span&gt;(animRange))) {
  today &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;animRange[i]
  &lt;span class=&quot;kw&quot;&gt;print&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;as.character&lt;/span&gt;(today))

  nowcastDates &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;seq&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;from =&lt;/span&gt; so_range[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;], &lt;span class=&quot;dt&quot;&gt;to =&lt;/span&gt; today -&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;safePredictLag, &lt;span class=&quot;dt&quot;&gt;by =&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)

  nowcasts[[&lt;span class=&quot;kw&quot;&gt;as.character&lt;/span&gt;(today)]] &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;nowcast&lt;/span&gt;(
    &lt;span class=&quot;dt&quot;&gt;now =&lt;/span&gt; today, &lt;span class=&quot;dt&quot;&gt;when =&lt;/span&gt; nowcastDates, &lt;span class=&quot;dt&quot;&gt;data =&lt;/span&gt; linelist,
    &lt;span class=&quot;dt&quot;&gt;dEventCol =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;Date.of.symptoms.onset&amp;quot;&lt;/span&gt;,
    &lt;span class=&quot;dt&quot;&gt;dReportCol =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;Date.of.notification.to.WHO&amp;quot;&lt;/span&gt;,
    &lt;span class=&quot;dt&quot;&gt;method =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;bayes.trunc&amp;quot;&lt;/span&gt;,
    &lt;span class=&quot;dt&quot;&gt;aggregate.by =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;1 day&amp;quot;&lt;/span&gt;,
    &lt;span class=&quot;dt&quot;&gt;D =&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;14&lt;/span&gt;,
    &lt;span class=&quot;dt&quot;&gt;m =&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;14&lt;/span&gt;, ##moving window of 14+1 days for estimation
    &lt;span class=&quot;dt&quot;&gt;control =&lt;/span&gt; nc.control)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We will use the &lt;code&gt;animation&lt;/code&gt; package to wrap the call to &lt;code&gt;animate_nowcasts&lt;/code&gt; in order to generate an animated GIF. Better control over the obtained animation can be obtained using the &lt;code&gt;animation::saveHTML&lt;/code&gt; function. If one wants to include the animation into a Power-Point presentation, I recommend the use of Flash animations (&lt;code&gt;animation::saveSWF&lt;/code&gt;). Note that the animation package requires &lt;a href=&quot;http://www.imagemagick.org/script/index.php&quot;&gt;ImageMagick&lt;/a&gt; to be installed on your system.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;animation::&lt;span class=&quot;kw&quot;&gt;saveGIF&lt;/span&gt;( {
  &lt;span class=&quot;kw&quot;&gt;par&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;mar=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;fl&quot;&gt;5.5&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;4&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;) +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.1&lt;/span&gt;) ; ##add extra space at the bottom and remove at top
  &lt;span class=&quot;kw&quot;&gt;animate_nowcasts&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;nowcasts =&lt;/span&gt; nowcasts,
                   &lt;span class=&quot;dt&quot;&gt;linelist_truth =&lt;/span&gt; linelist,
                   &lt;span class=&quot;dt&quot;&gt;method =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;bayes.trunc&amp;quot;&lt;/span&gt;, &lt;span class=&quot;co&quot;&gt;#nowcast method to use (has to be in the casts)&lt;/span&gt;
                   &lt;span class=&quot;dt&quot;&gt;control =&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;sys.sleep=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;dRange=&lt;/span&gt;nc.control$dRange,&lt;span class=&quot;dt&quot;&gt;anim.dRange=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;range&lt;/span&gt;(animRange),&lt;span class=&quot;dt&quot;&gt;ylim=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;40&lt;/span&gt;))) },
  &lt;span class=&quot;dt&quot;&gt;movie.name=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;animate-nowcasts.gif&amp;quot;&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;ani.width=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;800&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;ani.height=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;500&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-07-19-nowCast/animate-nowcasts.gif&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;As a final comparison we can also obtain an animation of how the delay distribution changes with time. From the animation we notice that the delay appears to steadily decrease, which is a typical behavior for high-profiled outbreaks. However, this also seriously questions the assumption of a &lt;strong&gt;time-invariant delay distribution&lt;/strong&gt;. Instead, one could use a window-limited estimation approach or one could try to model the delay distribution using a discrete time survival model as done in &lt;span class=&quot;citation&quot; data-cites=&quot;hoehle_anderheiden2014&quot;&gt;Höhle and an der Heiden (2014)&lt;/span&gt;.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;animation::&lt;span class=&quot;kw&quot;&gt;saveGIF&lt;/span&gt;(
  for (i in &lt;span class=&quot;kw&quot;&gt;seq_len&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;length&lt;/span&gt;(nowcasts))) {
    &lt;span class=&quot;kw&quot;&gt;plot&lt;/span&gt;(nowcasts[[i]], &lt;span class=&quot;dt&quot;&gt;w=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;type=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;delay&amp;quot;&lt;/span&gt;)
  },
  &lt;span class=&quot;dt&quot;&gt;movie.name=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;animate-delays.gif&amp;quot;&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;ani.width=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;800&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;ani.height=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;500&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-07-19-nowCast/animate-delays.gif&quot; /&gt;
&lt;/figure&gt;
&lt;h1 id=&quot;discussion&quot;&gt;Discussion&lt;/h1&gt;
&lt;p&gt;The adjustment of occurred-but-not-yet-reported-events applies to many other application areas besides &lt;strong&gt;real-time public health monitoring&lt;/strong&gt;. For example, direct links to claims reserve modelling in actuarial sciences exist, but many other areas of application, where delays play a role, appear of interest. For the methodological details of the nowcasting procedures see &lt;span class=&quot;citation&quot; data-cites=&quot;hoehle_anderheiden2014&quot;&gt;Höhle and an der Heiden (2014)&lt;/span&gt;, which is available as open access document. The present blog entry focused on getting methods operational using R.&lt;/p&gt;
&lt;h1 id=&quot;references&quot; class=&quot;unnumbered&quot;&gt;References&lt;/h1&gt;
&lt;div id=&quot;refs&quot; class=&quot;references&quot;&gt;
&lt;div id=&quot;ref-hoehle_anderheiden2014&quot;&gt;
&lt;p&gt;Höhle, M., and M. an der Heiden. 2014. “Bayesian Nowcasting During the STEC O104:H4 Outbreak in Germany, 2011.” &lt;em&gt;Biometrics&lt;/em&gt; 70 (4): 993–1002. doi:&lt;a href=&quot;https://doi.org/10.1111/biom.12194&quot;&gt;10.1111/biom.12194&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-salmon_etal2016a&quot;&gt;
&lt;p&gt;Salmon, M., D. Schumacher, and M. Höhle. 2016. “Monitoring Count Time Series in R: Aberration Detection in Public Health Surveillance.” &lt;em&gt;Journal of Statistical Software&lt;/em&gt; 70 (10). doi:&lt;a href=&quot;https://doi.org/10.18637/jss.v070.i10&quot;&gt;10.18637/jss.v070.i10&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
        <pubDate>Tue, 19 Jul 2016 00:00:00 +0200</pubDate>
        <link>http://staff.math.su.se/hoehle/blog/2016/07/19/nowCast.html</link>
        <guid isPermaLink="true">http://staff.math.su.se/hoehle/blog/2016/07/19/nowCast.html</guid>
        
        <category>math</category>
        
        <category>rstats</category>
        
        <category>surveillance</category>
        
        <category>open data</category>
        
        <category>MERS</category>
        
        
      </item>
    
      <item>
        <title>Princes Disguised in Uniforms</title>
        <description>&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;We revisit the &lt;strong&gt;secretary problem&lt;/strong&gt; as a mathematical fairy tale: Princes wooing a princess sequentially arrive each having a qualification score originating from a known parametric distribution with all parameters known, e.g., the standard uniform distribution or the normal distribution with known mean and variance. For this so called &lt;strong&gt;full information game&lt;/strong&gt; the question of interest is: How does the optimal strategy look, which maximizes the expected score of the selected candidate? As a further twist: How does the strategy change, if we sequentially have to estimate the parameters of the distribution alongside? The later variant is called the &lt;strong&gt;partial information game&lt;/strong&gt; and is nicely addressed using sequential Bayesian updating.&lt;/p&gt;
&lt;p&gt;&lt;br&gt; &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width:0&quot; src=&quot;https://i.creativecommons.org/l/by-sa/4.0/88x31.png&quot;/&gt;&lt;/a&gt; This work is licensed under a &lt;a rel=&quot;license&quot;
href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt;. The markdown+Rknitr source code of this blog is available under a &lt;a href=&quot;https://www.gnu.org/licenses/gpl-3.0.html&quot;&gt;GNU General Public License (GPL v3)&lt;/a&gt; license from &lt;a href=&quot;https://github.com/hoehleatsu/hoehleatsu.github.io&quot;&gt;&lt;img src=&quot;/hoehle/blog/images/GitHub-Mark-32px.png&quot; alt=&quot;github&quot; /&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;In the last blog post &lt;a href=&quot;../12/optimalChoice.html&quot;&gt;&lt;em&gt;Optimal Choice - Mathematical Advice for Real Life&lt;/em&gt;&lt;/a&gt; our interest was in determining a strategy to select the overall best candidate from a sequence of &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; candidates (e.g. princes, job candidates, houses, bids or tinder profiles) arriving sequentially. It was shown that the optimal strategy is to screen a number of candidates &lt;span class=&quot;math inline&quot;&gt;\(r-1\)&lt;/span&gt; in order to form a baseline and then, starting from the &lt;span class=&quot;math inline&quot;&gt;\(r\)&lt;/span&gt;&#39;th candidate, select the first candidate better than the baseline. If no candidate was chosen before the &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt;&#39;th candidate this last candidate has to be selected no matter what. The natural phenomena of getting &lt;em&gt;desperate towards the end&lt;/em&gt; was observed, if the objective of finding &lt;em&gt;the&lt;/em&gt; best is changed to maximizing the expected rank of the selected candidate.&lt;/p&gt;
&lt;p&gt;In this blog post we study the situation, where additional information about the absolute score of the candidates (instead of just their relative ranks) is available. In particular we assume that the candidate scores are known to originate from a known &lt;strong&gt;underlying distribution&lt;/strong&gt;, e.g. the uniform or the standard normal. This means that not only the underlying parametric family of the scores are known, but also the parameters of the distribution. In what follows we use the work of &lt;span class=&quot;citation&quot; data-cites=&quot;guttman1960&quot;&gt;Guttman (1960)&lt;/span&gt; to describe the problem in mathematical notation and discuss solution strategies. Then we move on to the work of &lt;span class=&quot;citation&quot; data-cites=&quot;stewart1978&quot;&gt;Stewart (1978)&lt;/span&gt; in order to investigate how the strategy changes, if we also have to simultaneously estimate the parameters of the distribution alongside. &lt;a href=&quot;https://www.r-project.org/&quot;&gt;&lt;strong&gt;R code&lt;/strong&gt;&lt;/a&gt; implementing the optimal strategies is provided for both situations in order to enable prudent decision support for real-life problems.&lt;/p&gt;
&lt;h1 id=&quot;methods&quot;&gt;Methods&lt;/h1&gt;
&lt;p&gt;Let the &lt;strong&gt;score&lt;/strong&gt; of a candidate be represented by a random variable &lt;span class=&quot;math inline&quot;&gt;\(X\)&lt;/span&gt; with continuous probability density function &lt;span class=&quot;math inline&quot;&gt;\(f\)&lt;/span&gt; having support on &lt;span class=&quot;math inline&quot;&gt;\((a,b)\)&lt;/span&gt;, where &lt;span class=&quot;math inline&quot;&gt;\(a&amp;lt;b\)&lt;/span&gt;. Note that &lt;span class=&quot;math inline&quot;&gt;\(a\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(b\)&lt;/span&gt; are allowed to be &lt;span class=&quot;math inline&quot;&gt;\(\pm \infty\)&lt;/span&gt;, respectively. Let &lt;span class=&quot;math inline&quot;&gt;\(F\)&lt;/span&gt; be the corresponding cumulative distribution of the score. Furthermore, let &lt;span class=&quot;math inline&quot;&gt;\(\mu=E(X)=\int_{a}^b x \cdot f(x) dx\)&lt;/span&gt; be the expectation of &lt;span class=&quot;math inline&quot;&gt;\(X\)&lt;/span&gt;. In what follows we will assume that the distribution is such that the expectation exists. Assuming a total of &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; candidates, we ascertain that their abilities/scores are independently and identically sampled from this distribution, i.e.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
X_1,\ldots,X_n \stackrel{\text{iid}}{\sim} F.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; candidates arrive sequentially and for each candidate one has to decide whether to select this candidate or to keep looking at further candidates. Once a candidate is rejected there is no opportunity to regret this choice later.&lt;/p&gt;
&lt;p&gt;Now we denote by &lt;span class=&quot;math inline&quot;&gt;\(E_{n}\)&lt;/span&gt; the expected score of the chosen candidate when one has to choose among &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; candidates according to some pre-described strategy. It is immediately obvious that &lt;span class=&quot;math inline&quot;&gt;\(E_1=\mu\)&lt;/span&gt;. If there are &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; candidates we would like to find the optimal stopping rule maximizing &lt;span class=&quot;math inline&quot;&gt;\(E_n\)&lt;/span&gt;. The standard stopping rule based on the expectation implies that we would already stop at the first candidate, if the observed value &lt;span class=&quot;math inline&quot;&gt;\(x\)&lt;/span&gt; is such that &lt;span class=&quot;math inline&quot;&gt;\(x &amp;gt; E_{n-1}\)&lt;/span&gt;. As a consequence,&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
\begin{align*}
E_{n+1} &amp;amp;= P(X &amp;gt; E_n) \cdot E(X\&amp;gt;|\&amp;gt;X \geq E_n)  +
P(X \leq E_n) \cdot E_n \\
%&amp;amp;= \int_{E_n}^b x \cdot f(x) dx + E_n \int_{a}^{E_n} f(x) dx \\
&amp;amp;= \int_{E_n}^b x \cdot f(x) dx + E_n \cdot (1-F(E_n)).
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;A function to perform these computations in R handling either general densities using numeric integration or analytic derivations would be:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;######################################################################
##Compute E vector using either numerical integration, a function for
##the computation of E[n+1] or using the analytic solution of
##\int_{E_n}^b x df(x) dx.
##
## Parameters:
##  n - number of candidates
##  df - density function of the score distribution (i.e. f)
##  pf - cumulative density function of the score distribution (i.e. F)
##  intE_fun - function g(E_n) = \int_{E_n}^b x*f(x)dx (if available)
##  Enp1_fun - function h(n,E_n) directly computing E_{n+1} from E_{n}
##
## Returns a vector of length (n+1) containing (E_0,...,E_n)&amp;#39;.
######################################################################
compute_E &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(n,df,pf,&lt;span class=&quot;dt&quot;&gt;intE_fun=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;NULL&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;Enp1_fun=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;NULL&lt;/span&gt;,...) {
  E &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;rep&lt;/span&gt;(&lt;span class=&quot;ot&quot;&gt;NA&lt;/span&gt;,n&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;)
  E[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;] &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;
  target &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(x) x*&lt;span class=&quot;kw&quot;&gt;df&lt;/span&gt;(x,...)

  for (n in &lt;span class=&quot;kw&quot;&gt;seq_len&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;length&lt;/span&gt;(E)-&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)) {
    if (&lt;span class=&quot;kw&quot;&gt;is.null&lt;/span&gt;(Enp1_fun)) {
      if (&lt;span class=&quot;kw&quot;&gt;is.null&lt;/span&gt;(intE_fun)) {
        E[n&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;] &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;integrate&lt;/span&gt;(target,E[n],&lt;span class=&quot;ot&quot;&gt;Inf&lt;/span&gt;)$value +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;E[n] *&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;pf&lt;/span&gt;(E[n],...)
      } else {
        E[n&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;] &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;intE_fun&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;En=&lt;/span&gt;E[n]) +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;E[n] *&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;pf&lt;/span&gt;(E[n],...)
      }
    } else {
      E[n&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;] &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;Enp1_fun&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;n,&lt;span class=&quot;dt&quot;&gt;En=&lt;/span&gt;E[n],...)
    }
  }
  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt;(E)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Altogether, the optimal stopping time is thus&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
T_{\text{stop}} = \min_{1\leq i \leq n} \left\{x_i &amp;gt; E_{n-i}\right\}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The sequential comparisons can be given in the same strategy vector format as for the &lt;a href=&quot;../12/optimalChoice.html&quot;&gt;secretary problem post&lt;/a&gt;, i.e. one selects the candidate &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt; if &lt;span class=&quot;math inline&quot;&gt;\(x_i&amp;gt;s_i\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;######################################################################
## Strategy of full information variant of the secretary problem
##
## Parameters:
##  n - number of candidates
######################################################################

strategy_fip &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(n,df,pf,&lt;span class=&quot;dt&quot;&gt;intE_fun=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;NULL&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;Enp1_fun=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;NULL&lt;/span&gt;,...) {
  E &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;compute_E&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;n,&lt;span class=&quot;dt&quot;&gt;df=&lt;/span&gt;df,&lt;span class=&quot;dt&quot;&gt;pf=&lt;/span&gt;pf,&lt;span class=&quot;dt&quot;&gt;intE_fun=&lt;/span&gt;intE_fun,&lt;span class=&quot;dt&quot;&gt;Enp1_fun=&lt;/span&gt;Enp1_fun,...)
  s &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;E[(n&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;:n)+&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;]
  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt;(s)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id=&quot;example-u01&quot;&gt;Example: U(0,1)&lt;/h4&gt;
&lt;p&gt;Example: In the case of &lt;span class=&quot;math inline&quot;&gt;\(X\sim U(0,1)\)&lt;/span&gt; we can analytically compute &lt;span class=&quot;math display&quot;&gt;\[
E_{n+1}=\frac{1}{2}(1-E_n^2) + E_n^2 =\frac{1}{2}(1+E_n^2).
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Given this setup, an R implementation of the strategy with, say, &lt;span class=&quot;math inline&quot;&gt;\(n=11\)&lt;/span&gt; looks as follows.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;strategy_unif &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(n) {
  &lt;span class=&quot;kw&quot;&gt;strategy_fip&lt;/span&gt;(n,&lt;span class=&quot;dt&quot;&gt;Enp1_fun=&lt;/span&gt;function(n,En) {&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;/&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;*(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;+En^&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;)})
}
(s_unif &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;strategy_unif&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;11&lt;/span&gt;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 0.861 0.850 0.836 0.820 0.800 0.775 0.742 0.695 0.625 0.500 0.000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can thus compare the computed expectations by simulation:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;## Simulate selection from n candidates if following the strategy s.
simulate &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(n,s) {
  x &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;runif&lt;/span&gt;(n)
  select_idx &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;which.max&lt;/span&gt;(x &amp;gt;&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;s)
  &lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;score=&lt;/span&gt;x[select_idx],&lt;span class=&quot;dt&quot;&gt;select_idx=&lt;/span&gt;select_idx,&lt;span class=&quot;dt&quot;&gt;isOverallBest=&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;rank&lt;/span&gt;(x)[select_idx] ==&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;n))
}

## Small simulation study to get expected score of the selected candidate
res &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;replicate&lt;/span&gt;(&lt;span class=&quot;fl&quot;&gt;1e5&lt;/span&gt;,&lt;span class=&quot;kw&quot;&gt;simulate&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;length&lt;/span&gt;(s_unif),&lt;span class=&quot;dt&quot;&gt;s=&lt;/span&gt;s_unif))
&lt;span class=&quot;kw&quot;&gt;apply&lt;/span&gt;(res,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,mean)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##         score    select_idx isOverallBest 
##         0.870         4.964         0.529&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;tail&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;compute_E&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;11&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;Enp1_fun=&lt;/span&gt;function(n,En) {&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;/&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;*(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;+En^&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;)}),&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.871&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As always, an animation says more than 1000 words and a few equations:&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-06-19-princesAsUniforms/animation.gif&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;Finally, we can see how the expected score develops with increasing &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt;.&lt;/p&gt;
&lt;center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&quot;header&quot;&gt;
&lt;th style=&quot;text-align: left;&quot;&gt;&lt;/th&gt;
&lt;th style=&quot;text-align: right;&quot;&gt;10&lt;/th&gt;
&lt;th style=&quot;text-align: right;&quot;&gt;100&lt;/th&gt;
&lt;th style=&quot;text-align: right;&quot;&gt;1000&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;score&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.862&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.981&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.998&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;select_idx&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;4.589&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;34.943&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;333.724&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;isOverallBest&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.544&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.426&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.409&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/center&gt;
&lt;p&gt;&lt;span class=&quot;citation&quot; data-cites=&quot;gilbert_mosteller1966&quot;&gt;Gilbert and Mosteller (1966)&lt;/span&gt; provide an approximation for the expectation:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;E_optE &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(n) { &lt;span class=&quot;dv&quot;&gt;1-2&lt;/span&gt;/(n+&lt;span class=&quot;kw&quot;&gt;log&lt;/span&gt;(n&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;)+&lt;span class=&quot;fl&quot;&gt;1.767&lt;/span&gt;) }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;which we can compare the &lt;code&gt;score&lt;/code&gt;column of the above simulation results:&lt;/p&gt;
&lt;center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&quot;header&quot;&gt;
&lt;th style=&quot;text-align: right;&quot;&gt;10&lt;/th&gt;
&lt;th style=&quot;text-align: right;&quot;&gt;100&lt;/th&gt;
&lt;th style=&quot;text-align: right;&quot;&gt;1000&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.859&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.981&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.998&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/center&gt;
&lt;p&gt;Altogether, this shows a pretty good agreement between the approximation and simulation results.&lt;/p&gt;
&lt;h4 id=&quot;example-n01&quot;&gt;Example N(0,1)&lt;/h4&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;## Compare results for the normal distribution (with and without
## analytic solution for 1st integral of the E[n+1] formula
&lt;span class=&quot;kw&quot;&gt;strategy_fip&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;11&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;df=&lt;/span&gt;dnorm,&lt;span class=&quot;dt&quot;&gt;pf=&lt;/span&gt;pnorm)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 1.324 1.276 1.223 1.162 1.092 1.011 0.913 0.790 0.630 0.399 0.000&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;(s_norm &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;strategy_fip&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;11&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;df=&lt;/span&gt;dnorm,&lt;span class=&quot;dt&quot;&gt;pf=&lt;/span&gt;pnorm,&lt;span class=&quot;dt&quot;&gt;intE_fun=&lt;/span&gt;function(En,...) {
  &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;/&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;*&lt;span class=&quot;kw&quot;&gt;sqrt&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;)*&lt;span class=&quot;kw&quot;&gt;exp&lt;/span&gt;(-&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;/&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;*En^&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;)/&lt;span class=&quot;kw&quot;&gt;sqrt&lt;/span&gt;(pi)
}))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 1.324 1.276 1.223 1.162 1.092 1.011 0.913 0.790 0.630 0.399 0.000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that by transforming the observations by the CDF &lt;span class=&quot;math inline&quot;&gt;\(F\)&lt;/span&gt;, i.e. &lt;span class=&quot;math inline&quot;&gt;\(Y_i=F(X_i)\)&lt;/span&gt; we for any continuous distribution obtain &lt;span class=&quot;math inline&quot;&gt;\(Y_i \stackrel{\text{iid}}{\sim} U(0,1)\)&lt;/span&gt;. Hence, the result of comparing the &lt;span class=&quot;math inline&quot;&gt;\(X_i\)&lt;/span&gt; against &lt;code&gt;s_norm&lt;/code&gt; is the same as comparing &lt;span class=&quot;math inline&quot;&gt;\(F(X_i)\)&lt;/span&gt; against &lt;code&gt;s_unif&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;set.seed&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)
x &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;rnorm&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;11&lt;/span&gt;) ; y &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;pnorm&lt;/span&gt;(x)
&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;which.max&lt;/span&gt;(x &amp;gt;&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;s_norm), &lt;span class=&quot;kw&quot;&gt;which.max&lt;/span&gt;(y &amp;gt;&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;s_unif))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## [1] 4 4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is thus not necessary to derive the optimal strategy for each possible continuous distribution. Instead one can transform the score to the uniform score as illustrated above and then use the corresponding strategy for the uniform to determine the stopping time.&lt;/p&gt;
&lt;h1 id=&quot;the-partial-information-game&quot;&gt;The Partial Information Game&lt;/h1&gt;
&lt;p&gt;To summarise the previous section&#39;s findings: knowing the candidate&#39;s score distribution means that no training sample is needed to form a baseline. Hence, in the full information game, one immediately is &lt;em&gt;ready for action&lt;/em&gt;: if a candidate with an excellent score is met early you do not hesitate! However, in a real word applications the parameters of the parametric distribution are likely to be unknown. This is known as the &lt;strong&gt;partial information game&lt;/strong&gt; and here statistical inference actually for the first time plays a role, because one needs to learn about the parameters of the distribution while candidates arrive and while simultaneously deciding to select the current candidate or keep looking.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;citation&quot; data-cites=&quot;stewart1978&quot;&gt;Stewart (1978)&lt;/span&gt; discusses a Bayesian approach to sequential learning the upper and lower limits of the underlying but unknown &lt;span class=&quot;math inline&quot;&gt;\(U(\alpha,\beta)\)&lt;/span&gt; distribution. Inspired by &lt;span class=&quot;citation&quot; data-cites=&quot;degroot1970&quot;&gt;DeGroot (1970)&lt;/span&gt;, a conjugate bilateral bivariate Pareto distribution on &lt;span class=&quot;math inline&quot;&gt;\((\alpha,\beta)\)&lt;/span&gt; is used. In what follows we describe this approach and the resulting selection strategy.&lt;/p&gt;
&lt;p&gt;We will assume a bilateral bivariate Pareto distribution as joint prior distribution for &lt;span class=&quot;math inline&quot;&gt;\(\alpha\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(\beta\)&lt;/span&gt;, i.e. the hierarchical Bayesian model is&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
\begin{align*}
(\alpha,\beta)                                &amp;amp; \sim \text{bPar}(k,l,u) \\
X_i \&amp;gt;|\&amp;gt; \alpha,\beta &amp;amp; \stackrel{\text{iid}}{\sim}   U(\alpha,\beta), &amp;amp; i=1,\ldots,n,
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where the density of the &lt;span class=&quot;math inline&quot;&gt;\(\text{bPar}(k,l,u)\)&lt;/span&gt; distribution is &lt;span class=&quot;math display&quot;&gt;\[
f(\alpha,\beta) = \frac{k(k+1)(u-l)^k}{(\beta-\alpha)^{k+2}} \cdot
I(\alpha&amp;lt;l \text{ and } \beta &amp;gt; u).
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Here, &lt;span class=&quot;math inline&quot;&gt;\(k&amp;gt;0\)&lt;/span&gt; is a shape parameter and &lt;span class=&quot;math inline&quot;&gt;\(I(\&amp;gt;)\)&lt;/span&gt; denotes the indicator function. In other words, the parameter &lt;span class=&quot;math inline&quot;&gt;\(l\)&lt;/span&gt; is an upper bound for the lower limit of the uniform (i.e. &lt;span class=&quot;math inline&quot;&gt;\(\alpha\)&lt;/span&gt;), and the parameter &lt;span class=&quot;math inline&quot;&gt;\(u\)&lt;/span&gt; is a lower limit for the upper limit of the uniform (i.e. &lt;span class=&quot;math inline&quot;&gt;\(\beta\)&lt;/span&gt;). We can think of &lt;span class=&quot;math inline&quot;&gt;\((-\infty,l)\)&lt;/span&gt; as our prior interval for the worst possible candidate applying and &lt;span class=&quot;math inline&quot;&gt;\((u,\infty)\)&lt;/span&gt; as our prior interval for the best possible candidate. The shape parameter &lt;span class=&quot;math inline&quot;&gt;\(k\)&lt;/span&gt; denotes how concentrated the prior density is near the limits &lt;span class=&quot;math inline&quot;&gt;\(l\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(u\)&lt;/span&gt;, respectively.&lt;/p&gt;
&lt;p&gt;In the example: the princess may think entitlements and the cool future title (king) ensures that the worst possible prince up for wooing her would at least be a five. Similarly, the lower bound on the upper limit means that the princess initially thinks that due to her stingy dad (the current king) the best overall applicant might, in worst case, just be about a seven. Finally, the parameter &lt;span class=&quot;math inline&quot;&gt;\(k\)&lt;/span&gt; quantifies the strength in her prior belief - the higher &lt;span class=&quot;math inline&quot;&gt;\(k\)&lt;/span&gt; the closer the true limits are to the values of &lt;span class=&quot;math inline&quot;&gt;\(l\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(u\)&lt;/span&gt;. Since the princess is unsure how well her prior is suited, she assumes a low value of &lt;span class=&quot;math inline&quot;&gt;\(k\)&lt;/span&gt;, say, &lt;span class=&quot;math inline&quot;&gt;\(k=0.1\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;#################################################
&lt;span class=&quot;co&quot;&gt;# Joint bilateral Pareto prior&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# Parameters:&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#  theta - vector length two containing (alpha,beta)&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#  k     - parameter&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#  l     - upper bound for alpha (i.e. an upper bound for the true lower bound)&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#  u     - lower for beta (i.e. a lower bound for the true upper bound)&lt;/span&gt;
################################################

f_pareto &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(theta,k,l,u) {
  if (&lt;span class=&quot;kw&quot;&gt;is.matrix&lt;/span&gt;(theta)) {
    alpha &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;theta[,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;] ; beta &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;theta[,&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;]
  } else {
    alpha &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;theta[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;]  ; beta &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;theta[&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;]
  }

  &lt;span class=&quot;co&quot;&gt;#Compute PDF&lt;/span&gt;
 &lt;span class=&quot;kw&quot;&gt;ifelse&lt;/span&gt;(alpha &amp;lt;&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;l &amp;amp;&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;beta &amp;gt;&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;u,
        k*(k&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;)*(u -&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;l)^k /&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;(beta-alpha)^(k&lt;span class=&quot;dv&quot;&gt;+2&lt;/span&gt;), &lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We illustrate the prior setting consisting of &lt;span class=&quot;math inline&quot;&gt;\(l=5\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(u=7\)&lt;/span&gt; and the two values &lt;span class=&quot;math inline&quot;&gt;\(k=0.1\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(k=1\)&lt;/span&gt;:&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-06-19-princesAsUniforms/PARETO_PDF-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;And the marginal density for two slices of the above joint density is:&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-06-19-princesAsUniforms/PDF_PARETO_MARGINAL-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;An important feature of this bivariate Pareto prior is that it is the conjugate prior to uniform sampling &lt;span class=&quot;citation&quot; data-cites=&quot;degroot1970&quot;&gt;(DeGroot 1970)&lt;/span&gt;. In other words, if &lt;span class=&quot;math inline&quot;&gt;\((\alpha,\beta) \sim \text{bPar}(k,l_0,u_0)\)&lt;/span&gt; and observations &lt;span class=&quot;math inline&quot;&gt;\(X_1,\ldots,X_i \stackrel{\text{iid}}{\sim} U(\alpha,\beta)\)&lt;/span&gt; become available, then the posterior distribution of interest is&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
(\alpha,\beta)&amp;#39; \&amp;gt;|\&amp;gt; X_1,\ldots,X_i \sim \text{bPar}(k+i,l_i,u_i),
\]&lt;/span&gt; where &lt;span class=&quot;math display&quot;&gt;\[
\begin{align*}
l_i &amp;amp;= \min(l_0,x_1,\ldots,x_i), \\
u_i &amp;amp;= \max(u_0,x_1,\ldots,x_i).
\end{align*}
\]&lt;/span&gt; In other words, the posterior depends only on &lt;span class=&quot;math inline&quot;&gt;\(l_i\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(u_i\)&lt;/span&gt; and not the individual &lt;span class=&quot;math inline&quot;&gt;\(x_i\)&lt;/span&gt;&#39;s. Let &lt;span class=&quot;math inline&quot;&gt;\(\gamma_i\)&lt;/span&gt; be the obtained score, if we at stage &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt; select the &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt;&#39;th candidate. Furthermore, using the same expectation definition as in the previous section, let &lt;span class=&quot;math inline&quot;&gt;\(E_i\)&lt;/span&gt; be the expected score obtained by following a particular strategy from the &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt;&#39;th candidate to the &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt;&#39;th candidate.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
\begin{align*}
\gamma_n &amp;amp;= x_n \\
E_i      &amp;amp;= E(\gamma_i | x_1,\ldots, x_{i-1}), &amp;amp; i \leq n, \\
\gamma_i &amp;amp;= \max(x_i, E_{i+1}),                  &amp;amp; i &amp;lt; n.
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;citation&quot; data-cites=&quot;stewart1978&quot;&gt;Stewart (1978)&lt;/span&gt; then shows that the optimal strategy is found by the following approach, which we here for simplicity shall program directly in R:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;## Small helper function to convert between index 0 and R&amp;#39;s index 1 storing
idx &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(i) i&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;

## Compute delta vector, which is a helper-vector in the solution of Stewart (1978)
compute_delta &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(n, k) {
  &lt;span class=&quot;co&quot;&gt;#Define delta&amp;#39;s&lt;/span&gt;
  delta &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;rep&lt;/span&gt;(&lt;span class=&quot;ot&quot;&gt;NA&lt;/span&gt;,n&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;)
  delta[&lt;span class=&quot;kw&quot;&gt;idx&lt;/span&gt;(n&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;)] =&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;/&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;

  for (i in &lt;span class=&quot;kw&quot;&gt;rev&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;seq_len&lt;/span&gt;(n&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;))) {
    if (delta[&lt;span class=&quot;kw&quot;&gt;idx&lt;/span&gt;(i)]&amp;gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;) {
      delta[&lt;span class=&quot;kw&quot;&gt;idx&lt;/span&gt;(i&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;)] &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;delta[&lt;span class=&quot;kw&quot;&gt;idx&lt;/span&gt;(i)]
    } else {
      delta[&lt;span class=&quot;kw&quot;&gt;idx&lt;/span&gt;(i&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;)] &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;/&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;*(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;+(k+i&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;)/(k+i&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;)*delta[&lt;span class=&quot;kw&quot;&gt;idx&lt;/span&gt;(i)]^&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;) +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;(k+i&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;)*delta[&lt;span class=&quot;kw&quot;&gt;idx&lt;/span&gt;(i)]/(k+i&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;)/(k+i&lt;span class=&quot;dv&quot;&gt;-2&lt;/span&gt;)
    }
  }

  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt;(delta)
}

###############################################################
## Bayesian sequential learning for a sequence of scores using the
## procedure described in Stewart (1978)
##
## Parameters:
##  x - vector of candidate scores (scores are only revealed sequentially)
##  prior - list containing prior values for k, l and u
###############################################################

strategy_pig &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(x, prior) {
  &lt;span class=&quot;co&quot;&gt;#Extract and precompute&lt;/span&gt;
  n &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;length&lt;/span&gt;(x)
  delta &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;compute_delta&lt;/span&gt;(n,&lt;span class=&quot;dt&quot;&gt;k=&lt;/span&gt;prior$k)

  &lt;span class=&quot;co&quot;&gt;#Generate data_frame to work on&lt;/span&gt;
  seq &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;data_frame&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;i=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;kw&quot;&gt;seq_len&lt;/span&gt;(n&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;)),&lt;span class=&quot;dt&quot;&gt;x=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;ot&quot;&gt;NA&lt;/span&gt;,x,&lt;span class=&quot;ot&quot;&gt;NA&lt;/span&gt;), &lt;span class=&quot;dt&quot;&gt;delta=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(delta,&lt;span class=&quot;ot&quot;&gt;NA&lt;/span&gt;))

  &lt;span class=&quot;co&quot;&gt;#Sequential updating of l and u from the data&lt;/span&gt;
  l &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;cummin&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(prior$l,x))
  u &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;cummax&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(prior$u,x))
  seq &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;seq %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;mutate&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;l=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(l,l[n]),&lt;span class=&quot;dt&quot;&gt;u=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(u,u[n]),&lt;span class=&quot;dt&quot;&gt;im1div2=&lt;/span&gt;i&lt;span class=&quot;fl&quot;&gt;-0.5&lt;/span&gt;)

  ##Compute expectation
  seq &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;seq %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;mutate&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;E=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;lag&lt;/span&gt;(delta)*&lt;span class=&quot;kw&quot;&gt;lag&lt;/span&gt;(u) +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;-&lt;span class=&quot;kw&quot;&gt;lag&lt;/span&gt;(delta))*&lt;span class=&quot;kw&quot;&gt;lag&lt;/span&gt;(l))
  ##Decision boundary
  seq &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;seq %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;mutate&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;threshold=&lt;/span&gt;delta*u +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;-delta)*l, &lt;span class=&quot;dt&quot;&gt;rank=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;rank&lt;/span&gt;(x),&lt;span class=&quot;dt&quot;&gt;isOverallBest=&lt;/span&gt;(rank ==&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;n))

  &lt;span class=&quot;co&quot;&gt;#Ensure that last candidate is always taken&lt;/span&gt;
  seq[n&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;:&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;&amp;quot;threshold&amp;quot;&lt;/span&gt;] &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;min&lt;/span&gt;(x)

  ##Find r_1 and return there characteristics
  r1 &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;seq %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;filter&lt;/span&gt;(delta &amp;lt;=&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt; &amp;amp;&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;i &amp;lt;&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;n &amp;amp;&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;i &amp;gt;&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;max&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;-prior$k)) %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;slice&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;) %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt;(i) %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;as.numeric
  select &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;seq %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;filter&lt;/span&gt;(i &amp;gt;=&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;r1) %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;filter&lt;/span&gt;(x &amp;gt;=&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;threshold) %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;slice&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)
  
  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;seq=&lt;/span&gt;seq,&lt;span class=&quot;dt&quot;&gt;select=&lt;/span&gt;select))
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We now simulate a particular scenario consisting of 11 princes wooing a princess and apply the optimal selection strategy applying the princess&#39; prior:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;##Prior info
prior &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;k=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.1&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;l=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;5&lt;/span&gt;,&lt;span class=&quot;dt&quot;&gt;u=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;7&lt;/span&gt;)

##Reverse engineering a happy end! :-)
&lt;span class=&quot;co&quot;&gt;# which(sapply(1:100, function(i) {&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#   set.seed(i); x &amp;lt;- runif(n=11,0,10)&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#   s &amp;lt;- strategy_pig(x, prior=prior)&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#   as.numeric(s$select[,&amp;quot;isOverallBest&amp;quot;])&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# })==1)&lt;/span&gt;

##Sample princes from an uniform with unknown limits -- here X_i \sim U(0,10)
&lt;span class=&quot;kw&quot;&gt;set.seed&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;8&lt;/span&gt;)
x &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;runif&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;11&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;)
s &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;strategy_pig&lt;/span&gt;(x, &lt;span class=&quot;dt&quot;&gt;prior=&lt;/span&gt;prior)
s$select&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## Source: local data frame [1 x 10]
## 
##       i     x delta     l     u im1div2     E threshold  rank isOverallBest
##   (dbl) (dbl) (dbl) (dbl) (dbl)   (dbl) (dbl)     (dbl) (dbl)         (lgl)
## 1     8  9.32 0.745  2.08  9.32     7.5  6.88      7.47    11          TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;figure&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-06-19-princesAsUniforms/animation-pig.gif&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;The animation provides interesting insights: Firstly, the upper bound on the lower limit is updated along the way, because some seriously unfit candidates dare to woo. Secondly, the decision boundary is initially slightly above our lower bound on the upper limit. However, the first candidate (candidate no. 3) above this prior bound is not accepted, since it is still early in the sequence and thus little is known about the support of the uniform, i.e. the range of candidates applying. Hence, the princess hopes to get an even better candidate. However, as time passes by and no such candidate appears, the limit is slowly adjusted downwards. Luckily, the 8&#39;th candidate not only brings a score better than imagined (and is thus selected), he also (seen through the omnipotent eyes of somebody knowing all the candidates) actually is the best prince among &lt;strong&gt;all&lt;/strong&gt; the candidates, i.e. &lt;code&gt;isOverallBest=TRUE&lt;/code&gt;. In other words: our mathematical fairy tale even has a happy end!&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-06-19-princesAsUniforms/Fairytale-Fantasy-Castle-Landscape-300px.png&quot; title=&quot;Source: https://openclipart.org/detail/231006/fairytale-fantasy-castle-landscape&quot; /&gt;
&lt;/center&gt;
&lt;h1 id=&quot;discussion&quot;&gt;Discussion&lt;/h1&gt;
&lt;p&gt;The full information game provides a good baseline to see the difference between having no information but the rank of candidates and knowing the distribution of the candidate&#39;s score. More references and variants of the secretary problem can be found in &lt;span class=&quot;citation&quot; data-cites=&quot;freeman1983&quot;&gt;Freeman (1983)&lt;/span&gt;.&lt;/p&gt;
&lt;h1 id=&quot;references&quot; class=&quot;unnumbered&quot;&gt;References&lt;/h1&gt;
&lt;div id=&quot;refs&quot; class=&quot;references&quot;&gt;
&lt;div id=&quot;ref-degroot1970&quot;&gt;
&lt;p&gt;DeGroot, Morris. 1970. &lt;em&gt;Optimal Statistical Decisions&lt;/em&gt;. McGraw-Hill. New York.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-freeman1983&quot;&gt;
&lt;p&gt;Freeman, P. R. 1983. “The Secretary Problem and Its Extensions: A Review.” &lt;em&gt;International Statistical Review / Revue Internationale de Statistique&lt;/em&gt; 51 (2): 189–206. &lt;a href=&quot;http://www.jstor.org/stable/1402748&quot; class=&quot;uri&quot;&gt;http://www.jstor.org/stable/1402748&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-gilbert_mosteller1966&quot;&gt;
&lt;p&gt;Gilbert, J. P., and F. Mosteller. 1966. “Recognizing the Maximum of a Sequence.” &lt;em&gt;Journal of the American Statistical Association&lt;/em&gt; 61 (313): 35–73. &lt;a href=&quot;http://www.jstor.org/stable/2283044&quot; class=&quot;uri&quot;&gt;http://www.jstor.org/stable/2283044&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-guttman1960&quot;&gt;
&lt;p&gt;Guttman, I. 1960. “On a Problem of L. Moser.” &lt;em&gt;Canadian Mathematical Bulletin&lt;/em&gt; 3: 35–39.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-stewart1978&quot;&gt;
&lt;p&gt;Stewart, T. J. 1978. “Optimal Selection from a Random Sequence with Learning of the Underlying Distribution.” &lt;em&gt;Journal of the American Statistical Association&lt;/em&gt; 73 (364): 775–80. &lt;a href=&quot;http://www.jstor.org/stable/2286279&quot; class=&quot;uri&quot;&gt;http://www.jstor.org/stable/2286279&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
        <pubDate>Sun, 19 Jun 2016 00:00:00 +0200</pubDate>
        <link>http://staff.math.su.se/hoehle/blog/2016/06/19/princesAsUniforms.html</link>
        <guid isPermaLink="true">http://staff.math.su.se/hoehle/blog/2016/06/19/princesAsUniforms.html</guid>
        
        <category>math</category>
        
        <category>rstats</category>
        
        <category>secretary problem</category>
        
        <category>stopping rule</category>
        
        
      </item>
    
      <item>
        <title>Optimal Choice - Mathematical Advice for Real Life</title>
        <description>&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;We discuss how to choose the optimal candidate from a rankable sequence of candidates arriving one by one. The candidates could for example be job applicants, princes, tinder profiles or flats. This &lt;strong&gt;choice problem&lt;/strong&gt; is casted into the context of sequential decision making and is solved using optimal stopping theory. Two R functions are provided to compute optimal selection strategies in two specific instances of the problem. Altogether, the mathematical inclined decision maker is given valuable open-source tools to support prudent real life decision making.&lt;/p&gt;
&lt;p&gt;&lt;br&gt; &lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;&lt;img alt=&quot;Creative Commons License&quot; style=&quot;border-width:0&quot; src=&quot;https://i.creativecommons.org/l/by-sa/4.0/88x31.png&quot;/&gt;&lt;/a&gt; This work is licensed under a &lt;a rel=&quot;license&quot;
href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt;. The markdown+Rknitr source code of this blog is available under a &lt;a href=&quot;https://www.gnu.org/licenses/gpl-3.0.html&quot;&gt;GNU General Public License (GPL v3)&lt;/a&gt; license from &lt;a href=&quot;https://github.com/hoehleatsu/hoehleatsu.github.io&quot;&gt;&lt;img src=&quot;/hoehle/blog/images/GitHub-Mark-32px.png&quot; alt=&quot;github&quot; /&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Life is full of choices. The prudent &lt;a href=&quot;https://en.wikipedia.org/wiki/Decision-making&quot;&gt;decision maker&lt;/a&gt; likes to rationally balance alternatives, assess uncertain outcomes, gather additional information and - when ready - pick the best action. A mathematical approach to such decision making under uncertainty is based on maximizing an adequate utility function subject to the identified stochasticity, e.g., by maximizing expected utility. The ultimate statistical guides to such &lt;a href=&quot;https://en.wikipedia.org/wiki/Optimal_decision&quot;&gt;optimal decision making&lt;/a&gt; are the books by &lt;span class=&quot;citation&quot; data-cites=&quot;degroot1970&quot;&gt;DeGroot (1970)&lt;/span&gt; and &lt;span class=&quot;citation&quot; data-cites=&quot;berger1985&quot;&gt;Berger (1985)&lt;/span&gt;. &lt;a href=&quot;https://en.wikipedia.org/wiki/Influence_diagram&quot;&gt;Influence diagrams&lt;/a&gt; are compact representations of decision problems embedded within the graphical modelling toolset of Bayesian networks, see e.g. &lt;span class=&quot;citation&quot; data-cites=&quot;jensen_nielsen2007&quot;&gt;Jensen and Nielsen (2007)&lt;/span&gt;.&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-06-12-optimalChoice/indecisive-silhouette-300px-scaled.png&quot; title=&quot;Source: https://openclipart.org/detail/171299/indecisive-silhouettesvg&quot; /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;In this note we consider the very simple -- but entertaining -- sequential decision problem known as the optimal choice, secretary, marriage, dowry or game of googol problem &lt;span class=&quot;citation&quot; data-cites=&quot;ferguson1989&quot;&gt;(Ferguson 1989)&lt;/span&gt;. Scientific publishing about the &lt;a href=&quot;https://en.wikipedia.org/wiki/Secretary_problem&quot;&gt;&lt;strong&gt;optimal choice problem&lt;/strong&gt;&lt;/a&gt; dates back to the 1950&#39;s and 1960&#39;s, but accounts of variations of the problem date back as far as &lt;a href=&quot;https://en.wikipedia.org/wiki/Johannes_Kepler#Second_marriage&quot;&gt;1613&lt;/a&gt;. To illustrate the problem we use the process of finding a real estate property in an overheated housing market as example. Of course, the human resource manager, wooed princess, &lt;a href=&quot;http://www.npr.org/sections/krulwich/2014/05/15/312537965/how-to-marry-the-right-girl-a-mathematical-solution&quot;&gt;Johannes Kepler&lt;/a&gt;, tinder hustler as well as the mathematical enthusiast (subsets might overlap) should easily be able to adapt terminology to their needs.&lt;/p&gt;
&lt;h2 id=&quot;the-optimal-choice-problem&quot;&gt;The optimal choice problem&lt;/h2&gt;
&lt;p&gt;The rules of the game are as follows:&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;You want to choose exactly one property (say, buy a &lt;strong&gt;flat&lt;/strong&gt;) within a given period of time&lt;/li&gt;
&lt;li&gt;The number of candidate flats available on the market and inspectable in the given time period is assumed to be known. We shall denote this number by &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;The flats are assumed to be rankable from best (rank 1) to worst (rank &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt;) without ties.&lt;/li&gt;
&lt;li&gt;The flats can only be inspected sequentially and in some random order.&lt;/li&gt;
&lt;li&gt;After seeing a flat one has to decide whether to pick this flat or not.&lt;/li&gt;
&lt;li&gt;Once a flat is rejected, this choice is permanent and cannot be re-called.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Your objective is to find the &lt;em&gt;best candidate&lt;/em&gt; among the &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; flats. Less will not work for you, i.e. you have no interest in the 2nd best candidate or any other worse candidate. Furthermore, the decision you have to make at each decision time is to either select the current candidate flat or reject it and inspect futher candidate flats. Which flat to pick thus at each time point is based only on the flat&#39;s relative rank within the set of flats seen up to now. Our goal is to find a strategy s.t. we end up with the best flat, i.e. rank 1, among all of the &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; flats. Note that simply looking at all candidates and then picking the best one will not work due to rules 5 and 6.&lt;/p&gt;
&lt;h2 id=&quot;mathematical-notation&quot;&gt;Mathematical notation&lt;/h2&gt;
&lt;p&gt;Following &lt;span class=&quot;citation&quot; data-cites=&quot;chow_etal1964&quot;&gt;Chow et al. (1964)&lt;/span&gt; we introduce the following mathematical notation: Let &lt;span class=&quot;math inline&quot;&gt;\(x_1,\ldots, x_n\)&lt;/span&gt; be a permutation of the integers between 1 and &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt;. At the time we are considering the &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt;&#39;th candidate in our ordered sequence we have seen the candidates &lt;span class=&quot;math inline&quot;&gt;\(1,\ldots,i\)&lt;/span&gt;. Let &lt;span class=&quot;math inline&quot;&gt;\(y_i\)&lt;/span&gt;, &lt;span class=&quot;math inline&quot;&gt;\(y_i \in \{1,\ldots,i\}\)&lt;/span&gt;, denote the rank of the &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt;&#39;th candidate among these &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt; candidates. We call this the &lt;strong&gt;relative rank&lt;/strong&gt; at time &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt; of the &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt;&#39;th candidate. Note that the relative rank can be 1 even though a candidates&#39; &lt;strong&gt;overall rank&lt;/strong&gt; is not 1. This is a consequence of the overall rank being only partially revealed by knowing more of the candidates.&lt;/p&gt;
&lt;p&gt;A code example illustrates the concept:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;co&quot;&gt;#Generate a sequence of ranks between 1 and n&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;set.seed&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;123&lt;/span&gt;)
n &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;10L ; x &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;sample&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;:n,&lt;span class=&quot;dt&quot;&gt;replace=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;FALSE&lt;/span&gt;)

&lt;span class=&quot;co&quot;&gt;#Function to compute sequential relative ranks, where smallest is best&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#Now programmed with Rcpp, which is faster than plain R. Github code&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#contains an even faster version relrank_rcpp_novec. Note index start at 0&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#in Rcpp.&lt;/span&gt;
Rcpp::&lt;span class=&quot;kw&quot;&gt;cppFunction&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;#39;NumericVector relrank(NumericVector x) {&lt;/span&gt;
&lt;span class=&quot;st&quot;&gt;  int n = x.size();&lt;/span&gt;
&lt;span class=&quot;st&quot;&gt;  NumericVector output(n);&lt;/span&gt;
&lt;span class=&quot;st&quot;&gt;  for (int i = 0; i &amp;lt; n; ++i) {&lt;/span&gt;
&lt;span class=&quot;st&quot;&gt;     output[i] = sum(x[Range(0,i)] &amp;lt;= x[i]);&lt;/span&gt;
&lt;span class=&quot;st&quot;&gt;  }&lt;/span&gt;
&lt;span class=&quot;st&quot;&gt;  return output;&lt;/span&gt;
&lt;span class=&quot;st&quot;&gt;}&amp;#39;&lt;/span&gt;)

&lt;span class=&quot;kw&quot;&gt;rbind&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;x=&lt;/span&gt;x, &lt;span class=&quot;dt&quot;&gt;y=&lt;/span&gt;y&amp;lt;-&lt;span class=&quot;kw&quot;&gt;relrank&lt;/span&gt;(x)) &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##   [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
## x    3    8    4    7    6    1   10    9    2     5
## y    1    2    2    3    3    1    7    7    2     5&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;finding-the-best&quot;&gt;Finding the best&lt;/h2&gt;
&lt;p&gt;It is possible to show &lt;span class=&quot;citation&quot; data-cites=&quot;gilbert_mosteller1966&quot;&gt;(Gilbert and Mosteller 1966)&lt;/span&gt; that the optimal selection policy is to follow the rather intuitive procedure:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Consider the first &lt;span class=&quot;math inline&quot;&gt;\(r-1\)&lt;/span&gt; candidates without picking any of them (=&amp;quot;training sample&amp;quot;).&lt;/li&gt;
&lt;li&gt;Then select the first candidate, which is better than the best among the training sample.&lt;/li&gt;
&lt;li&gt;If no candidate has been selected by the time &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; and, hence, the last candidate is reached, one is forced to select this candidate.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Mathematically expressed the optimal stopping time is thus&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
\min_{i \in \{r,\ldots,n\}}\{y_i = 1 \text{ or } i = n\}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The question is what &lt;span class=&quot;math inline&quot;&gt;\(r\)&lt;/span&gt; to choose? &lt;span class=&quot;citation&quot; data-cites=&quot;ferguson1989&quot;&gt;Ferguson (1989)&lt;/span&gt; in equation 2.1 shows that the probability &lt;span class=&quot;math inline&quot;&gt;\(\phi_n(r)\)&lt;/span&gt; of finding the overall best rank using a value of &lt;span class=&quot;math inline&quot;&gt;\(r\)&lt;/span&gt; in the above strategy is&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
\phi_n(r) = \frac{r-1}{n} \sum_{j=r}^n \frac{1}{j-1}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;It is obvious that &lt;span class=&quot;math inline&quot;&gt;\(\phi_n(1)=1/n\)&lt;/span&gt;. The remaining probabilities can easily be computed with R:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;co&quot;&gt;#Compute probability of finding max after screening the r-1 first out of n and then&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#picking the first, which is better than the best in the training sample.&lt;/span&gt;
phi &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(r,n) {
  if (r==&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;) &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;/n)
  j &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;r:n
  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt;((&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;/n)*(r&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;)*&lt;span class=&quot;kw&quot;&gt;sum&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;/(j&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;)))
}

&lt;span class=&quot;co&quot;&gt;#Compute probabilities for all i in {1,...,n}&lt;/span&gt;
df &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;data.frame&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;i=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;:n)
df &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;df %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;rowwise&lt;/span&gt;() %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;mutate&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;phi=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;phi&lt;/span&gt;(i,n)) %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;ungroup&lt;/span&gt;()
r &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;df %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;filter&lt;/span&gt;(phi==&lt;span class=&quot;kw&quot;&gt;max&lt;/span&gt;(phi))  %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt;(i)  %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;unlist&lt;/span&gt;() %&amp;gt;%&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;as.numeric&lt;/span&gt;()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We can illustrate &lt;span class=&quot;math inline&quot;&gt;\(\phi_n(r)\)&lt;/span&gt; as a function of &lt;span class=&quot;math inline&quot;&gt;\(r\)&lt;/span&gt;:&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-06-12-optimalChoice/PHIPLOT-1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;We thus select the &lt;span class=&quot;math inline&quot;&gt;\(r\)&lt;/span&gt;, which gives the highest value of &lt;span class=&quot;math inline&quot;&gt;\(\phi_n(r)\)&lt;/span&gt;. In the example with &lt;span class=&quot;math inline&quot;&gt;\(n=10\)&lt;/span&gt; the best choice is &lt;span class=&quot;math inline&quot;&gt;\(r=4\)&lt;/span&gt;; we therefore look at &lt;span class=&quot;math inline&quot;&gt;\(r-1=3\)&lt;/span&gt; candidates in order to get a &lt;em&gt;baseline&lt;/em&gt; and then take the first candidate, which is better than this baseline. In the example:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;(pickIdx &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;which.max&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;relrank&lt;/span&gt;(x)[r:n] ==&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt; |&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;(r:n ==&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;n)))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;x[pickIdx +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;(r&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;)]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the example we thus actually manage to select the best candidate! However, this is not always guaranteed: for example, if the best overall candidate is among the training sample (4/10 chance for this to happen) we would end up with the last candidate flat no matter how good or bad it is. As stated above: the probability that the above decision strategy will pick the best candidate is &lt;span class=&quot;math inline&quot;&gt;\(\phi_{10}(4)=0.40\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;In order to compare the decision strategy with later formulations we denote by &lt;span class=&quot;math inline&quot;&gt;\(\mathbf{s}=(s_1,\ldots,s_n)\)&lt;/span&gt; a strategy which at time &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt; selects candidate &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt;, if &lt;span class=&quot;math inline&quot;&gt;\(y_i \leq s_i\)&lt;/span&gt;. In other words, the above strategy for &lt;span class=&quot;math inline&quot;&gt;\(n=10\)&lt;/span&gt; is:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;s &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;rep&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;,r&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;),&lt;span class=&quot;kw&quot;&gt;rep&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,n-(r&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;)-&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;),n)
s&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  0  0  0  1  1  1  1  1  1 10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And the selected candidate can easily found as&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;which.max&lt;/span&gt;(y &amp;lt;=&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;s)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## [1] 6&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For small &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; the optimal &lt;span class=&quot;math inline&quot;&gt;\(r\)&lt;/span&gt; and corresponding probability of success can easily be computed numerically. However, for large &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; the numerical precision as well as the computations become more tedious and hence interest is in finding a general asymptotic approximation as &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; grows large: One can show that as &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; gets large the optimal procedure is always to screen the first &lt;span class=&quot;math inline&quot;&gt;\(1/e\)&lt;/span&gt; = 37% and then select the first candidate better than the training sample &lt;span class=&quot;citation&quot; data-cites=&quot;gilbert_mosteller1966&quot;&gt;(Gilbert and Mosteller 1966)&lt;/span&gt;. The asymptotic probability of success, i.e. finding the overall best candidate, when following the such a procedure is also about &lt;span class=&quot;math inline&quot;&gt;\(1/e\)&lt;/span&gt;=37% &lt;span class=&quot;citation&quot; data-cites=&quot;gilbert_mosteller1966&quot;&gt;(Gilbert and Mosteller 1966)&lt;/span&gt;. Below we show a small table illustrating the precision of the asymptotic approximation.&lt;/p&gt;
&lt;center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&quot;header&quot;&gt;
&lt;th style=&quot;text-align: right;&quot;&gt;&lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt;&lt;/th&gt;
&lt;th style=&quot;text-align: right;&quot;&gt;&lt;span class=&quot;math inline&quot;&gt;\(r-1\)&lt;/span&gt;&lt;/th&gt;
&lt;th style=&quot;text-align: right;&quot;&gt;&lt;span class=&quot;math inline&quot;&gt;\((r-1)/n\)&lt;/span&gt; (%)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;10&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;4&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;40.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;100&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;38&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;38.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;1000&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;369&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;36.9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;10000&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;3680&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;36.8&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/center&gt;
&lt;p&gt;We summarise our above findings for how to find the best candidate in the following function:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;strategy_best &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(n) {
  r &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;find_r&lt;/span&gt;(n)
  s &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;rep&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;,r&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;),&lt;span class=&quot;kw&quot;&gt;rep&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,n-(r&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;)-&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;),n)
  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt;(s)
}

(s &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;strategy_best&lt;/span&gt;(n))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  0  0  0  1  1  1  1  1  1 10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;...and sometimes one animation says more than a lot of text and equations:&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-06-12-optimalChoice/animation-select.gif&quot; /&gt;
&lt;/figure&gt;
&lt;h2 id=&quot;maximizing-the-expected-rank&quot;&gt;Maximizing the expected rank&lt;/h2&gt;
&lt;p&gt;As attractive as it may sound, finding the overall best candidate appears a pedant&#39;s criterion. In reality, you would typically settle with a lesser rank, as long as you know the candidate is good and it&#39;s yours to keep. Hence, finding a &lt;a href=&quot;https://en.wikipedia.org/wiki/Satisficing&quot;&gt;satisficing&lt;/a&gt; strategy to minimize, e.g., the expected rank appears a more prudent objective for the risk adverse decision maker. This problem was addressed by &lt;span class=&quot;citation&quot; data-cites=&quot;chow_etal1964&quot;&gt;Chow et al. (1964)&lt;/span&gt;, we shall follow their treatment in what follows.&lt;/p&gt;
&lt;p&gt;In their paper they show that the relative ranks &lt;span class=&quot;math inline&quot;&gt;\(y_1,\ldots,y_n\)&lt;/span&gt; are independent and the probability mass function of the &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt;&#39;s relative rank is &lt;span class=&quot;math inline&quot;&gt;\(P(y_i=j)=1/i\)&lt;/span&gt;, &lt;span class=&quot;math inline&quot;&gt;\(j=1,\ldots,i\)&lt;/span&gt;. Furthermore, the sequence of relative ranks has the Markov property and, hence,&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
P(x_i=k|y_1=j_1,\ldots,y_{i-1}=j_{i-1},y_i=j) = P(x_i=k|y_i=j) =
\frac{\binom{k-1}{j-1} \binom{n-k}{i-j}}{\binom{n}{i}}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;From this one computes&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
E(x_i|y_i=j) = \sum_{k=1}^n k\cdot P(x_i=k|y_i=j) = \frac{n+1}{i+1} j.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Define &lt;span class=&quot;math inline&quot;&gt;\(c_i=c_i(n)\)&lt;/span&gt; to be the minimal possible expected overall rank selected if we limit us to strategies of the following type: use the first &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt; candidates to generate a baseline and then, starting from &lt;span class=&quot;math inline&quot;&gt;\(i+1\)&lt;/span&gt;, select the first candidate better than the baseline. &lt;span class=&quot;citation&quot; data-cites=&quot;chow_etal1964&quot;&gt;Chow et al. (1964)&lt;/span&gt; shows that &lt;span class=&quot;math inline&quot;&gt;\(c_i\)&lt;/span&gt; can be computed by backwards recursion: Beginning with&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
c_{n-1} = E\left(\frac{n+1}{n+1}y_n\right) = \frac{1}{n} \sum_{j=1}^n
j = \frac{n+1}{2},
\]&lt;/span&gt; and then for &lt;span class=&quot;math inline&quot;&gt;\(i=n-1,n-2,\ldots,1\)&lt;/span&gt; letting &lt;span class=&quot;math display&quot;&gt;\[
s_i     = \left[ \frac{i+1}{n+1} c_i\right] \\
c_{i-1} = \frac{1}{i} \left[ \frac{n+1}{i+1} \cdot \frac{s_i(s_i+1)}{2}+ (i-s_i)c_i \right],
\]&lt;/span&gt; where &lt;span class=&quot;math inline&quot;&gt;\([x]\)&lt;/span&gt; denotes the largest integer smaller or equal to &lt;span class=&quot;math inline&quot;&gt;\(x\)&lt;/span&gt;, i.e. &lt;code&gt;floor(x)&lt;/code&gt;. Because at each decision time &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt; we choose between either picking the current candidate or proceeding to the next candidate, we can evaluate the two options according to their expected payoff:&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;if we decide to wait deciding for at least another round the expected payoff is &lt;span class=&quot;math inline&quot;&gt;\(c_i\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;If we selected the current candidate, which has relative rank &lt;span class=&quot;math inline&quot;&gt;\(y_i=j\)&lt;/span&gt; our expected payoff is &lt;span class=&quot;math inline&quot;&gt;\(E(x_i|y_i=j)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Our optimal stopping time is thus&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[
\min_{i\in \{1,\ldots,n\}} \{ E(x_i|y_i=j) \geq c_{i} \&amp;gt; \text{or} \&amp;gt; i=n \}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Implicitly, the above computed sequence of &lt;span class=&quot;math inline&quot;&gt;\(s_i\)&lt;/span&gt;&#39;s actually contains the resulting decision strategy &lt;span class=&quot;citation&quot; data-cites=&quot;chow_etal1964&quot;&gt;(Chow et al. 1964)&lt;/span&gt;. We transfer the procedure into R code as follows:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;co&quot;&gt;# Function to find a strategy minimizing expected rank as done by Chow et al. (1964).&lt;/span&gt;
strategy_erank &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(n) {
  c &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;s &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;rep&lt;/span&gt;(&lt;span class=&quot;ot&quot;&gt;NA&lt;/span&gt;,n)
  idx &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(i) {i&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;}
  c[&lt;span class=&quot;kw&quot;&gt;idx&lt;/span&gt;(n&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;)] &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;(n&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;)/&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;
  s[&lt;span class=&quot;kw&quot;&gt;idx&lt;/span&gt;(n)] &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;n

  for (i in (n&lt;span class=&quot;dv&quot;&gt;-1&lt;/span&gt;):&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;) {
    s[&lt;span class=&quot;kw&quot;&gt;idx&lt;/span&gt;(i)]   &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;floor&lt;/span&gt;( (i&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;)/(n&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;)*c[&lt;span class=&quot;kw&quot;&gt;idx&lt;/span&gt;(i)])
    c[&lt;span class=&quot;kw&quot;&gt;idx&lt;/span&gt;(i)-&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;] &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;/i *&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;( (n&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;)/(i&lt;span class=&quot;dv&quot;&gt;+1&lt;/span&gt;)*s[&lt;span class=&quot;kw&quot;&gt;idx&lt;/span&gt;(i)]*(s[&lt;span class=&quot;kw&quot;&gt;idx&lt;/span&gt;(i)]+&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)/&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt; +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;(i-s[&lt;span class=&quot;kw&quot;&gt;idx&lt;/span&gt;(i)])*c[&lt;span class=&quot;kw&quot;&gt;idx&lt;/span&gt;(i)])
  }

  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;s=&lt;/span&gt;s,&lt;span class=&quot;dt&quot;&gt;c=&lt;/span&gt;c))
}

&lt;span class=&quot;kw&quot;&gt;print&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;strategy_erank&lt;/span&gt;(n),&lt;span class=&quot;dt&quot;&gt;digits=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;4&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;## $s
##  [1] NA  0  0  0  1  1  2  2  3  5 10
## 
## $c
##  [1] 2.558 2.558 2.558 2.558 2.677 2.888 3.154 3.590 4.278 5.500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that in the above, the first element of the vectors &lt;code&gt;s&lt;/code&gt; and &lt;code&gt;c&lt;/code&gt; is the element 0. Hence, &lt;span class=&quot;math inline&quot;&gt;\(s_1\)&lt;/span&gt; is located at position two of the vector. It is interesting to observe that for the example one forms a baseline for the same amount of time, but after a while becomes more &lt;strong&gt;desperate&lt;/strong&gt; and accepts candidates who are not optimal.&lt;/p&gt;
&lt;p&gt;Finally, it is interesting to compare the two strategies for any &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; we like, e.g. &lt;span class=&quot;math inline&quot;&gt;\(n=15\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;(two_s &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;rbind&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;best=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;strategy_best&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;15&lt;/span&gt;), &lt;span class=&quot;dt&quot;&gt;erank=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;strategy_erank&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;15&lt;/span&gt;)$s[-&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;]))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] [,15]
## best     0    0    0    0    0    1    1    1    1     1     1     1     1     1    15
## erank    0    0    0    0    1    1    1    1    2     2     3     4     5     7    15&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again, for the expected minimizing rank strategy our training sample is slightly smaller than for the selecting the best strategy. Furthermore, we again adapt our relative-rank criterion as one becomes more desperate towards the end. Finally, we illustrate the two strategies on the &lt;span class=&quot;math inline&quot;&gt;\(n=15\)&lt;/span&gt; sequence with ranks &lt;span class=&quot;math inline&quot;&gt;\(x\)&lt;/span&gt; (and resulting relative ranks &lt;span class=&quot;math inline&quot;&gt;\(y\)&lt;/span&gt;):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##   [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] [,15]
## x    8    5    6    9    1    3   10   12   14    15     4    13    11     2     7
## y    1    1    2    4    1    2    7    8    9    10     3    10     9     2     7&lt;/code&gt;&lt;/pre&gt;
&lt;figure&gt;
&lt;img src=&quot;/hoehle/blog/figure/source/2016-06-12-optimalChoice/animation-select2.gif&quot; /&gt;
&lt;/figure&gt;
&lt;h1 id=&quot;monte-carlo-simulation&quot;&gt;Monte Carlo simulation&lt;/h1&gt;
&lt;p&gt;Using Monte Carlo integration we can for a given &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; compute the expected rank obtained by each of the strategies.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;simulate &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;function(s,n) {
  x &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;sample&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;seq_len&lt;/span&gt;(n),&lt;span class=&quot;dt&quot;&gt;size=&lt;/span&gt;n,&lt;span class=&quot;dt&quot;&gt;replace=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;FALSE&lt;/span&gt;)
  y &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;relrank&lt;/span&gt;(x)
  idxSelect &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;which.max&lt;/span&gt;(y &amp;lt;=&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;s)
  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;rank=&lt;/span&gt;x[idxSelect],&lt;span class=&quot;dt&quot;&gt;idx=&lt;/span&gt;idxSelect,&lt;span class=&quot;dt&quot;&gt;isBest=&lt;/span&gt;(x[idxSelect]==&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)))
}

strategies &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;list&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;s_best=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;strategy_best&lt;/span&gt;(n), &lt;span class=&quot;dt&quot;&gt;s_erank=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;strategy_erank&lt;/span&gt;(n)$s[-&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;])
res &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;lapply&lt;/span&gt;(strategies, function(s) &lt;span class=&quot;kw&quot;&gt;replicate&lt;/span&gt;(&lt;span class=&quot;fl&quot;&gt;1e5&lt;/span&gt;, &lt;span class=&quot;kw&quot;&gt;simulate&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;s=&lt;/span&gt;s,&lt;span class=&quot;dt&quot;&gt;n=&lt;/span&gt;n)))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;(sim &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;rbind&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;best=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;apply&lt;/span&gt;(res[[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;]], &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,mean), &lt;span class=&quot;dt&quot;&gt;erank=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;apply&lt;/span&gt;(res[[&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;]],&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,mean)))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;##          rank     idx  isBest
## best  3.02481 6.98755 0.39855
## erank 2.55563 6.27949 0.33177&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From the results it becomes clear that the expected rank optimizing strategy on average takes a little less time before selecting a candidate. Furthermore, the obtained expected rank is somewhat better than for the overall best decision strategy. We can also compare the Monte Carlo estimate &lt;code&gt;sim[&amp;quot;erank&amp;quot;,&amp;quot;rank&amp;quot;]&lt;/code&gt;=2.556 against the theoretical value of &lt;span class=&quot;math inline&quot;&gt;\(c_0\)&lt;/span&gt;=2.558.&lt;/p&gt;
&lt;h1 id=&quot;discussion&quot;&gt;Discussion&lt;/h1&gt;
&lt;p&gt;Is the blog title &lt;em&gt;Mathematical advice for real life&lt;/em&gt; an &lt;strong&gt;oxymoron&lt;/strong&gt;? Certainly not! Assumptions 1-6 clearly state the abstraction. You may not agree with these assumptions, but given that framework, the two functions &lt;code&gt;strategy_best&lt;/code&gt;and &lt;code&gt;strategy_erank&lt;/code&gt; give practical advice for a certain class of decisions. The methods are also clearly superior to &lt;a href=&quot;https://www.youtube.com/watch?v=BVIjqd8DBGw&quot;&gt;Sheldon Cooper&#39;s dice strategy&lt;/a&gt;. Furthermore, assumptions 1-6 have been improved upon in a multitude of ways &lt;span class=&quot;citation&quot; data-cites=&quot;freeman1983&quot;&gt;(Freeman 1983)&lt;/span&gt;. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;unknown &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; or random &lt;span class=&quot;math inline&quot;&gt;\(n\sim\operatorname{Po}(\lambda)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;the opportunity to return to previous candidates, but with a probability &lt;span class=&quot;math inline&quot;&gt;\(p\)&lt;/span&gt; of being rejected&lt;/li&gt;
&lt;li&gt;Candidate score originating from a known underlying distribution, e.g. the uniform or the normal&lt;/li&gt;
&lt;li&gt;Candidate score originating from an &lt;span class=&quot;math inline&quot;&gt;\(U(a,b)\)&lt;/span&gt; uniform with unknown &lt;span class=&quot;math inline&quot;&gt;\(a&amp;lt;b\)&lt;/span&gt;, but with a conjugate and sequentially updated bivariate Pareto prior on &lt;span class=&quot;math inline&quot;&gt;\((a,b)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Altogether, such methods provide decision support: One can evaluate a potential decision and compare results with other ways of reaching the decision. &lt;span class=&quot;citation&quot; data-cites=&quot;frey_eichenberger1996&quot;&gt;Frey and Eichenberger (1996)&lt;/span&gt; discuss that for marriage decisions investigations show that individuals decide rather quickly marrying the first reasonably serious partner. Where does this misalignment between theory and practice originate from? Some of it appears to be consequences of additional effects not addressed by the model, e.g., little marginal gain of searching longer, &lt;em&gt;lemon effects&lt;/em&gt;, satisficing, endowment effects, etc... &lt;strong&gt;Life is complicated&lt;/strong&gt;. Finding a satisficing complexity representation is non-trivial - even for mathematicians. :-)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://staff.math.su.se/hoehle/blog/figure/source/2016-06-12-optimalChoice/unnamed-chunk-17-1.png&quot; style=&quot;display: block; margin: auto;&quot; /&gt;&lt;/p&gt;
&lt;h1 id=&quot;references&quot; class=&quot;unnumbered&quot;&gt;References&lt;/h1&gt;
&lt;div id=&quot;refs&quot; class=&quot;references&quot;&gt;
&lt;div id=&quot;ref-berger1985&quot;&gt;
&lt;p&gt;Berger, J. O. 1985. &lt;em&gt;Statistical Decision Theory and Bayesian Analysis : With 23 Illustrations&lt;/em&gt;. 2nd ed. Springer Series in Statistics. New York, Berlin, Heidelberg: Springer.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-chow_etal1964&quot;&gt;
&lt;p&gt;Chow, Y. S., S. Moriguti, H. Robbins, and S. M. Samuels. 1964. “Optimal Selection Based on Relative Rank (the ‘Secretary Problem’).” &lt;em&gt;Israel Journal of Mathematics&lt;/em&gt; 2 (2): 81–90. doi:&lt;a href=&quot;https://doi.org/10.1007/BF02759948&quot;&gt;10.1007/BF02759948&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-degroot1970&quot;&gt;
&lt;p&gt;DeGroot, Morris. 1970. &lt;em&gt;Optimal Statistical Decisions&lt;/em&gt;. McGraw-Hill. New York.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-ferguson1989&quot;&gt;
&lt;p&gt;Ferguson, T. S. 1989. “Who Solved the Secretary Problem?” &lt;em&gt;Statist. Sci.&lt;/em&gt; 4 (3). The Institute of Mathematical Statistics: 282–89. doi:&lt;a href=&quot;https://doi.org/10.1214/ss/1177012493&quot;&gt;10.1214/ss/1177012493&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-freeman1983&quot;&gt;
&lt;p&gt;Freeman, P. R. 1983. “The Secretary Problem and Its Extensions: A Review.” &lt;em&gt;International Statistical Review / Revue Internationale de Statistique&lt;/em&gt; 51 (2): 189–206. &lt;a href=&quot;http://www.jstor.org/stable/1402748&quot; class=&quot;uri&quot;&gt;http://www.jstor.org/stable/1402748&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-frey_eichenberger1996&quot;&gt;
&lt;p&gt;Frey, B. S., and R. Eichenberger. 1996. “Marriage Paradoxes.” &lt;em&gt;Rationality and Society&lt;/em&gt; 8 (2): 187–206.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-gilbert_mosteller1966&quot;&gt;
&lt;p&gt;Gilbert, J. P., and F. Mosteller. 1966. “Recognizing the Maximum of a Sequence.” &lt;em&gt;Journal of the American Statistical Association&lt;/em&gt; 61 (313): 35–73. &lt;a href=&quot;http://www.jstor.org/stable/2283044&quot; class=&quot;uri&quot;&gt;http://www.jstor.org/stable/2283044&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ref-jensen_nielsen2007&quot;&gt;
&lt;p&gt;Jensen, F. V., and T. D. Nielsen. 2007. &lt;em&gt;Bayesian Networks and Decision Graphs&lt;/em&gt;. 2nd ed. Springer Verlag.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
        <pubDate>Sun, 12 Jun 2016 00:00:00 +0200</pubDate>
        <link>http://staff.math.su.se/hoehle/blog/2016/06/12/optimalChoice.html</link>
        <guid isPermaLink="true">http://staff.math.su.se/hoehle/blog/2016/06/12/optimalChoice.html</guid>
        
        <category>datascience</category>
        
        <category>rstats</category>
        
        <category>debugging</category>
        
        
      </item>
    
  </channel>
</rss>
